{'token': ['Semantic', 'Role', 'Labeling', '(', 'SRL', ')', ',', 'arguments', 'usually', 'limited', 'syntax', 'subtree', '.'], 'h': {'name': 'arguments', 'pos': [7, 8]}, 't': {'name': 'syntax subtree', 'pos': [10, 12]}, 'relation': 'part_whole'}
{'token': ['reasonable', 'label', 'arguments', 'locally', 'sub', '-', 'tree', 'rather', 'whole', 'tree', '.'], 'h': {'name': 'arguments', 'pos': [2, 3]}, 't': {'name': 'sub-tree', 'pos': [4, 7]}, 'relation': 'part_whole'}
{'token': ['anchor', 'group', 'approach', 'achieves', 'accuracy', '87.75', '%', 'single', 'anchor', 'approach', 'achieves', '83.63', '%.'], 'h': {'name': 'anchor group approach', 'pos': [0, 3]}, 't': {'name': 'accuracy', 'pos': [4, 5]}, 'relation': 'result'}
{'token': ['Experimental', 'results', 'also', 'indicate', 'prediction', 'MP', 'improves', 'semantic', 'role', 'labeling', '.'], 'h': {'name': 'prediction of MP', 'pos': [4, 6]}, 't': {'name': 'semantic role labeling', 'pos': [7, 10]}, 'relation': 'result'}
{'token': ['Recently', 'LATL', 'undertaken', 'development', 'multilingual', 'translation', 'system', 'based', 'symbolic', 'parsing', 'technology', 'transfer', '-', 'based', 'translation', 'model', '.'], 'h': {'name': 'symbolic parsing technology', 'pos': [8, 11]}, 't': {'name': 'multilingual translation system', 'pos': [4, 7]}, 'relation': 'usage'}
{'token': ['paper', 'describes', 'unsupervised', 'learning', 'algorithm', 'disambiguating', 'verbal', 'word', 'senses', 'using', 'term', 'weight', 'learning', '.'], 'h': {'name': 'term weight learning', 'pos': [10, 13]}, 't': {'name': 'verbal word senses', 'pos': [6, 9]}, 'relation': 'usage'}
{'token': ['quite', 'different', 'current', 'approaches', 'semantic', 'parsing', 'chunking', 'depend', 'full', 'statistical', 'syntactic', 'parsers', 'require', 'tree', 'bank', 'style', 'annotation', '.'], 'h': {'name': 'statistical syntactic parsers', 'pos': [9, 12]}, 't': {'name': 'chunking', 'pos': [6, 7]}, 'relation': 'usage'}
{'token': ['compare', 'recently', 'proposed', 'word', '-', 'word', 'semantic', 'chunker', 'and', 'results', 'that', 'that', 'phrase', '-', 'by-', 'approach', 'performs', 'better', 'than', 'its', '-', 'by', '-', 'counterpart', '.'], 'h': {'name': 'phrase-by-phrase approach', 'pos': [12, 16]}, 't': {'name': 'word-by-word counterpart', 'pos': [20, 24]}, 'relation': 'compare'}
{'token': ['primary', 'objective', 'basic', 'research', 'develop', 'improved', 'methods', 'models', 'acoustic', 'recognition', 'continuous', 'speech', '.'], 'h': {'name': 'acoustic recognition', 'pos': [8, 10]}, 't': {'name': 'continuous speech', 'pos': [10, 12]}, 'relation': 'usage'}
{'token': ['work', 'focussed', 'developing', 'accurate', 'detailed', 'mathematical', 'models', 'phonemes', 'coarticulation', 'purpose', 'large', '-', 'vocabulary', 'continuous', 'speech', 'recognition', '.'], 'h': {'name': 'phonemes', 'pos': [7, 8]}, 't': {'name': 'large-vocabulary continuous speech recognition', 'pos': [10, 16]}, 'relation': 'usage'}
{'token': ['KeyWords', 'compares', 'a', 'word', 'list', 'extracted', 'from', "'", 'the', 'corpus', "'", '(', 'the', 'which', 'is', 'in', ')', 'with', 'list', 'made', 'from', 'corpus', '.'], 'h': {'name': 'word list', 'pos': [3, 5]}, 't': {'name': 'corpus', 'pos': [9, 10]}, 'relation': 'part_whole'}
{'token': ['KeyWords', 'compares', 'a', 'list', 'extracted', 'from', "'", 'the', 'corpus', "'", '(', 'the', 'which', 'is', 'in', ')', 'with', 'word', 'list', 'made', 'from', 'reference', 'corpus', '.'], 'h': {'name': 'word list', 'pos': [17, 19]}, 't': {'name': 'reference corpus', 'pos': [21, 23]}, 'relation': 'part_whole'}
{'token': ['Five', 'English', 'corpora', 'compared', 'reference', 'corpora', 'various', 'sizes', '(', 'varying', 'two', '100', 'times', 'larger', 'study', 'corpus', ')', '.'], 'h': {'name': 'English corpora', 'pos': [1, 3]}, 't': {'name': 'reference corpora', 'pos': [4, 6]}, 'relation': 'compare'}
{'token': ['results', 'indicate', 'reference', 'corpus', 'five', 'times', 'large', 'study', 'corpus', 'yielded', 'larger', 'number', 'keywords', 'smaller', 'reference', 'corpus', '.'], 'h': {'name': 'keywords', 'pos': [12, 13]}, 't': {'name': 'corpus', 'pos': [8, 9]}, 'relation': 'part_whole'}
{'token': ['implication', 'larger', 'reference', 'corpus', 'always', 'better', 'smaller', 'one', ',', 'WordSmith', 'Tools', 'Keywords', 'analysis', ',', 'reference', 'corpus', 'less', 'five', 'times', 'size', 'study', 'corpus', 'may', 'reliable', '.'], 'h': {'name': 'reference corpus', 'pos': [14, 16]}, 't': {'name': 'study corpus', 'pos': [20, 22]}, 'relation': 'compare'}
{'token': ['paper', 'report', 'qualitative', 'evaluation', 'performance', 'dependency', 'analyser', 'Italian', 'runs', 'non-lexicalised', 'lexicalised', 'mode', '.'], 'h': {'name': 'dependency analyser', 'pos': [5, 7]}, 't': {'name': 'Italian', 'pos': [7, 8]}, 'relation': 'usage'}
{'token': ['Results', 'shed', 'light', 'contribution', 'types', 'lexical', 'information', 'parsing', '.'], 'h': {'name': 'lexical information', 'pos': [5, 7]}, 't': {'name': 'parsing', 'pos': [7, 8]}, 'relation': 'usage'}
{'token': ['international', 'phonology', 'speech', 'synthesis', 'research', ',', 'suggested', 'relative', 'informativeness', 'word', 'used', 'predict', 'pitch', 'prominence', '.'], 'h': {'name': 'relative informativeness', 'pos': [7, 9]}, 't': {'name': 'word', 'pos': [9, 10]}, 'relation': 'model-feature'}
{'token': ['paper', ',', 'provide', 'empirical', 'evidence', 'support', 'existence', 'correlation', 'employing', 'two', 'widely', 'accepted', 'measures', 'informativeness', '.'], 'h': {'name': 'measures', 'pos': [12, 13]}, 't': {'name': 'informativeness', 'pos': [13, 14]}, 'relation': 'model-feature'}
{'token': ['experiments', 'show', 'positive', 'correlation', 'informativeness', 'word', 'pitch', 'accent', 'assignment', '.'], 'h': {'name': 'informativeness', 'pos': [4, 5]}, 't': {'name': 'word', 'pos': [5, 6]}, 'relation': 'model-feature'}
{'token': ['computation', 'word', 'informativeness', 'inexpensive', 'incorporated', 'speech', 'synthesis', 'systems', 'easily', '.'], 'h': {'name': 'word informativeness', 'pos': [1, 3]}, 't': {'name': 'speech synthesis systems', 'pos': [5, 8]}, 'relation': 'usage'}
{'token': ['"', 'efficient', 'parsing', 'algorithm', 'augmented', 'context', '-', 'free', 'grammars', 'introduced', ',', 'application', 'line', 'natural', 'language', 'interfaces', 'discussed', '.'], 'h': {'name': 'parsing algorithm', 'pos': [2, 4]}, 't': {'name': 'augmented context-free grammars', 'pos': [4, 9]}, 'relation': 'usage'}
{'token': ['algorithm', 'generalized', 'LR', 'parsing', 'algorithm', ',', 'precomputes', 'LR', 'shift', '-', 'reduce', 'parsing', 'table', '(', 'possibly', 'multiple', 'entries', ')', 'given', 'augmented', 'context', '-', 'free', 'grammar', '.'], 'h': {'name': 'generalized LR parsing algorithm', 'pos': [1, 5]}, 't': {'name': 'LR shift-reduce parsing table', 'pos': [7, 13]}, 'relation': 'usage'}
{'token': ['also', 'view', 'parsing', 'algorithm', 'extended', 'chart', 'parsing', 'algorithm', 'efficiently', 'guided', 'LR', 'parsing', 'tables', '.'], 'h': {'name': 'LR parsing tables', 'pos': [10, 13]}, 't': {'name': 'chart parsing algorithm', 'pos': [5, 8]}, 'relation': 'usage'}
{'token': ['Also', ',', 'commercial', '-', 'line', 'parser', 'Japanese', 'language', 'built', 'Intelligent', 'Technology', 'Incorporation', ',', 'based', 'technique', 'developed', 'CMU', '.', '"'], 'h': {'name': 'on-line parser', 'pos': [3, 6]}, 't': {'name': 'Japanese language', 'pos': [6, 8]}, 'relation': 'usage'}
{'token': ['article', 'proposes', 'hybrid', 'statistical', 'structural', 'semantic', 'model', 'multi-stage', 'spoken', 'language', 'understanding', '(', 'SLU', ')', '.'], 'h': {'name': 'hybrid statistical and structural semantic model', 'pos': [2, 7]}, 't': {'name': 'multi-stage spoken language understanding (SLU)', 'pos': [7, 14]}, 'relation': 'usage'}
{'token': ['first', 'stage', 'SLU', 'utilizes', 'weighted', 'finite', '-', 'state', 'transducer', '(', 'WFST', ')', '-', 'based', 'parser', ',', 'encodes', 'regular', 'grammar', 'concepts', 'extracted', '.'], 'h': {'name': 'weighted finite-state transducer (WFST)-based parser', 'pos': [4, 15]}, 't': {'name': 'SLU', 'pos': [2, 3]}, 'relation': 'usage'}
{'token': ['proposed', 'method', 'improves', 'regular', 'grammar', 'model', 'incorporating', 'well', '-', 'known', 'n-gram', 'semantic', 'tagger', '.'], 'h': {'name': 'n-gram semantic tagger', 'pos': [10, 13]}, 't': {'name': 'regular grammar', 'pos': [3, 5]}, 'relation': 'usage'}
{'token': ['paper', 'presents', 'corpus', '-', 'based', 'account', 'structural', 'priming', 'human', 'sentence', 'processing', ',', 'focusing', 'role', 'syntactic', 'representations', 'play', 'account', '.'], 'h': {'name': 'structural priming', 'pos': [6, 8]}, 't': {'name': 'sentence processing', 'pos': [9, 11]}, 'relation': 'model-feature'}
{'token': ['estimate', 'strength', 'structural', 'priming', 'effects', 'corpus', 'spontaneous', 'spoken', 'dialogue', ',', 'annotated', 'syntactically', 'Combinatory', 'Categorial', 'Grammar', '(', 'CCG', ')', 'derivations', '.'], 'h': {'name': 'spontaneous spoken dialogue', 'pos': [6, 9]}, 't': {'name': 'corpus', 'pos': [5, 6]}, 'relation': 'part_whole'}
{'token': ['particular', ',', 'present', 'evidence', 'priming', 'lexical', 'syntactic', 'categories', 'encoding', 'partially', 'satisfied', 'sub-categorization', 'frames', ',', 'show', 'priming', 'effects', 'exist', 'incremental', 'normal', '-', 'form', 'CCG', 'derivations', '.'], 'h': {'name': 'priming effects', 'pos': [15, 17]}, 't': {'name': 'incremental and normal-form CCG derivations', 'pos': [18, 24]}, 'relation': 'model-feature'}
{'token': ['paper', 'describes', 'application', 'ensemble', 'indexing', 'classification', 'systems', ',', 'shown', 'successful', 'information', 'retrieval', 'classification', 'medical', 'literature', ',', 'new', 'task', 'assigning', 'ICD-9', '-', 'CM', 'codes', 'to', 'the', 'and', 'impression', 'of', 'radiology', '.'], 'h': {'name': 'information retrieval', 'pos': [10, 12]}, 't': {'name': 'medical literature', 'pos': [13, 15]}, 'relation': 'usage'}
{'token': ['type', 'summary', 'could', 'serve', 'effective', 'navigation', 'tool', 'accessing', 'information', 'long', 'texts', ',', 'books', '.'], 'h': {'name': 'summary', 'pos': [1, 2]}, 't': {'name': 'texts', 'pos': [10, 11]}, 'relation': 'model-feature'}
{'token': ['generate', 'coherent', 'table', '-', '-', 'contents', ',', 'need', 'capture', 'global', 'dependencies', 'across', 'different', 'titles', 'table', 'local', 'constraints', 'within', 'sections', '.'], 'h': {'name': 'titles', 'pos': [13, 14]}, 't': {'name': 'table-of-contents', 'pos': [2, 6]}, 'relation': 'usage'}
{'token': ['First', ',', 'compare', 'cruiser', 'baseline', 'system', '-', 'initiative', 'DS', ',', 'show', 'users', 'prefer', 'cruiser', '.'], 'h': {'name': 'cruiser', 'pos': [3, 4]}, 't': {'name': 'system-initiative DS', 'pos': [5, 9]}, 'relation': 'compare'}
{'token': ['improve', 'Mandarin', 'large', 'vocabulary', 'continuous', 'speech', 'recognition', '(', 'LVCSR', ')', ',', 'unified', 'framework', 'based', 'approach', 'introduced', 'exploit', 'multi-level', 'linguistic', 'knowledge', '.'], 'h': {'name': 'multi-level linguistic knowledge', 'pos': [17, 20]}, 't': {'name': 'large vocabulary continuous speech recognition (LVCSR)', 'pos': [2, 10]}, 'relation': 'usage'}
{'token': ['framework', ',', 'knowledge', 'source', 'represented', 'Weighted', 'Finite', 'State', 'Transducer', '(', 'WFST', ')', ',', 'combined', 'obtain', 'so-called', 'analyzer', 'integrating', 'multi-level', 'knowledge', 'sources', '.'], 'h': {'name': 'Weighted Finite State Transducer (WFST)', 'pos': [5, 12]}, 't': {'name': 'knowledge source', 'pos': [2, 4]}, 'relation': 'model-feature'}
{'token': ['Due', 'uniform', 'transducer', 'representation', ',', 'knowledge', 'source', 'easily', 'integrated', 'analyzer', ',', 'long', 'encoded', 'WFSTs', '.'], 'h': {'name': 'knowledge source', 'pos': [5, 7]}, 't': {'name': 'WFSTs', 'pos': [13, 14]}, 'relation': 'usage'}
{'token': ['paper', 'discuss', 'algorithms', 'clustering', 'words', 'classes', 'unlabeled', 'text', 'using', 'unsupervised', 'algorithms', ',', 'based', 'distributional', 'morphological', 'information', '.'], 'h': {'name': 'words', 'pos': [4, 5]}, 't': {'name': 'unlabeled text', 'pos': [6, 8]}, 'relation': 'part_whole'}
{'token': ['"', 'paper', 'presents', 'unsupervised', 'relation', 'extraction', 'algorithm', ',', 'induces', 'relations', 'entity', 'pairs', 'grouping', '"', 'natural', '"', 'number', 'clusters', 'based', 'similarity', 'contexts', '.'], 'h': {'name': 'unsupervised relation extraction algorithm', 'pos': [3, 7]}, 't': {'name': 'entity pairs', 'pos': [10, 12]}, 'relation': 'usage'}
{'token': ['paper', 'presents', 'method', 'measures', 'similarity', 'compound', 'nouns', 'different', 'languages', 'locate', 'translation', 'equivalents', 'corpora', '.'], 'h': {'name': 'translation equivalents', 'pos': [10, 12]}, 't': {'name': 'corpora', 'pos': [12, 13]}, 'relation': 'part_whole'}
{'token': ['method', 'uses', 'information', 'unrelated', 'corpora', 'different', 'languages', 'parallel', '.'], 'h': {'name': 'corpora', 'pos': [4, 5]}, 't': {'name': 'languages', 'pos': [6, 7]}, 'relation': 'model-feature'}
{'token': ['method', 'compares', 'contexts', 'target', 'compound', 'nouns', 'translation', 'candidates', 'word', 'semantic', 'attribute', 'level', '.'], 'h': {'name': 'contexts', 'pos': [2, 3]}, 't': {'name': 'translation candidates', 'pos': [6, 8]}, 'relation': 'compare'}
{'token': ['paper', ',', 'show', 'measuring', 'method', 'applied', 'select', 'best', 'English', 'translation', 'candidate', 'Japanese', 'compound', 'nouns', '70', '%', 'cases', '.'], 'h': {'name': 'English translation', 'pos': [8, 10]}, 't': {'name': 'Japanese compound nouns', 'pos': [11, 14]}, 'relation': 'usage'}
{'token': ['Applications', 'statistical', 'Arabic', 'NLP', 'general', ',', 'text', 'mining', 'specific', ',', 'along', 'tools', 'underneath', 'perform', 'much', 'better', 'statistical', 'processing', 'operates', 'deeper', 'language', 'factorization', '(', ')', 'raw', 'text'], 'h': {'name': 'text mining', 'pos': [6, 8]}, 't': {'name': 'statistical Arabic NLP', 'pos': [1, 4]}, 'relation': 'part_whole'}
{'token': ['Applications', 'statistical', 'Arabic', 'NLP', 'general', ',', 'text', 'mining', 'specific', ',', 'along', 'tools', 'underneath', 'perform', 'much', 'better', 'statistical', 'processing', 'operates', 'deeper', 'language', 'factorization', '(', ')', 'raw', 'text'], 'h': {'name': 'statistical processing', 'pos': [16, 18]}, 't': {'name': 'language factorization(s)', 'pos': [20, 24]}, 'relation': 'usage'}
{'token': ['building', 'LR', ',', 'go', 'beyond', 'conventional', 'exclusive', 'collection', 'words', 'dictionaries', 'thesauri', 'cannot', 'alone', 'produce', 'satisfactory', 'coverage', 'highly', 'inflective', 'derivative', 'language', '.'], 'h': {'name': 'words', 'pos': [8, 9]}, 't': {'name': 'dictionaries', 'pos': [9, 10]}, 'relation': 'part_whole'}
{'token': ['aid', 'large', '-', 'scale', 'Arabic', 'morphological', 'analyzer', 'PoS', 'tagger', 'runtime', ',', 'possible', 'senses', 'virtually', 'given', 'Arabic', 'word', 'retrievable', '.'], 'h': {'name': 'PoS tagger', 'pos': [7, 9]}, 't': {'name': 'Arabic word', 'pos': [15, 17]}, 'relation': 'usage'}
{'token': ['Similarly', 'well', '-', 'established', 'ROVER', 'approach', '(', 'Fiscus', ',', '1997', ')', 'combining', 'speech', 'recognition', 'hypotheses', ',', 'consensus', 'translation', 'computed', 'voting', 'confusion', 'network', '.'], 'h': {'name': 'confusion network', 'pos': [20, 22]}, 't': {'name': 'consensus translation', 'pos': [16, 18]}, 'relation': 'usage'}
{'token': ['create', 'confusion', 'network', ',', 'produce', 'pairwise', 'word', 'alignments', 'original', 'machine', 'translation', 'hypotheses', 'enhanced', 'statistical', 'alignment', 'algorithm', 'explicitly', 'models', 'word', 'reordering', '.'], 'h': {'name': 'statistical alignment algorithm', 'pos': [13, 16]}, 't': {'name': 'word alignments', 'pos': [6, 8]}, 'relation': 'usage'}
{'token': ['context', 'whole', 'document', 'translations', 'rather', 'single', 'sentence', 'taken', 'account', 'produce', 'alignment', '.'], 'h': {'name': 'document', 'pos': [2, 3]}, 't': {'name': 'alignment', 'pos': [10, 11]}, 'relation': 'usage'}
{'token': ['method', 'also', 'tested', 'framework', 'multi-source', 'speech', 'translation', '.'], 'h': {'name': 'method', 'pos': [0, 1]}, 't': {'name': 'multi-source and speech translation', 'pos': [4, 7]}, 'relation': 'usage'}
{'token': ['present', 'two', 'stage', 'parser', 'recovers', 'Penn', 'Treebank', 'style', 'syntactic', 'analyses', 'new', 'sentences', 'including', 'skeletal', 'syntactic', 'structure', ',', ',', 'first', 'time', ',', 'function', 'tags', 'empty', 'categories', '.'], 'h': {'name': 'syntactic analyses', 'pos': [8, 10]}, 't': {'name': 'sentences', 'pos': [11, 12]}, 'relation': 'usage'}
{'token': ['accuracy', 'first', '-', 'stage', 'parser', 'standard', 'Parseval', 'metric', 'matches', '(', 'Collins', ',', '2003', ')', 'parser', 'based', ',', 'despite', 'data', 'fragmentation', 'caused', 'greatly', 'enriched', 'space', 'possible', 'node', 'labels', '.'], 'h': {'name': 'parser', 'pos': [4, 5]}, 't': {'name': 'parser', 'pos': [14, 15]}, 'relation': 'compare'}
{'token': ['anaphora', 'resolution', 'prepositional', 'phrase', '(', 'PP', ')', 'attachment', 'frequent', 'ambiguities', 'natural', 'language', 'processing', '.'], 'h': {'name': 'ambiguities', 'pos': [9, 10]}, 't': {'name': 'natural language processing', 'pos': [10, 13]}, 'relation': 'model-feature'}
{'token': ['speaker', 'adaptation', 'speaker', '-', 'independent', 'system', ',', 'two', 'vocabulary', 'adaptation', 'algorithms', '[', '5', ']', 'implemented', 'order', 'tailor', 'VI', 'subword', 'models', 'target', 'vocabulary', '.'], 'h': {'name': 'vocabulary adaptation algorithms', 'pos': [8, 11]}, 't': {'name': 'VI subword models', 'pos': [17, 20]}, 'relation': 'usage'}
{'token': ['past', '9', 'years', ',', 'Applied', 'Science', 'Engineering', 'Laboratories', '(', 'ASEL', ')', 'University', 'Delaware', 'duPont', 'Hospital', 'Children', ',', 'involved', 'applying', 'natural', 'language', 'processing', '(', 'NLP', ')', 'technologies', 'field', 'AAC', '.'], 'h': {'name': 'natural language processing (NLP) technologies', 'pos': [19, 26]}, 't': {'name': 'AAC', 'pos': [27, 28]}, 'relation': 'usage'}
{'token': ['One', 'major', 'projects', 'ASEL', '(', 'COMPAN', '-', 'SION', 'project', ')', 'concerned', 'application', 'primarily', 'lexical', 'semantics', 'sentence', 'generation', 'technology', 'expand', 'telegraphic', 'input', 'full', 'sentences', '.'], 'h': {'name': 'sentence generation technology', 'pos': [15, 18]}, 't': {'name': 'telegraphic input', 'pos': [19, 21]}, 'relation': 'usage'}
{'token': ['view', 'entire', 'problem', 'series', 'classification', 'problems', 'employ', 'memory', '-', 'based', 'learning', '(', 'MBL', ')', 'resolve', '.'], 'h': {'name': 'memory-based learning (MBL)', 'pos': [7, 14]}, 't': {'name': 'classification problems', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['problem', 'word', 'segmentation', 'affects', 'aspects', 'Chinese', 'language', 'processing', ',', 'including', 'development', 'text', '-', '-speech', 'synthesis', 'systems', '.'], 'h': {'name': 'word segmentation', 'pos': [1, 3]}, 't': {'name': 'Chinese language processing', 'pos': [5, 8]}, 'relation': 'part_whole'}
{'token': ['paper', 'treats', 'classification', 'semantic', 'functions', 'performed', 'adnominal', 'constituents', 'Japanese', ',', 'many', 'parts', 'speech', 'act', 'adnominal', 'constituents', '.'], 'h': {'name': 'adnominal constituents', 'pos': [6, 8]}, 't': {'name': 'Japanese', 'pos': [8, 9]}, 'relation': 'part_whole'}
{'token': ['adjectives', '"', 'noun', '+', '"', '(', 'English', '"', '+', 'noun', '"', ')', 'structures', ',', 'broad', 'range', 'semantic', 'functions', ',', 'discussed', '.'], 'h': {'name': 'semantic functions', 'pos': [16, 18]}, 't': {'name': '"noun + NO" (in English "of + noun") structures', 'pos': [1, 13]}, 'relation': 'model-feature'}
{'token': ['feasibility', 'verified', 'self', '-', 'organizing', 'semantic', 'map', 'based', 'neural', 'network', 'model', '.'], 'h': {'name': 'neural network model', 'pos': [8, 11]}, 't': {'name': 'self-organizing semantic map', 'pos': [2, 7]}, 'relation': 'usage'}
{'token': ['Recent', 'corpus', '-', 'based', 'work', 'word', 'sense', 'disambiguation', 'explores', 'application', 'statistical', 'pattern', 'recognition', 'procedures', 'lexical', 'co-occurrence', 'data', 'large', 'text', 'databases', '.'], 'h': {'name': 'statistical pattern recognition procedures', 'pos': [10, 14]}, 't': {'name': 'lexical co-occurrence data', 'pos': [14, 17]}, 'relation': 'usage'}
{'token': ['Statistical', 'methods', 'play', 'definite', 'role', 'work', ',', 'helping', 'organize', 'analyze', 'data', ',', 'disambiguation', 'method', 'employ', 'statistical', 'data', 'decision', 'criteria', '.'], 'h': {'name': 'statistical data', 'pos': [15, 17]}, 't': {'name': 'disambiguation method', 'pos': [12, 14]}, 'relation': 'usage'}
{'token': ['approach', 'illustrated', 'experiment', 'discriminating', 'among', 'senses', 'adjectives', ',', 'relatively', 'neglected', 'work', 'sense', 'disambiguation', '.'], 'h': {'name': 'senses', 'pos': [5, 6]}, 't': {'name': 'adjectives', 'pos': [6, 7]}, 'relation': 'model-feature'}
{'token': ['particular', ',', 'paper', 'assesses', 'potential', 'nouns', 'discriminating', 'among', 'senses', 'adjectives', 'modify', '.'], 'h': {'name': 'senses', 'pos': [8, 9]}, 't': {'name': 'adjectives', 'pos': [9, 10]}, 'relation': 'model-feature'}
{'token': ['assessment', 'based', 'empirical', 'study', 'five', 'frequent', 'ambiguous', 'adjectives', 'English', ':', 'three', '-', 'quarters', 'instances', 'adjectives', 'disambiguated', 'almost', 'errorlessly', 'nouns', 'modify', 'syntactic', 'constructions', 'occur', '.'], 'h': {'name': 'ambiguous adjectives', 'pos': [6, 8]}, 't': {'name': 'English', 'pos': [8, 9]}, 'relation': 'part_whole'}
{'token': ['assessment', 'based', 'empirical', 'study', 'five', 'frequent', 'ambiguous', 'adjectives', 'English', ':', 'three', '-', 'quarters', 'instances', 'adjectives', 'disambiguated', 'almost', 'errorlessly', 'nouns', 'modify', 'syntactic', 'constructions', 'occur', '.'], 'h': {'name': 'nouns', 'pos': [18, 19]}, 't': {'name': 'syntactic constructions', 'pos': [20, 22]}, 'relation': 'model-feature'}
{'token': ['Furthermore', ',', 'small', 'number', 'semantic', 'attributes', 'supply', 'compact', 'means', 'representing', 'noun', 'clues', 'rules', '.'], 'h': {'name': 'semantic attributes', 'pos': [4, 6]}, 't': {'name': 'noun', 'pos': [10, 11]}, 'relation': 'model-feature'}
{'token': ['sense', 'ambiguous', 'modified', 'noun', 'may', 'needed', 'determine', 'relevant', 'semantic', 'attribute', 'disambiguation', 'target', 'adjective', ';', 'adjectives', ',', 'verbs', ',', 'grammatical', 'constructions', 'show', 'evidence', 'high', 'reliability', ',', 'sometimes', 'high', 'applicability', ',', 'stand', 'specific', ',', 'well', '-', 'defined', 'syntactic', 'relations', 'ambiguous', 'adjective', '.'], 'h': {'name': 'sense', 'pos': [0, 1]}, 't': {'name': 'ambiguous modified noun', 'pos': [1, 4]}, 'relation': 'model-feature'}
{'token': ['sense', 'ambiguous', 'modified', 'noun', 'may', 'needed', 'determine', 'relevant', 'semantic', 'attribute', 'disambiguation', 'target', 'adjective', ';', 'adjectives', ',', 'verbs', ',', 'grammatical', 'constructions', 'show', 'evidence', 'high', 'reliability', ',', 'sometimes', 'high', 'applicability', ',', 'stand', 'specific', ',', 'well', '-', 'defined', 'syntactic', 'relations', 'ambiguous', 'adjective', '.'], 'h': {'name': 'semantic attribute', 'pos': [8, 10]}, 't': {'name': 'target adjective', 'pos': [11, 13]}, 'relation': 'model-feature'}
{'token': ['paper', 'presents', 'method', 'incorporating', 'character', 'clustering', 'based', 'mutual', 'information', 'Decision', '-', 'Tree', 'Dictionary', '-', 'less', 'morphological', 'analysis', '.'], 'h': {'name': 'mutual information', 'pos': [7, 9]}, 't': {'name': 'character clustering', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['using', 'natural', 'classes', ',', 'confirmed', 'morphological', 'analyzer', 'significantly', 'improved', 'tokenizing', 'tagging', 'Japanese', 'text', '.'], 'h': {'name': 'tagging', 'pos': [10, 11]}, 't': {'name': 'text', 'pos': [12, 13]}, 'relation': 'usage'}
{'token': ['case', 'study', 'one', 'direction', ',', 'discuss', 'recent', 'development', 'automatic', 'method', 'evaluating', 'definition', 'questions', 'based', 'n-gram', 'overlap', ',', 'commonly', '-', 'used', 'technique', 'summarization', 'evaluation', '.'], 'h': {'name': 'n-gram overlap', 'pos': [14, 16]}, 't': {'name': 'automatic method for evaluating definition questions', 'pos': [8, 13]}, 'relation': 'usage'}
{'token': ["SYSTRAN'S", 'Chinese', 'word', 'segmentation', 'one', 'important', 'component', 'Chinese', '-', 'English', 'machine', 'translation', 'system', '.'], 'h': {'name': 'Chinese word segmentation', 'pos': [1, 4]}, 't': {'name': 'Chinese-English machine translation system', 'pos': [7, 13]}, 'relation': 'part_whole'}
{'token': ['Chinese', 'word', 'segmentation', 'module', 'uses', 'rule', '-', 'based', 'approach', ',', 'based', 'large', 'dictionary', 'fine', '-', 'grained', 'linguistic', 'rules', '.'], 'h': {'name': 'rule-based approach', 'pos': [5, 9]}, 't': {'name': 'Chinese word segmentation', 'pos': [0, 3]}, 'relation': 'usage'}
{'token': ['works', 'general', '-', 'purpose', 'texts', 'different', 'Chinese', '-speaking', 'regions', ',', 'with', 'performance', '.'], 'h': {'name': 'Chinese-speaking regions', 'pos': [6, 9]}, 't': {'name': 'general-purpose texts', 'pos': [1, 5]}, 'relation': 'model-feature'}
{'token': ['ParaMor', ',', 'minimally', 'supervised', 'morphology', 'induction', 'algorithm', ',', 'retrusses', 'word', 'forms', 'raw', 'text', 'corpora', 'back', 'onto', 'paradigmatic', 'skeletons', ';', 'performing', 'par', 'state', '-', '-', '-', 'art', 'minimally', 'supervised', 'morphology', 'induction', 'algorithms', 'morphological', 'analysis', 'English', 'German', '.'], 'h': {'name': 'morphological analysis', 'pos': [31, 33]}, 't': {'name': 'English', 'pos': [33, 34]}, 'relation': 'usage'}
{'token': ['structures', 'hand', ',', 'Para', 'Mor', 'annotates', 'word', 'forms', 'morpheme', 'boundaries', '.'], 'h': {'name': 'morpheme boundaries', 'pos': [8, 10]}, 't': {'name': 'word forms', 'pos': [6, 8]}, 'relation': 'model-feature'}
{'token': ['set', 'ParaMor', "'s", 'free', 'parameters', 'analyze', 'training', 'corpus', 'Spanish', '.'], 'h': {'name': 'Spanish', 'pos': [8, 9]}, 't': {'name': 'training corpus', 'pos': [6, 8]}, 'relation': 'part_whole'}
{'token': ['Without', 'adjusting', 'parameters', ',', 'induce', 'morphological', 'structure', 'English', 'German', '.'], 'h': {'name': 'morphological structure', 'pos': [5, 7]}, 't': {'name': 'English', 'pos': [7, 8]}, 'relation': 'model-feature'}
{'token': ['contribution', 'work', 'incorporated', 'novel', 'long', 'distance', 'features', 'address', 'challenges', 'computing', 'multi-level', 'confidence', 'scores', '.'], 'h': {'name': 'distance features', 'pos': [5, 7]}, 't': {'name': 'multi-level confidence scores', 'pos': [10, 13]}, 'relation': 'usage'}
{'token': ['Using', 'Conditional', 'Maximum', 'Entropy', '(', 'CME', ')', 'classifier', 'selected', 'features', ',', 'reached', 'annotation', 'error', 'rate', '26.0', '%', 'SWBD', 'corpus', ',', 'compared', 'subtree', 'error', 'rate', '41.91', '%', ',', 'closely', 'related', 'benchmark', 'Charniak', 'parser', '(', 'Kahn', 'et', 'al.', ',', '2005', ')', '.'], 'h': {'name': 'Conditional Maximum Entropy (CME) classifier', 'pos': [1, 8]}, 't': {'name': 'annotation error rate', 'pos': [12, 15]}, 'relation': 'result'}
{'token': ['Coreference', 'resolution', 'systems', 'usually', 'attempt', 'find', 'suitable', 'antecedent', '(', 'almost', ')', 'every', 'noun', 'phrase'], 'h': {'name': 'Coreference resolution systems', 'pos': [0, 3]}, 't': {'name': 'noun phrase', 'pos': [12, 14]}, 'relation': 'usage'}
{'token': ['use', 'small', 'training', 'corpus', '(', 'MUC', '-', '7', ')', ',', 'also', 'acquire', 'data', 'Internet', '.'], 'h': {'name': 'data', 'pos': [12, 13]}, 't': {'name': 'Internet', 'pos': [13, 14]}, 'relation': 'part_whole'}
{'token': ['Combining', 'classifiers', 'sequentially', ',', 'achieve', '88.9', '%', 'precision', '84.6', '%', 'recall', 'discourse', 'new', 'entities', '.'], 'h': {'name': 'classifiers', 'pos': [1, 2]}, 't': {'name': 'precision', 'pos': [7, 8]}, 'relation': 'result'}
{'token': ['expect', 'classifiers', 'provide', 'good', 'prefiltering', 'coreference', 'resolution', 'systems', ',', 'improving', 'speed', 'performance', '.'], 'h': {'name': 'classifiers', 'pos': [1, 2]}, 't': {'name': 'coreference resolution systems', 'pos': [5, 8]}, 'relation': 'usage'}
{'token': ['MBDP', '-1', 'knowledge', '-', 'free', 'segmentation', 'algorithm', 'bootstraps', 'lexicon', ',', 'starts', 'empty', '.'], 'h': {'name': 'knowledge-free segmentation algorithm', 'pos': [2, 7]}, 't': {'name': 'lexicon', 'pos': [8, 9]}, 'relation': 'usage'}
{'token': ['paper', ',', 'present', 'methods', 'allow', 'users', 'natural', 'language', 'processor', '(', 'NLP', ')', 'define', ',', 'inspect', ',', 'modify', 'case', 'frame', 'information', 'associated', 'words', 'phrases', 'known', 'system', '.'], 'h': {'name': 'case frame information', 'pos': [17, 20]}, 't': {'name': 'words', 'pos': [21, 22]}, 'relation': 'model-feature'}
{'token': ['number', 'sizes', 'parallel', 'corpora', 'keep', 'growing', ',', 'makes', 'necessary', 'automatic', 'methods', 'processing', ':', 'combining', ',', 'checking', 'improving', 'corpora', 'quality', ',', 'etc.'], 'h': {'name': 'corpora quality', 'pos': [17, 19]}, 't': {'name': 'parallel corpora', 'pos': [2, 4]}, 'relation': 'model-feature'}
{'token': ['method', 'takes', 'consideration', 'slight', 'differences', 'source', 'documents', ',', 'different', 'levels', 'segmentation', 'input', 'corpora', ',', 'encoding', 'differences', 'aspects', 'task', '.'], 'h': {'name': 'segmentation', 'pos': [10, 11]}, 't': {'name': 'input corpora', 'pos': [11, 13]}, 'relation': 'usage'}
{'token': ['first', 'experiment', ',', 'Estonian', '-', 'English', 'part', 'JRC', '-', 'Acquis', 'corpus', 'combined', 'another', 'corpus', 'legislation', 'texts', '.'], 'h': {'name': 'Estonian-English', 'pos': [3, 6]}, 't': {'name': 'JRC-Acquis corpus', 'pos': [7, 11]}, 'relation': 'part_whole'}
{'token': ['first', 'experiment', ',', 'Estonian', '-', 'English', 'part', 'JRC', '-', 'Acquis', 'corpus', 'combined', 'another', 'corpus', 'legislation', 'texts', '.'], 'h': {'name': 'legislation texts', 'pos': [14, 16]}, 't': {'name': 'corpus', 'pos': [13, 14]}, 'relation': 'part_whole'}
{'token': ['generation', 'module', 'supports', 'seamless', 'integration', 'full', 'grammar', 'rules', ',', 'templates', 'canned', 'text', '.'], 'h': {'name': 'grammar rules', 'pos': [6, 8]}, 't': {'name': 'generation module', 'pos': [0, 2]}, 'relation': 'usage'}
{'token': ['Ambiguity', 'fundamental', 'property', 'natural', 'language'], 'h': {'name': 'Ambiguity', 'pos': [0, 1]}, 't': {'name': 'natural language', 'pos': [3, 5]}, 'relation': 'model-feature'}
{'token': ['Perhaps', ',', 'burdensome', 'case', 'ambiguity', 'manifests', 'syntactic', 'level', 'analysis', '.'], 'h': {'name': 'ambiguity', 'pos': [4, 5]}, 't': {'name': 'syntactic level of analysis', 'pos': [6, 9]}, 'relation': 'model-feature'}
{'token': ['presented', 'methods', 'based', 'language', 'specific', 'features', 'synthetical', 'languages', 'improve', 'results', 'simple', 'stochastic', 'approaches', '.'], 'h': {'name': 'language specific features', 'pos': [3, 6]}, 't': {'name': 'synthetical languages', 'pos': [6, 8]}, 'relation': 'model-feature'}
{'token': ['texts', 'English', 'Czech', '.'], 'h': {'name': 'texts', 'pos': [0, 1]}, 't': {'name': 'English', 'pos': [1, 2]}, 'relation': 'model-feature'}
{'token': ['paper', 'presents', 'techniques', 'multimedia', 'annotation', 'application', 'video', 'summarization', 'translation', '.'], 'h': {'name': 'multimedia annotation', 'pos': [3, 5]}, 't': {'name': 'video summarization and translation', 'pos': [6, 9]}, 'relation': 'usage'}
{'token': ['video', 'scene', 'description', 'consists', 'semi-automatically', 'detected', 'keyframes', 'scene', 'video', 'clip', 'time', 'codes', 'scenes', '.'], 'h': {'name': 'semi-automatically detected keyframes', 'pos': [4, 7]}, 't': {'name': 'video scene description', 'pos': [0, 3]}, 'relation': 'part_whole'}
{'token': ['text', 'data', 'multimedia', 'annotation', 'syntactically', 'semantically', 'structured', 'using', 'linguistic', 'annotation', '.'], 'h': {'name': 'text data', 'pos': [0, 2]}, 't': {'name': 'syntactically and semantically structured', 'pos': [4, 7]}, 'relation': 'model-feature'}
{'token': ['proposed', 'multimedia', 'summarization', 'works', 'upon', 'multimodal', 'document', 'consists', 'video', ',', 'keyframes', 'scenes', ',', 'transcripts', 'scenes', '.'], 'h': {'name': ' multimedia summarization', 'pos': [1, 3]}, 't': {'name': 'multimodal document', 'pos': [5, 7]}, 'relation': 'usage'}
{'token': ['multimedia', 'translation', 'automatically', 'generates', 'several', 'versions', 'multimedia', 'content', 'different', 'languages', '.'], 'h': {'name': 'languages', 'pos': [9, 10]}, 't': {'name': 'multimedia content', 'pos': [6, 8]}, 'relation': 'model-feature'}
{'token': ['machine', 'translation', '(', 'MT', ')', 'knowledge', 'automatically', 'constructed', 'bilingual', 'corpora', ',', 'redundant', 'rules', 'acquired', 'due', 'translation', 'variety', '.'], 'h': {'name': 'bilingual corpora', 'pos': [8, 10]}, 't': {'name': 'machine translation (MT) knowledge', 'pos': [0, 6]}, 'relation': 'usage'}
{'token': ['rules', 'increase', 'ambiguity', 'cause', 'incorrect', 'MT', 'results', '.'], 'h': {'name': 'rules', 'pos': [0, 1]}, 't': {'name': 'ambiguity', 'pos': [2, 3]}, 'relation': 'result'}
{'token': ['overcome', 'problem', ',', 'constrain', 'sentences', 'used', 'knowledge', 'extraction', '"', 'appropriate', 'bilingual', 'sentences', 'MT', '"', '.'], 'h': {'name': 'sentences', 'pos': [4, 5]}, 't': {'name': 'knowledge extraction', 'pos': [6, 8]}, 'relation': 'usage'}
{'token': ['overcome', 'problem', ',', 'constrain', 'sentences', 'used', 'knowledge', 'extraction', '"', 'appropriate', 'bilingual', 'sentences', 'MT', '"', '.'], 'h': {'name': 'bilingual sentences', 'pos': [10, 12]}, 't': {'name': 'MT', 'pos': [12, 13]}, 'relation': 'usage'}
{'token': ['creation', 'scholarly', 'digital', 'editions', 'AAC', 'edition', 'philosophy', 'edition', 'principles', 'applied', 'whereby', 'new', 'corpus', 'research', 'methods', 'made', 'use', 'questions', 'computational', 'philology', 'textual', 'studies', 'digital', 'environment', '.'], 'h': {'name': 'AAC edition philosophy and edition principles', 'pos': [4, 9]}, 't': {'name': 'scholarly digital editions', 'pos': [1, 4]}, 'relation': 'usage'}
{'token': ['evaluation', 'results', 'show', 'system', 'achieve', 'F', 'measure', '0.9400.967', 'different', 'testing', 'corpora', '.'], 'h': {'name': 'system', 'pos': [3, 4]}, 't': {'name': 'F measure', 'pos': [5, 7]}, 'relation': 'result'}
{'token': ['paper', ',', 'propose', 'machine', 'learning', 'algorithm', 'shallow', 'semantic', 'parsing', ',', 'extending', 'work', 'Gildea', 'Jurafsky', '(', '2002', ')', ',', 'Surdeanu', 'et', 'al.', '(', '2003', ')', 'others', '.'], 'h': {'name': 'machine learning algorithm', 'pos': [3, 6]}, 't': {'name': 'shallow semantic parsing', 'pos': [6, 9]}, 'relation': 'usage'}
{'token': ['algorithm', 'based', 'Support', 'Vector', 'Machines', 'show', 'give', 'improvement', 'performance', 'earlier', 'classifiers', '.'], 'h': {'name': 'Support Vector Machines', 'pos': [2, 5]}, 't': {'name': 'algorithm', 'pos': [0, 1]}, 'relation': 'usage'}
{'token': ['show', 'performance', 'improvements', 'number', 'new', 'features', 'measure', 'ability', 'generalize', 'new', 'test', 'set', 'drawn', 'AQUAINT', 'corpus', '.'], 'h': {'name': 'test set', 'pos': [10, 12]}, 't': {'name': 'AQUAINT corpus', 'pos': [13, 15]}, 'relation': 'part_whole'}
{'token': ['Many', 'kinds', 'language', 'model', 'used', 'speech', 'understanding', 'suffer', 'imperfect', 'modeling', 'intra-sentential', 'contextual', 'influences', '.'], 'h': {'name': 'language model', 'pos': [2, 4]}, 't': {'name': 'speech understanding', 'pos': [5, 7]}, 'relation': 'usage'}
{'token': ['argue', 'problem', 'addressed', 'clustering', 'sentences', 'training', 'corpus', 'automatically', 'sub', 'corpora', 'criterion', 'entropy', 'reduction', ',', 'calculating', 'separate', 'language', 'model', 'parameters', 'cluster', '.'], 'h': {'name': 'sentences', 'pos': [4, 5]}, 't': {'name': 'training corpus', 'pos': [5, 7]}, 'relation': 'part_whole'}
{'token': ['kind', 'clustering', 'offers', 'way', 'represent', 'important', 'contextual', 'effects', 'therefore', 'significantly', 'improve', 'performance', 'model', '.'], 'h': {'name': 'clustering', 'pos': [1, 2]}, 't': {'name': 'contextual effects', 'pos': [6, 8]}, 'relation': 'model-feature'}
{'token': ['also', 'offers', 'reasonably', 'automatic', 'means', 'gather', 'evidence', 'whether', 'complex', ',', 'context', '-', 'sensitive', 'model', 'using', 'general', 'kind', 'linguistic', 'information', 'likely', 'reward', 'effort', 'would', 'required', 'develop', ':', 'clustering', 'improves', 'performance', 'model', ',', 'proves', 'existence', 'context', 'dependencies', ',', 'exploited', 'unclustered', 'model', '.'], 'h': {'name': 'clustering', 'pos': [26, 27]}, 't': {'name': 'model', 'pos': [29, 30]}, 'relation': 'result'}
{'token': ['evidence', 'claims', ',', 'present', 'results', 'showing', 'clustering', 'improves', 'models', 'others', 'ATIS', 'domain', '.'], 'h': {'name': 'clustering', 'pos': [6, 7]}, 't': {'name': 'models', 'pos': [8, 9]}, 'relation': 'result'}
{'token': ['paper', 'presents', 'parsing', 'system', 'detection', 'syntactic', 'errors', '.'], 'h': {'name': 'parsing system', 'pos': [2, 4]}, 't': {'name': 'detection of syntactic errors', 'pos': [4, 7]}, 'relation': 'usage'}
{'token': ['combines', 'robust', 'partial', 'parser', 'obtains', 'main', 'sentence', 'components', 'finite', '-', 'state', 'parser', 'used', 'description', 'syntactic', 'error', 'patterns', '.'], 'h': {'name': 'finite-state parser', 'pos': [8, 12]}, 't': {'name': 'syntactic error patterns', 'pos': [14, 17]}, 'relation': 'usage'}
{'token': ['system', 'tested', 'corpus', 'real', 'texts', ',', 'containing', 'correct', 'incorrect', 'sentences', ',', 'promising', 'results', '.'], 'h': {'name': 'texts', 'pos': [4, 5]}, 't': {'name': 'corpus', 'pos': [2, 3]}, 'relation': 'part_whole'}
{'token': ['objectives', 'project', 'advance', 'understanding', 'merits', 'current', 'text', 'analysis', 'techniques', ',', 'applied', 'performance', 'realistic', 'text', 'analysis', 'tasks', ',', 'achieve', 'understanding', 'means', 'sound', 'performance', 'evaluation', 'methodology', '.'], 'h': {'name': 'text analysis techniques', 'pos': [6, 9]}, 't': {'name': 'realistic text analysis tasks', 'pos': [12, 16]}, 'relation': 'usage'}
{'token': ['Talk', "'n", "'", 'Travel', 'fully', 'conversational', ',', 'mixed', '-', 'initiative', 'system', 'allows', 'user', 'specify', 'constraints', 'travel', 'plan', 'arbitrary', 'order', ',', 'ask', 'questions', ',', 'etc.', ',', 'general', 'spoken', 'English', '.'], 'h': {'name': 'general spoken English', 'pos': [25, 28]}, 't': {'name': 'questions', 'pos': [21, 22]}, 'relation': 'model-feature'}
{'token': ['system', 'operates', 'according', 'plan', '-', 'based', 'agenda', 'mechanism', ',', 'rather', 'finite', 'state', 'network', ',', 'attempts', 'negotiate', 'user', 'constraints', 'met', '.'], 'h': {'name': 'plan-based agenda mechanism', 'pos': [3, 8]}, 't': {'name': 'system', 'pos': [0, 1]}, 'relation': 'usage'}
{'token': ['mentioned', 'Mitkov', '(', '1996', ')', ',', 'solving', 'anaphora', 'extracting', 'antecedent', 'key', 'issues', 'correct', 'translation', '.'], 'h': {'name': 'anaphora', 'pos': [7, 8]}, 't': {'name': 'translation', 'pos': [13, 14]}, 'relation': 'part_whole'}
{'token': ['SS', 'stores', 'lexical', ',', 'syntactic', ',', 'morphologic', 'semantic', 'information', 'every', 'constituent', 'grammar', '.'], 'h': {'name': 'lexical, syntactic, morphologic and semantic information', 'pos': [2, 9]}, 't': {'name': 'constituent', 'pos': [10, 11]}, 'relation': 'model-feature'}
{'token': ['mechanism', 'could', 'added', 'MT', 'system', 'additional', 'module', 'solve', 'anaphora', 'generation', 'problem', '.'], 'h': {'name': 'mechanism', 'pos': [0, 1]}, 't': {'name': 'MT system', 'pos': [3, 5]}, 'relation': 'usage'}
{'token': ['paper', 'addresses', 'language', 'engineering', 'infrastructure', 'issues', 'considering', 'whether', 'standard', 'V&amp', ';', 'V', 'methods', 'fundamentally', 'different', 'evaluation', 'practices', 'commonly', 'used', 'NLP', 'systems', ',', 'proposes', 'practical', 'approaches', 'applying', 'V&amp', ';', 'V', 'context', 'language', 'processing', 'systems', '.'], 'h': {'name': 'standard V&amp;V methods', 'pos': [8, 13]}, 't': {'name': 'evaluation practices', 'pos': [15, 17]}, 'relation': 'compare'}
{'token': ['paper', 'addresses', 'language', 'engineering', 'infrastructure', 'issues', 'considering', 'whether', 'standard', 'V&amp', ';', 'V', 'methods', 'fundamentally', 'different', 'evaluation', 'practices', 'commonly', 'used', 'NLP', 'systems', ',', 'proposes', 'practical', 'approaches', 'applying', 'V&amp', ';', 'V', 'context', 'language', 'processing', 'systems', '.'], 'h': {'name': 'V&amp;V', 'pos': [26, 29]}, 't': {'name': 'language processing systems', 'pos': [30, 33]}, 'relation': 'usage'}
{'token': ['paper', ',', 'propose', 'practical', 'approach', 'extracting', 'relevant', 'paragraphs', 'original', 'document', 'form', 'summary', 'Thai', 'text', '.'], 'h': {'name': 'paragraphs', 'pos': [7, 8]}, 't': {'name': 'document', 'pos': [9, 10]}, 'relation': 'part_whole'}
{'token': ['paper', ',', 'propose', 'practical', 'approach', 'extracting', 'relevant', 'paragraphs', 'original', 'document', 'form', 'summary', 'Thai', 'text', '.'], 'h': {'name': 'summary', 'pos': [11, 12]}, 't': {'name': 'Thai text', 'pos': [12, 14]}, 'relation': 'model-feature'}
{'token': ['idea', 'approach', 'exploit', 'local', 'global', 'properties', 'paragraphs', '.'], 'h': {'name': 'local and global properties', 'pos': [3, 6]}, 't': {'name': 'paragraphs', 'pos': [6, 7]}, 'relation': 'model-feature'}
{'token': ['local', 'property', 'considered', 'clusters', 'significant', 'words', 'within', 'paragraph', ',', 'global', 'property', 'thought', 'relations', 'paragraphs', 'document', '.'], 'h': {'name': 'clusters', 'pos': [3, 4]}, 't': {'name': 'significant words', 'pos': [4, 6]}, 'relation': 'model-feature'}
{'token': ['Syntax', '-', 'based', 'Machine', 'Translation', 'systems', 'recently', 'become', 'focus', 'research', 'much', 'hope', 'outperform', 'traditional', 'Phrase', '-', 'Based', 'Statistical', 'Machine', 'Translation', '(', 'PBSMT', ')'], 'h': {'name': 'Syntax-based Machine Translation systems', 'pos': [0, 6]}, 't': {'name': 'traditional Phrase- Based Statistical Machine Translation (PBSMT)', 'pos': [13, 23]}, 'relation': 'compare'}
{'token': ['Toward', 'goal', ',', 'present', 'method', 'analyzing', 'morphosyntactic', 'content', 'language', 'Elicitation', 'Corpus', 'one', 'included', 'LDC', "'s", 'upcoming', 'LCTL', 'language', 'packs', '.'], 'h': {'name': 'morphosyntactic content', 'pos': [6, 8]}, 't': {'name': 'Elicitation Corpus', 'pos': [9, 11]}, 'relation': 'part_whole'}
{'token': ['providing', 'tool', 'augment', 'structure', '-', 'based', 'MT', 'models', 'rich', 'features', ',', 'believe', 'discriminative', 'power', 'current', 'models', 'improved', '.'], 'h': {'name': 'rich features', 'pos': [8, 10]}, 't': {'name': 'structure-based MT models', 'pos': [3, 8]}, 'relation': 'usage'}
{'token': ['article', 'outlines', 'quantitative', 'method', 'segmenting', 'texts', 'thematically', 'coherent', 'units', '.'], 'h': {'name': 'quantitative method', 'pos': [2, 4]}, 't': {'name': 'texts', 'pos': [5, 6]}, 'relation': 'usage'}
{'token': ['method', 'relies', 'network', 'lexical', 'collocations', 'compute', 'thematic', 'coherence', 'different', 'parts', 'text', 'lexical', 'cohesiveness', 'words', '.'], 'h': {'name': 'network of lexical collocations', 'pos': [2, 5]}, 't': {'name': 'method', 'pos': [0, 1]}, 'relation': 'usage'}
{'token': ['method', 'relies', 'network', 'lexical', 'collocations', 'compute', 'thematic', 'coherence', 'different', 'parts', 'text', 'lexical', 'cohesiveness', 'words', '.'], 'h': {'name': 'lexical cohesiveness', 'pos': [11, 13]}, 't': {'name': 'words', 'pos': [13, 14]}, 'relation': 'model-feature'}
{'token': ['also', 'present', 'results', 'experiment', 'locating', 'boundaries', 'series', 'concatened', 'texts', '.'], 'h': {'name': 'boundaries', 'pos': [5, 6]}, 't': {'name': 'texts', 'pos': [8, 9]}, 'relation': 'part_whole'}
{'token': ['work', ',', 'introduce', 'model', 'sense', 'assignment', 'relies', 'assigning', 'senses', 'contexts', 'within', 'words', 'appear', ',', 'rather', 'words', '.'], 'h': {'name': 'model', 'pos': [3, 4]}, 't': {'name': 'sense assignment', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['work', ',', 'introduce', 'model', 'sense', 'assignment', 'relies', 'assigning', 'senses', 'contexts', 'within', 'words', 'appear', ',', 'rather', 'words', '.'], 'h': {'name': 'words', 'pos': [11, 12]}, 't': {'name': 'contexts', 'pos': [9, 10]}, 'relation': 'model-feature'}
{'token': ['paper', 'describe', 'morphological', 'analysis', 'method', 'based', 'maximum', 'entropy', 'model', '.'], 'h': {'name': 'maximum entropy model', 'pos': [6, 9]}, 't': {'name': 'morphological analysis method', 'pos': [2, 5]}, 'relation': 'usage'}
{'token': ['method', 'uses', 'model', 'consult', 'dictionary', 'large', 'amount', 'lexical', 'information', 'also', 'identify', 'unknown', 'words', 'learning', 'certain', 'characteristics', '.'], 'h': {'name': 'model', 'pos': [2, 3]}, 't': {'name': 'method', 'pos': [0, 1]}, 'relation': 'usage'}
{'token': ['method', 'uses', 'model', 'consult', 'dictionary', 'large', 'amount', 'lexical', 'information', 'also', 'identify', 'unknown', 'words', 'learning', 'certain', 'characteristics', '.'], 'h': {'name': 'lexical information', 'pos': [7, 9]}, 't': {'name': 'dictionary', 'pos': [4, 5]}, 'relation': 'part_whole'}
{'token': ['method', 'uses', 'model', 'consult', 'dictionary', 'large', 'amount', 'lexical', 'information', 'also', 'identify', 'unknown', 'words', 'learning', 'certain', 'characteristics', '.'], 'h': {'name': 'characteristics', 'pos': [15, 16]}, 't': {'name': 'unknown words', 'pos': [11, 13]}, 'relation': 'model-feature'}
{'token': ['Finally', ',', 'present', 'Corporator', ',', 'Open', 'Source', 'software', 'designed', 'collecting', 'corpus', 'RSS', 'feeds', '.'], 'h': {'name': 'corpus', 'pos': [10, 11]}, 't': {'name': 'RSS feeds', 'pos': [11, 13]}, 'relation': 'part_whole'}
{'token': ['Several', 'SVMs', 'trained', 'using', 'information', 'pyramids', 'summary', 'content', 'units', '.'], 'h': {'name': 'summary content units', 'pos': [6, 9]}, 't': {'name': 'SVMs', 'pos': [1, 2]}, 'relation': 'usage'}
{'token': ['performance', 'compared', 'best', 'performing', 'systems', 'DUC-2005', ',', 'using', 'both', 'and', 'Pan', ',', 'an', 'scoring', 'method', 'for', 'evaluation', '.'], 'h': {'name': 'performance', 'pos': [0, 1]}, 't': {'name': 'DUC-2005', 'pos': [5, 6]}, 'relation': 'compare'}
{'token': ['performance', 'compared', 'best', 'performing', 'systems', 'DUC-2005', ',', 'using', 'both', 'ROUGE', 'auto', ',', 'an', 'scoring', 'method', 'for', 'evaluation', '.'], 'h': {'name': 'automatic scoring method', 'pos': [13, 15]}, 't': {'name': 'pyramid evaluation', 'pos': [16, 17]}, 'relation': 'usage'}
{'token': ['present', 'novel', 'unsupervised', 'method', 'sentence', 'compression', 'relies', 'dependency', 'tree', 'representation', 'shortens', 'sentences', 'removing', 'subtrees', '.'], 'h': {'name': 'unsupervised method', 'pos': [2, 4]}, 't': {'name': 'sentence compression', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['demonstrate', 'choice', 'parser', 'affects', 'performance', 'system', '.'], 'h': {'name': 'parser', 'pos': [2, 3]}, 't': {'name': 'performance', 'pos': [4, 5]}, 'relation': 'result'}
{'token': ['also', 'apply', 'method', 'German', 'report', 'results', 'evaluation', 'humans', '.'], 'h': {'name': 'method', 'pos': [2, 3]}, 't': {'name': 'German', 'pos': [3, 4]}, 'relation': 'usage'}
{'token': ['approach', 'even', 'outperformed', 'hand', 'coded', 'system', 'NER', 'Spanish', ',', 'achieved', 'high', 'accuracies', 'Portuguese', '.'], 'h': {'name': 'NER', 'pos': [6, 7]}, 't': {'name': 'Spanish', 'pos': [7, 8]}, 'relation': 'usage'}
{'token': ['karaka', 'based', 'approach', 'parsing', 'Indian', 'languages', 'described', '.'], 'h': {'name': 'parsing', 'pos': [3, 4]}, 't': {'name': 'Indian languages', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['used', 'building', 'parser', 'Hindi', 'prototype', 'Machine', 'Translation', 'system', '.'], 'h': {'name': 'parser', 'pos': [2, 3]}, 't': {'name': 'Hindi', 'pos': [3, 4]}, 'relation': 'usage'}
{'token': ['paper', 'presents', 'work', 'detection', 'temporal', 'information', 'web', 'pages', '.'], 'h': {'name': 'detection', 'pos': [3, 4]}, 't': {'name': 'web pages', 'pos': [6, 8]}, 'relation': 'usage'}
{'token': ['pages', 'examined', 'within', 'scope', 'study', 'taken', 'tourism', 'sector', 'temporal', 'information', 'question', 'thus', 'particular', 'area', '.'], 'h': {'name': 'temporal information', 'pos': [8, 10]}, 't': {'name': 'pages', 'pos': [0, 1]}, 'relation': 'part_whole'}
{'token': ['differences', 'exist', 'extraction', 'plain', 'textual', 'data', 'extraction', 'web', 'brought', 'light', '.'], 'h': {'name': 'extraction', 'pos': [2, 3]}, 't': {'name': 'plain textual data', 'pos': [3, 6]}, 'relation': 'usage'}
{'token': ['adopt', 'symbolic', 'approach', 'relying', 'patterns', 'rules', 'detection', ',', 'extraction', 'annotation', 'temporal', 'expressions', ';', 'method', 'based', 'use', 'transducers', '.'], 'h': {'name': 'patterns', 'pos': [4, 5]}, 't': {'name': 'symbolic approach', 'pos': [1, 3]}, 'relation': 'usage'}
{'token': ['adopt', 'symbolic', 'approach', 'relying', 'patterns', 'rules', 'detection', ',', 'extraction', 'annotation', 'temporal', 'expressions', ';', 'method', 'based', 'use', 'transducers', '.'], 'h': {'name': 'rules', 'pos': [5, 6]}, 't': {'name': 'detection', 'pos': [6, 7]}, 'relation': 'usage'}
{'token': ['adopt', 'symbolic', 'approach', 'relying', 'patterns', 'rules', 'detection', ',', 'extraction', 'annotation', 'temporal', 'expressions', ';', 'method', 'based', 'use', 'transducers', '.'], 'h': {'name': 'annotation', 'pos': [9, 10]}, 't': {'name': 'temporal expressions', 'pos': [10, 12]}, 'relation': 'usage'}
{'token': ['first', 'release', 'German', 'Ph@ttSessionz', 'speech', 'database', 'contains', 'read', 'spontaneous', 'speech', '864', 'adolescent', 'speakers', 'largest', 'database', 'kind', 'German', '.'], 'h': {'name': 'read and spontaneous speech', 'pos': [7, 10]}, 't': {'name': 'German Ph@ttSessionz speech database', 'pos': [2, 6]}, 'relation': 'part_whole'}
{'token': ['paper', ',', 'present', 'cross', '-sectional', 'study', 'of', 'f0', 'measurements', 'on', '.'], 'h': {'name': 'cross-sectional study', 'pos': [3, 6]}, 't': {'name': 'f0 measurements', 'pos': [7, 9]}, 'relation': 'topic'}
{'token': ['Furthermore', ',', 'shows', 'perceptive', 'mel-scale', ',', 'little', 'difference', 'relative', 'f0', 'variability', 'male', 'female', 'speakers', '.'], 'h': {'name': 'relative f0 variability', 'pos': [8, 11]}, 't': {'name': 'male and female speakers', 'pos': [11, 14]}, 'relation': 'model-feature'}
{'token': ['study', 'provides', 'statistically', 'reliable', 'voice', 'parameters', 'adolescent', 'speakers', 'German', '.'], 'h': {'name': 'voice parameters', 'pos': [4, 6]}, 't': {'name': 'adolescent speakers', 'pos': [6, 8]}, 'relation': 'model-feature'}
{'token': ['results', 'may', 'contribute', 'making', 'spoken', 'dialog', 'systems', 'robust', 'restricting', 'user', 'input', 'utterances', 'low', 'f0', 'variability', '.'], 'h': {'name': 'utterances', 'pos': [11, 12]}, 't': {'name': 'user input', 'pos': [9, 11]}, 'relation': 'part_whole'}
{'token': ['platform', 'support', 'researchers', 'engineers', 'well', '-', 'developed', 'standardized', 'resources', 'application', 'tools', 'thereby', 'avoiding', 'duplicate', 'activities', 'scratch', 'amplifying', 'overall', 'effort', 'domain', '.'], 'h': {'name': 'standardized resources', 'pos': [7, 9]}, 't': {'name': 'platform', 'pos': [0, 1]}, 'relation': 'usage'}
{'token': ['present', 'article', ',', 'part', 'aspectual', 'operation', 'system', ',', 'generation', 'system', 'iterative', 'expressions', 'using', 'set', 'operators', 'called', 'iterative', 'operators', '.'], 'h': {'name': 'generation system', 'pos': [8, 10]}, 't': {'name': 'aspectual operation system', 'pos': [4, 7]}, 'relation': 'part_whole'}
{'token': ['classification', 'carried', 'especially', 'consideration', 'durative', '/', 'non-durative', 'character', 'denoted', 'events', 'also', 'consideration', 'existence', '/', 'non-existence', 'culmination', 'point', '(', 'boundary', ')', 'events', '.'], 'h': {'name': 'durative / non-durative character', 'pos': [4, 8]}, 't': {'name': 'events', 'pos': [9, 10]}, 'relation': 'model-feature'}
{'token': ['paper', ',', 'show', 'time', '-', 'synchronous', 'one', '-', 'pass', 'decoding', 'using', 'cross', '-', 'word', 'triphones', 'trigram', 'language', 'model', 'implemented', 'using', 'dynamically', 'built', 'tree', '-', 'structured', 'network', '.'], 'h': {'name': 'cross-word triphones', 'pos': [11, 15]}, 't': {'name': 'time-synchronous one-pass decoding', 'pos': [3, 10]}, 'relation': 'usage'}
{'token': ['paper', ',', 'show', 'time', '-', 'synchronous', 'one', '-', 'pass', 'decoding', 'using', 'cross', '-', 'word', 'triphones', 'trigram', 'language', 'model', 'implemented', 'using', 'dynamically', 'built', 'tree', '-', 'structured', 'network', '.'], 'h': {'name': 'tree-structured network', 'pos': [22, 26]}, 't': {'name': 'trigram language model', 'pos': [15, 18]}, 'relation': 'usage'}
{'token': ['included', 'HTK', 'large', 'vocabulary', 'speech', 'recognition', 'system', 'used', '1993', 'ARPA', 'WSJ', 'evaluation', 'experimental', 'results', 'presented', 'task', '.'], 'h': {'name': 'HTK large vocabulary speech recognition system', 'pos': [1, 7]}, 't': {'name': '1993 ARPA WSJ evaluation', 'pos': [8, 12]}, 'relation': 'usage'}
{'token': ['Traditionally', ',', 'statistical', 'machine', 'translation', 'systems', 'relied', 'parallel', 'bi-lingual', 'data', 'train', 'translation', 'model', '.'], 'h': {'name': 'parallel bi-lingual data', 'pos': [7, 10]}, 't': {'name': 'statistical machine translation systems', 'pos': [2, 6]}, 'relation': 'usage'}
{'token': ['bi-lingual', 'parallel', 'data', 'expensive', 'generate', ',', 'monolingual', 'data', 'relatively', 'common', '.'], 'h': {'name': 'bi-lingual parallel data', 'pos': [0, 3]}, 't': {'name': 'monolingual data', 'pos': [6, 8]}, 'relation': 'compare'}
{'token': ['Yet', 'monolingual', 'data', 'under-utilized', ',', 'used', 'primarily', 'training', 'language', 'model', 'target', 'language', '.'], 'h': {'name': 'monolingual data', 'pos': [1, 3]}, 't': {'name': 'language model', 'pos': [8, 10]}, 'relation': 'usage'}
{'token': ['paper', 'describes', 'novel', 'method', 'utilizing', 'monolingual', 'target', 'data', 'improve', 'performance', 'statistical', 'machine', 'translation', 'system', 'news', 'stories', '.'], 'h': {'name': 'monolingual target data', 'pos': [5, 8]}, 't': {'name': 'statistical machine translation system', 'pos': [10, 14]}, 'relation': 'usage'}
{'token': ['every', 'source', 'document', 'translated', ',', 'large', 'monolingual', 'data', 'set', 'target', 'language', 'searched', 'documents', 'might', 'comparable', 'source', 'documents', '.'], 'h': {'name': 'documents', 'pos': [12, 13]}, 't': {'name': 'source documents', 'pos': [15, 17]}, 'relation': 'compare'}
{'token': ['documents', 'used', 'adapt', 'MT', 'system', 'increase', 'probability', 'generating', 'texts', 'resemble', 'comparable', 'document', '.'], 'h': {'name': 'documents', 'pos': [0, 1]}, 't': {'name': 'MT system', 'pos': [3, 5]}, 'relation': 'usage'}
{'token': ['Experimental', 'results', 'obtained', 'adapting', 'language', 'translation', 'models', 'show', 'substantial', 'gains', 'baseline', 'system', '.'], 'h': {'name': 'language and translation models', 'pos': [4, 7]}, 't': {'name': 'baseline system', 'pos': [10, 12]}, 'relation': 'compare'}
{'token': ['paper', 'describes', 'unsupervised', 'knowledge', '-', 'lean', 'methodology', 'automatically', 'determining', 'number', 'senses', 'ambiguous', 'word', 'used', 'large', 'corpus', '.'], 'h': {'name': 'ambiguous word', 'pos': [11, 13]}, 't': {'name': 'corpus', 'pos': [15, 16]}, 'relation': 'part_whole'}
{'token': ['paper', 'describes', 'Unisys', 'MUC', '-', '3', 'text', 'understanding', 'system', ',', 'system', 'based', 'upon', 'three', '-', 'tiered', 'approach', 'text', 'processing', 'powerful', 'knowledge', '-', 'based', 'form', 'information', 'retrieval', 'plays', 'central', 'role', '.'], 'h': {'name': 'three-tiered approach', 'pos': [13, 17]}, 't': {'name': 'system', 'pos': [10, 11]}, 'relation': 'usage'}
{'token': ['decision', 'made', 'focus', 'development', 'knowledge', '-', 'based', 'information', 'retrieval', 'component', ',', 'precluded', 'integration', 'Pundit', 'prototype', '.'], 'h': {'name': 'Pundit', 'pos': [13, 14]}, 't': {'name': 'prototype', 'pos': [14, 15]}, 'relation': 'part_whole'}
{'token': ['ARBITER', 'Prolog', 'program', 'extracts', 'assertions', 'macromolecular', 'binding', 'relationships', 'biomedical', 'text', '.'], 'h': {'name': 'macromolecular binding relationships', 'pos': [5, 8]}, 't': {'name': 'biomedical text', 'pos': [8, 10]}, 'relation': 'part_whole'}
{'token': ['discussing', 'formal', 'evaluation', 'ARBITER', ',', 'report', 'application', '491,000', 'MEDLINE', 'abstracts', ',', 'almost', '25,000', 'binding', 'relationships', 'suitable', 'entry', 'database', 'macro-molecular', 'function', 'extracted', '.'], 'h': {'name': 'ARBITER', 'pos': [3, 4]}, 't': {'name': 'MEDLINE abstracts', 'pos': [8, 10]}, 'relation': 'usage'}
{'token': ['discussing', 'formal', 'evaluation', 'ARBITER', ',', 'report', 'application', '491,000', 'MEDLINE', 'abstracts', ',', 'almost', '25,000', 'binding', 'relationships', 'suitable', 'entry', 'database', 'macro-molecular', 'function', 'extracted', '.'], 'h': {'name': 'macro-molecular function', 'pos': [18, 20]}, 't': {'name': 'database', 'pos': [17, 18]}, 'relation': 'part_whole'}
{'token': ['resolution', 'lexical', 'ambiguity', 'important', 'natural', 'language', 'processing', 'tasks', ',', 'range', 'computational', 'techniques', 'proposed', 'solution', '.'], 'h': {'name': 'lexical ambiguity', 'pos': [1, 3]}, 't': {'name': 'natural language processing tasks', 'pos': [4, 8]}, 'relation': 'part_whole'}
{'token': ['paper', ',', 'describe', 'method', 'lexical', 'disambiguation', 'text', 'using', 'definitions', 'machine', '-', 'readable', 'dictionary', 'together', 'technique', 'simulated', 'annealing', '.'], 'h': {'name': 'definitions', 'pos': [8, 9]}, 't': {'name': 'lexical disambiguation', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['initial', 'results', 'sample', 'set', '50', 'sentences', 'comparable', 'researchers', ',', 'fully', 'automatic', 'method', 'requires', 'hand', 'coding', 'lexical', 'entries', ',', 'hand', 'tagging', 'text', '.'], 'h': {'name': 'hand coding', 'pos': [13, 15]}, 't': {'name': 'lexical entries', 'pos': [15, 17]}, 'relation': 'usage'}
{'token': ['initial', 'results', 'sample', 'set', '50', 'sentences', 'comparable', 'researchers', ',', 'fully', 'automatic', 'method', 'requires', 'hand', 'coding', 'lexical', 'entries', ',', 'hand', 'tagging', 'text', '.'], 'h': {'name': 'hand tagging', 'pos': [18, 20]}, 't': {'name': 'text', 'pos': [20, 21]}, 'relation': 'usage'}
{'token': ['date', ',', 'array', 'formal', 'natural', 'language', 'processing', 'technologies', 'used', 'perform', 'mass', 'changes', 'legacy', 'textual', 'databases', 'facilitate', 'user', 'interfacing', 'relational', 'databases', 'software', 'applications', '.'], 'h': {'name': 'formal and natural language processing technologies', 'pos': [3, 8]}, 't': {'name': 'legacy textual databases', 'pos': [12, 15]}, 'relation': 'usage'}
{'token': ['present', 'discourse', 'annotation', 'work', 'aimed', 'constructing', 'parallel', 'corpus', 'Rhetorical', 'Structure', 'trees', 'collection', 'Japanese', 'texts', 'corresponding', 'English', 'translations', '.'], 'h': {'name': 'Rhetorical Structure trees', 'pos': [8, 11]}, 't': {'name': 'parallel corpus', 'pos': [6, 8]}, 'relation': 'part_whole'}
{'token': ['approach', 'knowledge', 'representation', 'taken', 'multi-modal', 'multi-domain', 'dialogue', 'system', '-', 'SmartKom', '-', 'presented', '.'], 'h': {'name': 'knowledge representation', 'pos': [1, 3]}, 't': {'name': 'multi-modal multi-domain dialogue system - SmartKom -', 'pos': [4, 11]}, 'relation': 'usage'}
{'token': ['paper', 'presents', 'intial', 'work', 'system', 'bridges', 'robust', ',', 'broad', '-', 'coverage', 'natural', 'language', 'processing', 'precise', 'semantics', 'automated', 'reasoning', ',', 'focusing', 'solving', 'logic', 'puzzles', 'drawn', 'sources', 'Law', 'School', 'Admission', 'Test', '(', 'LSAT', ')', 'analytic', 'section', 'Graduate', 'Record', 'Exam', '(', 'GRE', ')', '.'], 'h': {'name': 'logic puzzles', 'pos': [21, 23]}, 't': {'name': 'Law School Admission Test (LSAT)', 'pos': [25, 32]}, 'relation': 'part_whole'}
{'token': ['highlight', 'key', 'challenges', ',', 'discuss', 'representations', 'performance', 'prototype', 'system', '.'], 'h': {'name': 'performance', 'pos': [6, 7]}, 't': {'name': 'prototype system', 'pos': [7, 9]}, 'relation': 'model-feature'}
{'token': ['paper', ',', 'new', 'parsing', 'model', 'proposed', 'formulate', 'complete', 'chunking', 'problem', 'series', 'boundary', 'detection', 'subtasks', '.'], 'h': {'name': 'chunking problem', 'pos': [8, 10]}, 't': {'name': 'parsing model', 'pos': [3, 5]}, 'relation': 'model-feature'}
{'token': ['applying', 'SVM', 'algorithm', 'subtasks', ',', 'achieved', 'best', 'F-', 'Score', 'of', '%', 'and', '%', 'respectively', '.'], 'h': {'name': 'SVM algorithm', 'pos': [1, 3]}, 't': {'name': 'F-Score', 'pos': [7, 9]}, 'relation': 'result'}
{'token': ['paper', ',', 'introduce', 'WordNet', '-', 'based', 'measure', 'semantic', 'relatedness', 'combining', 'structure', 'content', 'WordNet', 'co-occurrence', 'information', 'derived', 'raw', 'text', '.'], 'h': {'name': 'co-occurrence information', 'pos': [13, 15]}, 't': {'name': 'raw text', 'pos': [16, 18]}, 'relation': 'part_whole'}
{'token': ['use', 'co-occurrence', 'information', 'along', 'Word', 'Net', 'definitions', 'build', 'gloss', 'vectors', 'corresponding', 'concept', 'Word', 'Net', '.'], 'h': {'name': 'gloss vectors', 'pos': [8, 10]}, 't': {'name': 'concept', 'pos': [11, 12]}, 'relation': 'model-feature'}
{'token': ['Numeric', 'scores', 'relatedness', 'assigned', 'pair', 'concepts', 'measuring', 'cosine', 'angle', 'respective', 'gloss', 'vectors', '.'], 'h': {'name': 'Numeric scores of relatedness', 'pos': [0, 3]}, 't': {'name': 'concepts', 'pos': [5, 6]}, 'relation': 'model-feature'}
{'token': ['show', 'measure', 'compares', 'favorably', 'measures', 'respect', 'human', 'judgments', 'semantic', 'relatedness', ',', 'performs', 'well', 'used', 'word', 'sense', 'disambiguation', 'algorithm', 'relies', 'semantic', 'relatedness', '.'], 'h': {'name': 'semantic relatedness', 'pos': [19, 21]}, 't': {'name': 'word sense disambiguation algorithm', 'pos': [14, 18]}, 'relation': 'usage'}
{'token': ['addition', ',', 'adapted', 'different', 'domains', ',', 'since', 'plain', 'text', 'corpus', 'used', 'derive', 'co–occurrence', 'information', '.'], 'h': {'name': 'co–occurrence information', 'pos': [12, 14]}, 't': {'name': 'plain text corpus', 'pos': [7, 10]}, 'relation': 'part_whole'}
{'token': ['paper', 'describes', 'system', 'used', 'RTE3', 'task', '.'], 'h': {'name': 'system', 'pos': [2, 3]}, 't': {'name': 'RTE3 task', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['system', 'maps', 'premise', 'hypothesis', 'pairs', 'abstract', 'knowledge', 'representation', '(', 'AKR', ')', 'performs', 'entailment', 'contradiction', 'detection', '(', 'ecd', ')', 'resulting', 'AKRs', '.'], 'h': {'name': 'abstract knowledge representation (AKR)', 'pos': [5, 11]}, 't': {'name': 'premise and hypothesis pairs', 'pos': [2, 5]}, 'relation': 'model-feature'}
{'token': ['Two', 'versions', 'ECD', 'used', 'RTE3', ',', 'one', 'strict', 'ECD', 'one', 'looser', 'ECD', '.'], 'h': {'name': 'ECD', 'pos': [2, 3]}, 't': {'name': 'RTE3', 'pos': [4, 5]}, 'relation': 'usage'}
{'token': ['propose', 'new', 'language', 'learning', 'model', 'learns', 'syntactic-semantic', 'grammar', 'small', 'number', 'natural', 'language', 'strings', 'annotated', 'semantics', ',', 'along', 'basic', 'assumptions', 'natural', 'language', 'syntax', '.'], 'h': {'name': 'natural language strings', 'pos': [10, 13]}, 't': {'name': 'semantics', 'pos': [14, 15]}, 'relation': 'model-feature'}
{'token': ['paper', ',', 'propose', 'novel', 'graph', 'based', 'sentence', 'ranking', 'algorithm', ',', 'namely', 'PNR2', ',', 'update', 'summarization', '.'], 'h': {'name': 'graph based sentence ranking algorithm', 'pos': [4, 9]}, 't': {'name': 'update summarization', 'pos': [13, 15]}, 'relation': 'usage'}
{'token': ['paper', 'discusses', 'application', 'Expectation', '-', 'Maximization', '(', 'EM', ')', 'clustering', 'algorithm', 'task', 'Chinese', 'verb', 'sense', 'discrimination', '.'], 'h': {'name': 'Expectation-Maximization (EM) clustering algorithm', 'pos': [3, 11]}, 't': {'name': 'Chinese verb sense discrimination', 'pos': [12, 16]}, 'relation': 'usage'}
{'token': ['model', 'utilized', 'rich', 'linguistic', 'features', 'capture', 'predicate', '-', 'argument', 'structure', 'information', 'target', 'verbs', '.'], 'h': {'name': 'rich linguistic features', 'pos': [2, 5]}, 't': {'name': 'model', 'pos': [0, 1]}, 'relation': 'usage'}
{'token': ['model', 'utilized', 'rich', 'linguistic', 'features', 'capture', 'predicate', '-', 'argument', 'structure', 'information', 'target', 'verbs', '.'], 'h': {'name': 'predicate-argument structure information', 'pos': [6, 11]}, 't': {'name': 'target verbs', 'pos': [11, 13]}, 'relation': 'model-feature'}
{'token': ['semantic', 'taxonomy', 'Chinese', 'nouns', ',', 'built', 'semi-automatically', 'based', 'two', 'electronic', 'Chinese', 'semantic', 'dictionaries', ',', 'used', 'provide', 'semantic', 'features', 'model', '.'], 'h': {'name': 'semantic taxonomy', 'pos': [0, 2]}, 't': {'name': 'Chinese nouns', 'pos': [2, 4]}, 'relation': 'model-feature'}
{'token': ['semantic', 'taxonomy', 'Chinese', 'nouns', ',', 'built', 'semi-automatically', 'based', 'two', 'electronic', 'Chinese', 'semantic', 'dictionaries', ',', 'used', 'provide', 'semantic', 'features', 'model', '.'], 'h': {'name': 'semantic features', 'pos': [16, 18]}, 't': {'name': 'model', 'pos': [18, 19]}, 'relation': 'usage'}
{'token': ['enhanced', 'model', 'certain', 'fine', '-', 'grained', 'semantic', 'categories', 'called', 'lexical', 'sets', '.'], 'h': {'name': 'fine-grained semantic categories', 'pos': [3, 8]}, 't': {'name': 'model', 'pos': [1, 2]}, 'relation': 'usage'}
{'token': ['results', 'indicate', 'lexical', 'sets', 'improve', 'model', "'s", 'performance', 'three', 'challenging', 'verbs', 'chosen', 'first', 'set', 'experiments', '.'], 'h': {'name': 'lexical sets', 'pos': [2, 4]}, 't': {'name': 'model', 'pos': [5, 6]}, 'relation': 'result'}
{'token': ['paper', 'proposes', 'efficient', 'linguistic', 'processing', 'strategy', 'speech', 'recognition', 'understanding', 'using', 'dependency', 'structure', 'grammar', '.'], 'h': {'name': 'dependency structure grammar', 'pos': [10, 13]}, 't': {'name': 'speech recognition and understanding', 'pos': [6, 9]}, 'relation': 'usage'}
{'token': ['speech', 'processing', 'phrase', 'recognition', 'based', 'phoneme', 'recognition', ',', 'parser', 'extracts', 'sentence', 'best', 'likelihood', 'taking', 'account', 'phonetic', 'likelihood', 'phrase', 'candidates', 'linguistic', 'likelihood', 'semantic', 'inter-phrase', 'dependency', 'relationships', '.'], 'h': {'name': 'phoneme recognition', 'pos': [5, 7]}, 't': {'name': 'phrase recognition', 'pos': [2, 4]}, 'relation': 'usage'}
{'token': ['fast', 'parsing', 'algorithm', 'using', 'breadth-', 'first', 'search', 'is', 'proposed', '.'], 'h': {'name': 'breadth-first search', 'pos': [4, 7]}, 't': {'name': 'parsing algorithm', 'pos': [1, 3]}, 'relation': 'usage'}
{'token': ['predictor', 'pre-selects', 'phrase', 'candidates', 'using', 'transition', 'rules', 'combined', 'dependency', 'structure', 'reduce', 'amount', 'phonetic', 'processing', '.'], 'h': {'name': 'transition rules', 'pos': [5, 7]}, 't': {'name': 'predictor', 'pos': [0, 1]}, 'relation': 'usage'}
{'token': ['experimental', 'results', 'show', 'greatly', 'increases', 'accuracy', 'speech', 'recognitions', ',', 'breadth-', 'first', 'parsing', 'algorithm', 'and', 'predictor', 'increase', 'processing', 'speed', '.'], 'h': {'name': 'predictor', 'pos': [14, 15]}, 't': {'name': 'processing speed', 'pos': [16, 18]}, 'relation': 'result'}
{'token': ['EU', '-', 'funded', 'project', ',', 'QALL', '-', ',', 'domain-specific', 'ontology', 'was', 'developed', 'applied', 'answering', 'in', 'the', 'tourism', 'along', 'with', 'the', 'two', 'ontologies', 'for', 'concept', 'and', 'reasoning'], 'h': {'name': 'domain-specific ontology', 'pos': [8, 10]}, 't': {'name': 'question answering', 'pos': [13, 14]}, 'relation': 'usage'}
{'token': ['design', 'ontology', 'presented', 'paper', ',', 'semi-automatic', 'alignment', 'procedure', 'described', 'alignment', 'results', 'given', 'well', '.'], 'h': {'name': 'semi-automatic alignment procedure', 'pos': [5, 8]}, 't': {'name': 'alignment results', 'pos': [9, 11]}, 'relation': 'result'}
{'token': ['Furthermore', ',', 'aligned', 'ontology', 'used', 'semantically', 'annotate', 'original', 'data', 'obtained', 'tourism', 'web', 'sites', 'natural', 'language', 'questions', '.'], 'h': {'name': 'natural language questions', 'pos': [13, 16]}, 't': {'name': 'data', 'pos': [8, 9]}, 'relation': 'part_whole'}
{'token': ['storage', 'schema', 'annotated', 'data', 'data', 'access', 'method', 'retrieving', 'answers', 'annotated', 'data', 'also', 'reported', 'paper', '.'], 'h': {'name': 'data access method', 'pos': [4, 7]}, 't': {'name': 'annotated data', 'pos': [9, 11]}, 'relation': 'usage'}
{'token': ['particular', 'discuss', 'natural', 'language', 'generation', 'system', 'composed', 'SPoT', ',', 'trainable', 'sentence', 'planner', ',', 'FERGUS', ',', 'stochastic', 'surface', 'realizer', '.'], 'h': {'name': 'SPoT', 'pos': [7, 8]}, 't': {'name': 'natural language generation system', 'pos': [2, 6]}, 'relation': 'part_whole'}
{'token': ['show', 'stochastic', 'NLG', 'components', 'made', 'work', 'together', ',', 'ported', 'new', 'domains', 'apparent', 'ease', ',', 'NLG', 'components', 'integrated', 'real', '-', 'time', 'dialog', 'system', '.'], 'h': {'name': 'NLG components', 'pos': [14, 16]}, 't': {'name': 'real-time dialog system', 'pos': [17, 22]}, 'relation': 'part_whole'}
{'token': ['current', 'work', ',', 'produce', 'manual', 'segmentation', 'laughter', 'large', 'corpus', 'interactive', 'multi-party', 'seminars', ',', 'promises', 'valuable', 'resource', 'acoustic', 'modeling', 'purposes', '.'], 'h': {'name': 'interactive multi-party seminars', 'pos': [9, 12]}, 't': {'name': 'corpus', 'pos': [8, 9]}, 'relation': 'part_whole'}
{'token': ['paper', 'presents', 'extended', 'GLR', 'parsing', 'algorithm', 'grammar', 'PCFG', '*', 'based', 'Tomita', "'s", 'GLR', 'parsing', 'algorithm', 'extends', '.'], 'h': {'name': 'grammar PCFG*', 'pos': [6, 9]}, 't': {'name': 'extended GLR parsing algorithm', 'pos': [2, 6]}, 'relation': 'usage'}
{'token': ['paper', 'presents', 'extended', 'GLR', 'parsing', 'algorithm', 'grammar', 'PCFG', '*', 'based', 'Tomita', "'s", 'GLR', 'parsing', 'algorithm', 'extends', '.'], 'h': {'name': "Tomita's GLR parsing algorithm", 'pos': [10, 15]}, 't': {'name': 'grammar PCFG*', 'pos': [6, 9]}, 'relation': 'usage'}
{'token': ['also', 'define', 'new', 'grammar', 'PCFG', '*', 'based', 'PCFG', 'assigns', 'probability', 'also', 'frequency', 'associated', 'rule', '.'], 'h': {'name': 'PCFG', 'pos': [7, 8]}, 't': {'name': 'grammar PCFG*', 'pos': [3, 6]}, 'relation': 'usage'}
{'token': ['also', 'define', 'new', 'grammar', 'PCFG', '*', 'based', 'PCFG', 'assigns', 'probability', 'also', 'frequency', 'associated', 'rule', '.'], 'h': {'name': 'frequency', 'pos': [11, 12]}, 't': {'name': 'rule', 'pos': [13, 14]}, 'relation': 'model-feature'}
{'token': ['syntactic', 'parsing', 'system', 'implemented', 'based', 'rule', '-', 'based', 'approach', 'statistics', 'approach', '.'], 'h': {'name': 'rule-based approach', 'pos': [5, 9]}, 't': {'name': 'syntactic parsing system', 'pos': [0, 3]}, 'relation': 'usage'}
{'token': ['paper', ',', 'discuss', 'lemma', 'identification', 'Japanese', 'morphological', 'analysis', ',', 'crucial', 'proper', 'formulation', 'morphological', 'analysis', 'benefits', 'NLP', 'researchers', 'also', 'corpus', 'linguists', '.'], 'h': {'name': 'lemma identification', 'pos': [3, 5]}, 't': {'name': 'Japanese morphological analysis', 'pos': [5, 8]}, 'relation': 'usage'}
{'token': ['Since', 'Japanese', 'words', 'often', 'variation', 'orthography', 'vocabulary', 'Japanese', 'consists', 'words', 'several', 'different', 'origins', ',', 'sometimes', 'happens', 'one', 'writing', 'form', 'corresponds', 'lemma', 'single', 'writing', 'form', 'corresponds', 'two', 'lemmas', 'different', 'readings', '/', 'meanings', '.'], 'h': {'name': 'words', 'pos': [9, 10]}, 't': {'name': 'vocabulary', 'pos': [6, 7]}, 'relation': 'part_whole'}
{'token': ['Since', 'Japanese', 'words', 'often', 'variation', 'orthography', 'vocabulary', 'Japanese', 'consists', 'words', 'several', 'different', 'origins', ',', 'sometimes', 'happens', 'one', 'writing', 'form', 'corresponds', 'lemma', 'single', 'writing', 'form', 'corresponds', 'two', 'lemmas', 'different', 'readings', '/', 'meanings', '.'], 'h': {'name': 'writing form', 'pos': [17, 19]}, 't': {'name': 'lemma', 'pos': [20, 21]}, 'relation': 'model-feature'}
{'token': ['Since', 'Japanese', 'words', 'often', 'variation', 'orthography', 'vocabulary', 'Japanese', 'consists', 'words', 'several', 'different', 'origins', ',', 'sometimes', 'happens', 'one', 'writing', 'form', 'corresponds', 'lemma', 'single', 'writing', 'form', 'corresponds', 'two', 'lemmas', 'different', 'readings', '/', 'meanings', '.'], 'h': {'name': 'writing form', 'pos': [22, 24]}, 't': {'name': 'lemmas', 'pos': [26, 27]}, 'relation': 'model-feature'}
{'token': ['mapping', 'writing', 'form', 'onto', 'lemma', 'important', 'linguistic', 'analysis', 'corpora', '.'], 'h': {'name': 'linguistic analysis', 'pos': [6, 8]}, 't': {'name': 'corpora', 'pos': [8, 9]}, 'relation': 'topic'}
{'token': ['current', 'study', 'focuses', 'disambiguation', 'heteronyms', ',', 'words', 'writing', 'form', 'different', 'word', 'forms', '.'], 'h': {'name': 'disambiguation', 'pos': [3, 4]}, 't': {'name': 'heteronyms', 'pos': [4, 5]}, 'relation': 'usage'}
{'token': ['resolve', 'heteronym', 'ambiguity', ',', 'make', 'use', 'goshu', 'information', ',', 'classification', 'words', 'based', 'origin', '.'], 'h': {'name': 'origin', 'pos': [12, 13]}, 't': {'name': 'words', 'pos': [10, 11]}, 'relation': 'model-feature'}
{'token': ['Founded', 'fact', 'words', 'goshu', 'classes', 'likely', 'combine', 'compound', 'words', 'words', 'classes', ',', 'employ', 'statistical', 'model', 'based', 'CRFs', 'using', 'goshu', 'information', '.'], 'h': {'name': 'words', 'pos': [2, 3]}, 't': {'name': 'goshu classes', 'pos': [3, 5]}, 'relation': 'part_whole'}
{'token': ['Founded', 'fact', 'words', 'goshu', 'classes', 'likely', 'combine', 'compound', 'words', 'words', 'classes', ',', 'employ', 'statistical', 'model', 'based', 'CRFs', 'using', 'goshu', 'information', '.'], 'h': {'name': 'words', 'pos': [9, 10]}, 't': {'name': 'classes', 'pos': [10, 11]}, 'relation': 'part_whole'}
{'token': ['Founded', 'fact', 'words', 'goshu', 'classes', 'likely', 'combine', 'compound', 'words', 'words', 'classes', ',', 'employ', 'statistical', 'model', 'based', 'CRFs', 'using', 'goshu', 'information', '.'], 'h': {'name': 'CRFs', 'pos': [16, 17]}, 't': {'name': 'statistical model', 'pos': [13, 15]}, 'relation': 'usage'}
{'token': ['Experimental', 'results', 'show', 'use', 'goshu', 'information', 'considerably', 'improves', 'performance', 'heteronym', 'disambiguation', 'lemma', 'identification', ',', 'suggesting', 'goshu', 'information', 'solves', 'lemma', 'identification', 'task', 'effectively', '.'], 'h': {'name': 'goshu information', 'pos': [4, 6]}, 't': {'name': 'performance', 'pos': [8, 9]}, 'relation': 'result'}
{'token': ['Experimental', 'results', 'show', 'use', 'goshu', 'information', 'considerably', 'improves', 'performance', 'heteronym', 'disambiguation', 'lemma', 'identification', ',', 'suggesting', 'goshu', 'information', 'solves', 'lemma', 'identification', 'task', 'effectively', '.'], 'h': {'name': 'information', 'pos': [16, 17]}, 't': {'name': 'lemma identification task', 'pos': [18, 21]}, 'relation': 'usage'}
{'token': ['event', 'detection', 'algorithm', 'identifies', 'collocations', 'may', 'cause', 'event', 'specific', 'timestamp', '.'], 'h': {'name': 'event detection algorithm', 'pos': [0, 3]}, 't': {'name': 'collocations', 'pos': [4, 5]}, 'relation': 'usage'}
{'token': ['event', 'summarization', 'algorithm', 'retrieves', 'set', 'collocations', 'describe', 'event', '.'], 'h': {'name': 'event summarization algorithm', 'pos': [0, 3]}, 't': {'name': 'collocations', 'pos': [5, 6]}, 'relation': 'usage'}
{'token': ['describe', 'two', 'approaches', 'analyzing', 'tagging', 'team', 'discourse', 'using', 'Latent', 'Semantic', 'Analysis', '(', 'LSA', ')', 'predict', 'team', 'performance', '.'], 'h': {'name': 'Latent Semantic Analysis (LSA)', 'pos': [8, 14]}, 't': {'name': 'tagging', 'pos': [4, 5]}, 'relation': 'usage'}
{'token': ['huge', 'amount', 'translation', 'work', 'needs', 'done', 'creating', 'updating', 'technical', 'documentation', '.'], 'h': {'name': 'translation work', 'pos': [2, 4]}, 't': {'name': 'technical documentation', 'pos': [8, 10]}, 'relation': 'usage'}
{'token': ['objective', 'project', 'pilot', 'study', 'several', 'new', 'ideas', 'automatic', 'adaptation', 'improvement', 'natural', 'language', 'processing', '(', 'NLP', ')', 'systems', '.'], 'h': {'name': 'pilot study', 'pos': [2, 4]}, 't': {'name': 'automatic adaptation', 'pos': [7, 9]}, 'relation': 'topic'}
{'token': ['effort', 'focuses', 'particularly', 'automatically', 'inferring', 'meaning', 'new', 'words', 'context', 'developing', 'partial', 'interpretations', 'language', 'either', 'fragmentary', 'beyond', 'capability', 'NLP', 'system', 'understand', '.'], 'h': {'name': 'meaning', 'pos': [5, 6]}, 't': {'name': 'words', 'pos': [7, 8]}, 'relation': 'model-feature'}
{'token': ['NLP', 'system', 'uses', 'large', 'annotated', 'corpora', ',', 'developed', 'DARPA', '-', 'funded', 'TREE-BANK', 'project', 'at', 'the', 'Pennsylvania', 'to', 'adapt', 'acquiring', 'and', 'semantic', 'from', 'the', '.'], 'h': {'name': 'large annotated corpora', 'pos': [3, 6]}, 't': {'name': 'NLP system', 'pos': [0, 2]}, 'relation': 'usage'}
{'token': ['NLP', 'system', 'uses', 'large', 'annotated', 'corpora', ',', 'developed', 'DARPA', '-', 'funded', 'TREE-BANK', 'project', 'at', 'the', 'Pennsylvania', 'to', 'adapt', 'acquiring', 'syntactic', 'and', 'semantic', 'from', 'the', 'examples', '.'], 'h': {'name': 'syntactic and semantic information', 'pos': [19, 22]}, 't': {'name': 'annotated examples', 'pos': [24, 25]}, 'relation': 'part_whole'}
{'token': ['Statistical', 'language', 'modeling', ',', 'based', 'probability', 'estimates', 'derived', 'large', 'corpora', ',', 'provide', 'means', 'ranking', 'alternative', 'interpretations', 'fragments', '.'], 'h': {'name': 'probability estimates', 'pos': [5, 7]}, 't': {'name': 'Statistical language modeling', 'pos': [0, 3]}, 'relation': 'usage'}
{'token': ['Lexicalized', 'concepts', 'organized', 'semantic', 'relations', '(', 'synonymy', ',', 'antonymy', ',', 'hyponymy', ',', 'meronymy', ',', 'etc.', ')'], 'h': {'name': 'semantic relations', 'pos': [3, 5]}, 't': {'name': 'Lexicalized concepts', 'pos': [0, 2]}, 'relation': 'model-feature'}
{'token': ['Work', 'grant', 'intended', 'extend', 'upgrade', 'WordNet', ',', 'make', 'generally', 'available', ',', 'develop', 'tool', 'use', 'practical', 'applications', '.'], 'h': {'name': 'WordNet', 'pos': [5, 6]}, 't': {'name': 'applications', 'pos': [15, 16]}, 'relation': 'usage'}
{'token': ['order', 'make', 'available', 'information', 'retrieval', 'machine', 'translation', ',', 'system', 'developed', 'English', 'text', 'input', 'automatically', 'gives', 'output', 'text', 'augmented', 'syntactic', 'semantic', 'anotations', 'disambiguate', 'substantive', 'words', '.'], 'h': {'name': 'syntactic and semantic anotations', 'pos': [18, 21]}, 't': {'name': 'substantive words', 'pos': [22, 24]}, 'relation': 'model-feature'}
{'token': ['Initially', ',', 'semantic', 'tagging', 'done', 'manually', '(', '1', ')', 'obtain', 'extensive', 'experience', 'tagging', 'process', '(', '2', ')', 'create', 'database', 'correctly', 'tagged', 'text', 'use', 'testing', 'proposals', 'automatic', 'sense', 'disambiguation', '.'], 'h': {'name': 'text', 'pos': [21, 22]}, 't': {'name': 'database', 'pos': [18, 19]}, 'relation': 'part_whole'}
{'token': ['Review', 'previous', 'designs', 'involving', 'TIPSTER', 'technology', ',', 'support', 'design', 'process', '.', 'Determine', 'application', 'benefit', 'upgrading', 'advanced', 'TIPSTER', 'technology', 'developed', 'since', 'application', 'implemented', '.'], 'h': {'name': 'TIPSTER technology', 'pos': [16, 18]}, 't': {'name': 'application', 'pos': [12, 13]}, 'relation': 'usage'}
{'token': ['Accurate', 'lemmatization', 'German', 'nouns', 'mandates', 'use', 'lexicon', '.'], 'h': {'name': 'lemmatization', 'pos': [1, 2]}, 't': {'name': 'German nouns', 'pos': [2, 4]}, 'relation': 'usage'}
{'token': ['present', 'self', '-', 'learning', 'lemmatizer', 'capable', 'automatically', 'creating', 'full', '-', 'form', 'lexicon', 'processing', 'German', 'documents', '.'], 'h': {'name': 'self-learning lemmatizer', 'pos': [1, 5]}, 't': {'name': 'German documents', 'pos': [13, 15]}, 'relation': 'usage'}
{'token': ['paper', 'describe', '-', 'Atlas', 'creates', 'utilizes', 'proof', '-', 'based', 'representation', 'student', 'essays', '.'], 'h': {'name': 'proof-based representation', 'pos': [6, 10]}, 't': {'name': 'Why-Atlas', 'pos': [2, 4]}, 'relation': 'usage'}
{'token': ['describe', 'creates', 'proof', 'given', 'output', 'sentence', '-', 'level', 'understanding', ',', 'uses', 'proofs', 'give', 'students', 'feedback', ',', 'preliminary', 'runtime', 'measures', ',', 'work', 'currently', 'derive', 'additional', 'benefits', 'proof', '-', 'based', 'approach', 'tutoring', 'applications', '.'], 'h': {'name': 'proof-based approach', 'pos': [25, 29]}, 't': {'name': 'tutoring applications', 'pos': [29, 31]}, 'relation': 'usage'}
{'token': ['Compared', 'syntactic', 'knowledge', ',', 'semantic', 'knowledge', 'difficult', 'annotate', ',', 'ambiguity', 'problem', 'serious', '.'], 'h': {'name': 'syntactic knowledge', 'pos': [1, 3]}, 't': {'name': 'semantic knowledge', 'pos': [4, 6]}, 'relation': 'compare'}
{'token': ['Finally', ',', 'compare', 'corpus', 'well', '-', 'known', 'corpora', '.'], 'h': {'name': 'corpus', 'pos': [3, 4]}, 't': {'name': 'corpora', 'pos': [7, 8]}, 'relation': 'compare'}
{'token': ['techniques', ',', 'developed', 'within', 'Augmented', 'Transition', 'Network', '(', 'ATN', ')', 'model', ',', 'shown', 'adequate', 'handle', 'many', 'cases', '.'], 'h': {'name': 'techniques', 'pos': [0, 1]}, 't': {'name': 'Augmented Transition Network (ATN) model', 'pos': [4, 11]}, 'relation': 'usage'}
{'token': ['identified', ',', 'reference', 'chains', 'extended', 'across', 'segment', 'boundaries', ',', 'thus', 'enabling', 'application', 'CT', 'entire', 'discourse', '.'], 'h': {'name': 'CT', 'pos': [12, 13]}, 't': {'name': 'discourse', 'pos': [14, 15]}, 'relation': 'usage'}
{'token': ['describe', 'processes', 'veins', 'defined', 'discourse', 'structure', 'trees', 'CT', 'applied', 'global', 'discourse', 'using', 'chains', '.'], 'h': {'name': 'CT', 'pos': [7, 8]}, 't': {'name': 'global discourse', 'pos': [9, 11]}, 'relation': 'usage'}
{'token': ['also', 'define', 'discourse', 'smoothness', 'index', 'used', 'compare', 'different', 'discourse', 'structures', 'interpretations', ',', 'show', 'VT', 'used', 'abstract', 'span', 'text', 'context', 'whole', 'discourse', '.'], 'h': {'name': 'discourse smoothness index', 'pos': [2, 5]}, 't': {'name': 'discourse structures and interpretations', 'pos': [8, 11]}, 'relation': 'usage'}
{'token': ['HITIQA', 'interactive', 'open-domain', 'question', 'answering', 'technology', 'designed', 'allow', 'analysts', 'pose', 'complex', 'exploratory', 'questions', 'natural', 'language', 'obtain', 'relevant', 'information', 'units', 'prepare', 'briefing', 'reports', 'order', 'satisfy', 'given', 'scenario', '.'], 'h': {'name': 'natural language', 'pos': [13, 15]}, 't': {'name': 'exploratory questions', 'pos': [11, 13]}, 'relation': 'model-feature'}
{'token': ['system', 'uses', 'novel', 'data-driven', 'semantics', 'conduct', 'clarification', 'dialogue', 'user', 'explores', 'scope', 'context', 'desired', 'answer', 'space', '.'], 'h': {'name': 'data-driven semantics', 'pos': [3, 5]}, 't': {'name': 'system', 'pos': [0, 1]}, 'relation': 'usage'}
{'token': ['One', 'resulted', 'first', 'freely', 'distributable', 'corpus', 'fully', 'anonymized', 'clinical', 'text', '.'], 'h': {'name': 'fully anonymized clinical text', 'pos': [6, 10]}, 't': {'name': 'corpus', 'pos': [5, 6]}, 'relation': 'part_whole'}
{'token': ['key', 'feature', 'task', 'required', 'categorization', 'respect', 'large', 'commercially', 'significant', 'set', 'labels', '.'], 'h': {'name': 'set of labels', 'pos': [9, 11]}, 't': {'name': 'categorization', 'pos': [4, 5]}, 'relation': 'usage'}
{'token': ['Many', 'systems', 'performed', 'levels', 'approaching', 'inter', '-', 'coder', 'agreement', ',', 'suggesting', 'human', '-', 'like', 'performance', 'task', 'within', 'reach', 'currently', 'available', 'technologies', '.'], 'h': {'name': 'human-like performance', 'pos': [11, 15]}, 't': {'name': 'currently available technologies', 'pos': [18, 21]}, 'relation': 'compare'}
{'token': ['paper', 'describe', 'automatic', 'information', 'nuggetization', 'application', 'text', 'comparison', '.'], 'h': {'name': 'automatic information nuggetization', 'pos': [2, 5]}, 't': {'name': 'text comparison', 'pos': [6, 8]}, 'relation': 'usage'}
{'token': ['specifically', ',', 'take', 'close', 'look', 'machine', '-', 'generated', 'nuggets', 'used', 'create', 'evaluation', 'material', '.'], 'h': {'name': 'machine-generated nuggets', 'pos': [5, 9]}, 't': {'name': 'evaluation material', 'pos': [11, 13]}, 'relation': 'usage'}
{'token': ['semiautomatic', 'annotation', 'scheme', 'designed', 'produce', 'gold', '-', 'standard', 'data', 'exceptionally', 'high', 'inter-human', 'agreement', '.'], 'h': {'name': 'semiautomatic annotation scheme', 'pos': [0, 3]}, 't': {'name': 'gold-standard data', 'pos': [5, 9]}, 'relation': 'usage'}
{'token': ['paper', 'presents', 'results', 'experiments', 'tested', 'different', 'kinds', 'features', 'retrieval', 'Chinese', 'opinionated', 'texts', '.'], 'h': {'name': 'features', 'pos': [7, 8]}, 't': {'name': 'retrieval', 'pos': [8, 9]}, 'relation': 'usage'}
{'token': ['assume', 'task', 'retrieval', 'opinionated', 'texts', '(', 'OIR', ')', 'regarded', 'subtask', 'general', 'IR', ',', 'distinct', 'features', '.'], 'h': {'name': 'retrieval', 'pos': [2, 3]}, 't': {'name': 'IR', 'pos': [11, 12]}, 'relation': 'part_whole'}
{'token': ['paper', 'discusses', 'supervised', 'learning', 'morphology', 'using', 'stochastic', 'transducers', ',', 'trained', 'using', 'Expectation', '-', 'Maximization', '(', 'EM', ')', 'algorithm', '.'], 'h': {'name': 'stochastic transducers', 'pos': [6, 8]}, 't': {'name': 'supervised learning', 'pos': [2, 4]}, 'relation': 'usage'}
{'token': ['evaluated', 'compared', 'data', 'sets', 'English', ',', 'German', ',', 'Slovene', 'Arabic', '.'], 'h': {'name': 'data sets', 'pos': [2, 4]}, 't': {'name': 'English', 'pos': [4, 5]}, 'relation': 'part_whole'}
{'token': ['Speech', 'recognition', 'problems', 'reality', 'current', 'spoken', 'dialogue', 'systems'], 'h': {'name': 'Speech recognition problems', 'pos': [0, 3]}, 't': {'name': 'spoken dialogue systems', 'pos': [5, 8]}, 'relation': 'part_whole'}
{'token': ['apply', 'Chi', 'Square', '(', '%', '2', ')', 'analysis', 'corpus', 'speech', '-', 'based', 'computer', 'tutoring', 'dialogues', 'discover', 'dependencies', 'within', 'across', 'turns', '.'], 'h': {'name': 'Chi Square (%2) analysis', 'pos': [1, 8]}, 't': {'name': 'corpus of speech-based computer tutoring dialogues', 'pos': [8, 15]}, 'relation': 'usage'}
{'token': ['interlingual', 'knowledge', '-', 'based', 'machine', 'translation', 'system', ',', 'ambiguity', 'arises', 'source', 'language', 'analyzer', 'produces', 'one', 'interlingua', 'expression', 'source', 'sentence', '.'], 'h': {'name': 'interlingua expression', 'pos': [15, 17]}, 't': {'name': 'source sentence', 'pos': [17, 19]}, 'relation': 'model-feature'}
{'token': ['also', 'test', 'methods', 'large', 'corpus', 'test', 'sentences', ',', 'order', 'illustrate', 'different', 'disambiguation', 'methods', 'reduce', 'average', 'number', 'parses', 'per', 'sentence', '.'], 'h': {'name': 'test sentences', 'pos': [5, 7]}, 't': {'name': 'corpus', 'pos': [4, 5]}, 'relation': 'part_whole'}
{'token': ['also', 'test', 'methods', 'large', 'corpus', 'test', 'sentences', ',', 'order', 'illustrate', 'different', 'disambiguation', 'methods', 'reduce', 'average', 'number', 'parses', 'per', 'sentence', '.'], 'h': {'name': 'disambiguation methods', 'pos': [11, 13]}, 't': {'name': 'parses', 'pos': [16, 17]}, 'relation': 'result'}
{'token': ['intersection', 'tree', 'transducer', '-', 'based', 'translation', 'models', 'n-gram', 'language', 'models', 'results', 'huge', 'dynamic', 'programs', 'machine', 'translation', 'decoding', '.'], 'h': {'name': 'dynamic programs', 'pos': [12, 14]}, 't': {'name': 'machine translation decoding', 'pos': [14, 17]}, 'relation': 'usage'}
{'token': ['contrast', 'previous', 'order', '-', 'based', 'bigram-', 'to', 'trigram', 'approaches', ',', 'we', 'on', 'encoding', '-', 'based', 'methods', ',', 'which', 'a', 'clustered', 'encoding', 'of', 'language', '.'], 'h': {'name': 'clustered encoding', 'pos': [19, 21]}, 't': {'name': 'encoding-based methods', 'pos': [12, 16]}, 'relation': 'usage'}
{'token': ['Moreover', ',', 'entire', 'decoding', 'cascade', 'trigram', 'language', 'models', 'faster', 'corresponding', 'bigram', 'pass', 'alone', 'bigram-', 'to', 'decoder', '.'], 'h': {'name': 'decoding cascade for trigram language models', 'pos': [3, 8]}, 't': {'name': 'bigram-to-trigram decoder', 'pos': [13, 16]}, 'relation': 'compare'}
{'token': ['paper', 'presents', 'findings', 'feasibility', 'pronoun', 'resolution', 'biomedical', 'texts', ',', 'comparison', 'conducting', 'pronoun', 'resolution', 'newswire', 'domain', '.'], 'h': {'name': 'pronoun resolution', 'pos': [4, 6]}, 't': {'name': 'biomedical texts', 'pos': [6, 8]}, 'relation': 'usage'}
{'token': ['paper', 'presents', 'findings', 'feasibility', 'pronoun', 'resolution', 'biomedical', 'texts', ',', 'comparison', 'conducting', 'pronoun', 'resolution', 'newswire', 'domain', '.'], 'h': {'name': 'pronoun resolution', 'pos': [11, 13]}, 't': {'name': 'newswire domain', 'pos': [13, 15]}, 'relation': 'usage'}
{'token': ['Sharing', 'portions', 'grammars', 'across', 'languages', 'greatly', 'reduces', 'costs', 'multilingual', 'grammar', 'engineering', '.'], 'h': {'name': 'grammars', 'pos': [2, 3]}, 't': {'name': 'multilingual grammar engineering', 'pos': [8, 11]}, 'relation': 'result'}
{'token': ['Taking', 'grammatical', 'relatedness', 'seriously', ',', 'particularly', 'interested', 'designing', 'linguistically', 'motivated', 'grammatical', 'resources', 'Slavic', 'languages', 'used', 'applied', 'theoretical', 'computational', 'linguistics', '.'], 'h': {'name': 'linguistically motivated grammatical resources', 'pos': [8, 12]}, 't': {'name': 'applied and theoretical computational linguistics', 'pos': [15, 19]}, 'relation': 'usage'}
{'token': ['basis', 'Slavic', 'data', ',', 'show', 'domain', 'ontology', 'conceptualising', 'morpho-syntactic', '"', 'building', 'blocks', '"', 'serve', 'basis', 'shared', 'grammar', 'Slavic', '.'], 'h': {'name': 'domain ontology', 'pos': [5, 7]}, 't': {'name': 'shared grammar of Slavic', 'pos': [15, 18]}, 'relation': 'usage'}
{'token': ['currently', 'developing', 'MiniSTEx', ',', 'spatiotemporal', 'annotation', 'system', 'handle', 'temporal', '/', 'geospatial', 'information', 'directly', 'indirectly', 'expressed', 'texts', '.'], 'h': {'name': 'temporal and/or geospatial information', 'pos': [8, 12]}, 't': {'name': 'texts', 'pos': [15, 16]}, 'relation': 'part_whole'}
{'token': ['first', 'version', 'MiniSTEx', 'originally', 'developed', 'Dutch', ',', 'keeping', 'mind', 'also', 'useful', 'European', 'languages', ',', 'multilingual', 'applications', '.'], 'h': {'name': 'MiniSTEx', 'pos': [2, 3]}, 't': {'name': 'Dutch', 'pos': [5, 6]}, 'relation': 'usage'}
{'token': ['world', 'knowledge', 'MiniSTEx', 'uses', 'contained', 'interconnected', 'tables', 'database', '.'], 'h': {'name': 'world knowledge', 'pos': [0, 2]}, 't': {'name': 'MiniSTEx', 'pos': [2, 3]}, 'relation': 'part_whole'}
{'token': ['paper', 'describe', 'technique', 'improving', 'performance', 'information', 'extraction', 'system', 'speech', 'data', 'explicitly', 'modeling', 'errors', 'recognizer', 'output', '.'], 'h': {'name': 'information extraction system', 'pos': [5, 8]}, 't': {'name': 'speech data', 'pos': [8, 10]}, 'relation': 'usage'}
{'token': ['paper', ',', 'report', 'QA', 'system', 'answer', 'type', 'questions', 'based', 'confirmed', 'knowledge', 'base', 'developed', 'using', 'mails', 'posted', 'mailing', 'list', '.'], 'h': {'name': 'QA system', 'pos': [3, 5]}, 't': {'name': 'type questions', 'pos': [6, 8]}, 'relation': 'usage'}
{'token': ['paper', ',', 'report', 'QA', 'system', 'answer', 'type', 'questions', 'based', 'confirmed', 'knowledge', 'base', 'developed', 'using', 'mails', 'posted', 'mailing', 'list', '.'], 'h': {'name': 'confirmed knowledge base', 'pos': [9, 12]}, 't': {'name': 'mails', 'pos': [14, 15]}, 'relation': 'part_whole'}
{'token': ['first', 'discuss', 'problem', 'developing', 'knowledge', 'base', 'using', 'natural', 'language', 'documents', ':', 'wrong', 'information', 'natural', 'language', 'documents', '.'], 'h': {'name': 'knowledge base', 'pos': [4, 6]}, 't': {'name': 'natural language documents', 'pos': [7, 10]}, 'relation': 'part_whole'}
{'token': ['first', 'discuss', 'problem', 'developing', 'knowledge', 'base', 'using', 'natural', 'language', 'documents', ':', 'wrong', 'information', 'natural', 'language', 'documents', '.'], 'h': {'name': 'wrong information', 'pos': [11, 13]}, 't': {'name': 'natural language documents', 'pos': [13, 16]}, 'relation': 'part_whole'}
{'token': [',', 'describe', 'method', 'detecting', 'wrong', 'information', 'mails', 'posted', 'mailing', 'list', 'developing', 'knowledge', 'base', 'using', 'mails', '.'], 'h': {'name': 'wrong information', 'pos': [4, 6]}, 't': {'name': 'mails', 'pos': [6, 7]}, 'relation': 'part_whole'}
{'token': [',', 'describe', 'method', 'detecting', 'wrong', 'information', 'mails', 'posted', 'mailing', 'list', 'developing', 'knowledge', 'base', 'using', 'mails', '.'], 'h': {'name': 'knowledge base', 'pos': [11, 13]}, 't': {'name': 'mails', 'pos': [14, 15]}, 'relation': 'part_whole'}
{'token': ['Finally', ',', 'show', 'question', 'answer', 'mails', 'posted', 'mailing', 'list', 'used', 'knowledge', 'base', 'QA', 'system', '.'], 'h': {'name': 'knowledge base', 'pos': [10, 12]}, 't': {'name': 'QA system', 'pos': [12, 14]}, 'relation': 'usage'}
{'token': ['demonstrate', 'new', 'research', 'approach', 'problem', 'predicting', 'reading', 'difficulty', 'text', 'passage', ',', 'recasting', 'readability', 'terms', 'statistical', 'language', 'modeling', '.'], 'h': {'name': 'reading difficulty', 'pos': [6, 8]}, 't': {'name': 'text passage', 'pos': [8, 10]}, 'relation': 'model-feature'}
{'token': ['demonstrate', 'new', 'research', 'approach', 'problem', 'predicting', 'reading', 'difficulty', 'text', 'passage', ',', 'recasting', 'readability', 'terms', 'statistical', 'language', 'modeling', '.'], 'h': {'name': 'statistical language modeling', 'pos': [14, 17]}, 't': {'name': 'readability', 'pos': [12, 13]}, 'relation': 'model-feature'}
{'token': ['derive', 'measure', 'based', 'extension', 'multinomial', 'naive', 'Bayes', 'classification', 'combines', 'multiple', 'language', 'models', 'estimate', 'likely', 'grade', 'level', 'given', 'passage', '.'], 'h': {'name': 'language models', 'pos': [10, 12]}, 't': {'name': 'multinomial naive Bayes classification', 'pos': [4, 8]}, 'relation': 'usage'}
{'token': ['perform', 'predictions', 'individual', 'Web', 'pages', 'English', 'compare', 'performance', 'widely', '-', 'used', 'semantic', 'variables', 'traditional', 'readability', 'measures', '.'], 'h': {'name': 'semantic variables', 'pos': [11, 13]}, 't': {'name': 'readability measures', 'pos': [14, 16]}, 'relation': 'part_whole'}
{'token': ['traditional', 'semantic', 'variables', 'type-', 'token', 'ratio', 'gave', 'the', 'performance', 'on', 'calibrated', 'test', 'passages', ',', 'while', 'language', 'modeling', 'approach', 'gave', 'better', 'accuracy', 'for', 'Web', 'documents', 'and', 'passages', '(', 'less', 'than', 'words', ')', '.'], 'h': {'name': 'language modeling approach', 'pos': [15, 18]}, 't': {'name': 'Web documents', 'pos': [22, 24]}, 'relation': 'usage'}
{'token': ['Syntactic', 'semantic', 'information', 'represented', 'grammar', 'uniform', 'manner', ',', 'similar', 'HPSG', '(', 'Pollard', 'Sag', ',', '1987', ')', '.'], 'h': {'name': 'grammar', 'pos': [4, 5]}, 't': {'name': 'Syntactic and semantic information', 'pos': [0, 3]}, 'relation': 'model-feature'}
{'token': ['LINK', 'used', 'several', 'information', 'extraction', 'applications', '.'], 'h': {'name': 'LINK', 'pos': [0, 1]}, 't': {'name': 'information extraction applications', 'pos': [3, 6]}, 'relation': 'usage'}
{'token': ['project', 'General', 'Motors', ',', 'LINK', 'used', 'process', 'terse', 'free', '-', 'form', 'descriptions', 'symptoms', 'displayed', 'malfunctioning', 'automobiles', ',', 'repairs', 'fixed', '.'], 'h': {'name': 'LINK', 'pos': [4, 5]}, 't': {'name': 'free-form descriptions', 'pos': [8, 12]}, 'relation': 'usage'}
{'token': ['Reduplication', ',', 'central', 'instance', 'prosodic', 'morphology', ',', 'particularly', 'challenging', 'state', '-', '-', '-', 'art', 'computational', 'morphology', ',', 'since', 'involves', 'copying', 'part', 'phonological', 'string'], 'h': {'name': 'Reduplication', 'pos': [0, 1]}, 't': {'name': 'prosodic morphology', 'pos': [4, 6]}, 'relation': 'part_whole'}
{'token': ['paper', 'advocate', 'finite', '-', 'state', 'method', 'combines', 'enriched', 'lexical', 'representations', 'via', 'intersection', 'implement', 'copying', '.'], 'h': {'name': 'enriched lexical representations', 'pos': [7, 10]}, 't': {'name': 'finite-state method', 'pos': [2, 6]}, 'relation': 'usage'}
{'token': ['proposal', 'includes', 'resource', '-', 'conscious', 'variant', 'automata', 'benefit', 'existence', 'lazy', 'algorithms', '.'], 'h': {'name': 'lazy algorithms', 'pos': [9, 11]}, 't': {'name': 'resource-conscious variant of automata', 'pos': [2, 7]}, 'relation': 'usage'}
{'token': ['quick', 'relevancy', 'judgements', 'require', 'two', 'steps', ':', '(', '1', ')', 'recognizing', 'expression', 'highly', 'relevant', 'given', 'domain', ',', 'e.g.', '"', 'killed', '"', 'domain', 'terrorism', ',', '(', '2', ')', 'verifying', 'context', 'surrounding', 'expression', 'consistent', 'relevancy', 'guidelines', 'domain', ',', 'e.g.', '"', '5', 'soldiers', 'killed', 'guerrillas', '"', 'consistent', 'terrorism', 'domain', 'since', 'victims', 'terrorist', 'acts', 'must', 'civilians', '.'], 'h': {'name': 'expression', 'pos': [11, 12]}, 't': {'name': 'given domain', 'pos': [14, 16]}, 'relation': 'model-feature'}
{'token': ['Relevancy', 'Signatures', 'Algorithm', 'attempts', 'simulate', 'first', 'step', 'process', 'deriving', 'reliable', 'relevancy', 'cues', 'corpus', 'training', 'texts', 'using', 'cues', 'quickly', 'identify', 'new', 'texts', 'highly', 'likely', 'relevant', '.'], 'h': {'name': 'reliable relevancy cues', 'pos': [9, 12]}, 't': {'name': 'corpus of training texts', 'pos': [12, 15]}, 'relation': 'part_whole'}
{'token': ['system', 'accepts', 'entire', 'English', 'news', 'story', '(', 'text', ')', 'query', ',', 'retrieves', 'relevant', 'Chinese', 'broadcast', 'news', 'stories', '(', 'audio', ')', 'document', 'collection', '.'], 'h': {'name': 'relevant Chinese broadcast news stories (audio)', 'pos': [12, 20]}, 't': {'name': 'document collection', 'pos': [20, 22]}, 'relation': 'part_whole'}
{'token': ['English', 'queries', 'translated', 'Chinese', 'means', 'dictionary', '-', 'based', 'approach', ',', 'integrated', 'phrase', '-', 'based', 'translation', 'word', '-', '-', 'word', 'translation', '.'], 'h': {'name': 'phrase-based translation', 'pos': [11, 15]}, 't': {'name': 'dictionary-based approach', 'pos': [5, 9]}, 'relation': 'usage'}
{'token': ['Untranslatable', 'named', 'entities', 'transliterated', 'novel', 'subword', 'translation', 'technique', '.'], 'h': {'name': 'novel subword translation technique', 'pos': [4, 8]}, 't': {'name': 'Untranslatable named entities', 'pos': [0, 3]}, 'relation': 'usage'}
{'token': ['Experimental', 'results', 'demonstrate', 'use', 'phrase', '-', 'based', 'translation', 'subword', 'translation', 'gave', 'performance', 'gains', ',', 'multi-scale', 'retrieval', 'outperforms', 'word', '-', 'based', 'retrieval', '.'], 'h': {'name': 'multi-scale retrieval', 'pos': [14, 16]}, 't': {'name': 'word-based retrieval', 'pos': [17, 21]}, 'relation': 'compare'}
{'token': ['English', 'past', 'tense', 'interesting', 'features', 'combination', 'regular', 'rules', 'semi-productive', 'strong', 'verb', 'patterns', ',', 'many', 'respects', 'trivial', 'morphological', 'system', '-', 'reflecting', 'generally', 'vestigal', 'nature', 'inflectional', 'morphology', 'within', 'modern', 'English', '.'], 'h': {'name': 'features', 'pos': [4, 5]}, 't': {'name': 'English past tense', 'pos': [0, 3]}, 'relation': 'model-feature'}
{'token': ['English', 'past', 'tense', 'interesting', 'features', 'combination', 'regular', 'rules', 'semi-productive', 'strong', 'verb', 'patterns', ',', 'many', 'respects', 'trivial', 'morphological', 'system', '-', 'reflecting', 'generally', 'vestigal', 'nature', 'inflectional', 'morphology', 'within', 'modern', 'English', '.'], 'h': {'name': 'vestigal nature', 'pos': [21, 23]}, 't': {'name': 'inflectional morphology', 'pos': [23, 25]}, 'relation': 'model-feature'}
{'token': ['define', ',', 'implement', 'evaluate', 'novel', 'model', 'statistical', 'machine', 'translation', ',', 'based', 'shallow', 'syntactic', 'analysis', '(', 'part', '-of', 'speech', 'tagging', 'and', 'chunking', ')', 'in', 'and', 'languages', '.'], 'h': {'name': 'shallow syntactic analysis', 'pos': [11, 14]}, 't': {'name': 'statistical machine translation', 'pos': [6, 9]}, 'relation': 'usage'}
{'token': ['paper', 'analyzes', 'translation', 'quality', 'machine', 'translation', 'systems', '10', 'language', 'pairs', 'translating', 'Czech', ',', 'English', ',', 'French', ',', 'German', ',', 'Hungarian', ',', 'Spanish', '.'], 'h': {'name': 'machine translation systems', 'pos': [4, 7]}, 't': {'name': 'language pairs', 'pos': [8, 10]}, 'relation': 'usage'}
{'token': ['validate', 'manual', 'evaluation', 'methodology', 'measuring', 'intra', '-', 'inter-annotator', 'agreement', ',', 'collecting', 'timing', 'information', '.'], 'h': {'name': 'intra- and inter-annotator agreement', 'pos': [5, 9]}, 't': {'name': 'manual evaluation methodology', 'pos': [1, 4]}, 'relation': 'usage'}
{'token': ['paper', ',', 'describe', 'issues', 'translation', 'proper', 'names', 'English', 'Chinese', 'faced', 'constructing', 'system', 'multilingual', 'text', 'generation', 'supporting', 'languages', '.'], 'h': {'name': 'translation', 'pos': [4, 5]}, 't': {'name': 'proper names', 'pos': [5, 7]}, 'relation': 'usage'}
{'token': ['CWS', 'based', 'backward', 'maximum', 'matching', 'word', 'support', 'model', '(', 'WSM', ')', 'contextual', '-', 'based', 'Chinese', 'unknown', 'word', 'identification', '.'], 'h': {'name': 'backward maximum matching', 'pos': [2, 5]}, 't': {'name': 'CWS', 'pos': [0, 1]}, 'relation': 'usage'}
{'token': ['Arabic', 'language', 'far', 'richer', 'systems', 'inflection', 'derivation', 'English', 'little', 'morphology', '.'], 'h': {'name': 'systems of inflection and derivation', 'pos': [4, 7]}, 't': {'name': 'Arabic language', 'pos': [0, 2]}, 'relation': 'model-feature'}
{'token': ['Segmentation', 'inflected', 'Arabic', 'words', 'way', 'smooth', 'highly', 'morphological', 'nature', '.'], 'h': {'name': 'Segmentation', 'pos': [0, 1]}, 't': {'name': 'inflected Arabic words', 'pos': [1, 4]}, 'relation': 'usage'}
{'token': ['paper', ',', 'describe', 'statistically', 'linguistically', 'motivated', 'methods', 'Arabic', 'word', 'segmentation', '.'], 'h': {'name': 'statistically and linguistically motivated methods', 'pos': [3, 7]}, 't': {'name': 'Arabic word segmentation', 'pos': [7, 10]}, 'relation': 'usage'}
{'token': [',', 'show', 'efficiency', 'proposed', 'methods', 'Arabic-English', 'BTEC', 'and', 'NIST', '.'], 'h': {'name': 'proposed methods', 'pos': [3, 5]}, 't': {'name': 'Arabic-English BTEC and NIST tasks', 'pos': [5, 9]}, 'relation': 'usage'}
{'token': ['Developing', 'high', '-', 'quality', 'lexicon', 'often', 'first', 'step', 'towards', 'building', 'POS', 'tagger', ',', 'turn', 'front', '-', 'end', 'many', 'NLP', 'systems', '.'], 'h': {'name': 'high-quality lexicon', 'pos': [1, 5]}, 't': {'name': 'POS tagger', 'pos': [10, 12]}, 'relation': 'usage'}
{'token': ['frame', 'lexicon', 'acquisition', 'problem', 'transductive', 'learning', 'problem', ',', 'perform', 'comparisons', 'three', 'transductive', 'algorithms', ':', 'Transductive', 'SVMs', ',', 'Spectral', 'Graph', 'Transducers', ',', 'novel', 'Transductive', 'Clustering', 'method', '.'], 'h': {'name': 'Transductive SVMs', 'pos': [14, 16]}, 't': {'name': 'Spectral Graph Transducers', 'pos': [17, 20]}, 'relation': 'compare'}
{'token': ['present', 'API', 'computing', 'semantic', 'relatedness', 'words', 'Wikipedia', '.'], 'h': {'name': 'API', 'pos': [1, 2]}, 't': {'name': 'semantic relatedness', 'pos': [3, 5]}, 'relation': 'usage'}
{'token': ['paper', 'presents', 'general', 'platform', ',', 'namely', 'synchronous', 'tree', 'sequence', 'substitution', 'grammar', '(', 'STSSG', ')', ',', 'grammar', 'comparison', 'study', 'Translational', 'Equivalence', 'Modeling', '(', 'TEM', ')', 'Statistical', 'Machine', 'Translation', '(', 'SMT', ')', '.'], 'h': {'name': 'synchronous tree sequence substitution grammar (STSSG)', 'pos': [6, 14]}, 't': {'name': 'grammar comparison study', 'pos': [15, 18]}, 'relation': 'usage'}
{'token': ['Experimental', 'results', 'show', 'STSSG', 'able', 'better', 'explain', 'data', 'parallel', 'corpora', 'grammars', '.'], 'h': {'name': 'STSSG', 'pos': [3, 4]}, 't': {'name': 'other grammars', 'pos': [10, 11]}, 'relation': 'compare'}
{'token': ['study', 'finds', 'complexity', 'structure', 'divergence', 'much', 'higher', 'suggested', 'literature', ',', 'imposes', 'big', 'challenge', 'syntactic', 'transformation', '-', 'based', 'SMT', '.'], 'h': {'name': 'structure divergence', 'pos': [3, 5]}, 't': {'name': 'syntactic transformation-based SMT', 'pos': [13, 18]}, 'relation': 'result'}
{'token': ['paper', 'presents', 'innovative', 'unsupervised', 'method', 'automatic', 'sentence', 'extraction', 'using', 'graph', '-', 'based', 'ranking', 'algorithms', '.'], 'h': {'name': 'unsupervised method', 'pos': [3, 5]}, 't': {'name': 'automatic sentence extraction', 'pos': [5, 8]}, 'relation': 'usage'}
{'token': ['evaluate', 'method', 'context', 'text', 'summarization', 'task', ',', 'show', 'results', 'obtained', 'compare', 'favorably', 'previously', 'published', 'results', 'established', 'benchmarks', '.'], 'h': {'name': 'method', 'pos': [1, 2]}, 't': {'name': 'text summarization task', 'pos': [3, 6]}, 'relation': 'usage'}
{'token': ['Preferred', 'antecedents', 'subset', 'possible', 'antecedents', ',', 'selected', 'application', 'extralinguistic', 'knowledge', '.'], 'h': {'name': 'Preferred antecedents', 'pos': [0, 2]}, 't': {'name': 'possible antecedents', 'pos': [3, 5]}, 'relation': 'part_whole'}
{'token': ['paper', 'presents', 'syntactic', 'description', 'fragment', 'German', 'worked', 'within', 'machine', 'translation', 'project', 'Eurotra', '.'], 'h': {'name': 'syntactic description', 'pos': [2, 4]}, 't': {'name': 'German', 'pos': [5, 6]}, 'relation': 'model-feature'}
{'token': ['represents', 'syntactic', 'part', 'German', 'module', 'multilingual', 'translation', 'system', '.'], 'h': {'name': 'syntactic part', 'pos': [1, 3]}, 't': {'name': 'German module', 'pos': [3, 5]}, 'relation': 'part_whole'}
{'token': ['present', 'approach', 'querying', 'collections', 'heterogeneous', 'linguistic', 'corpora', 'annotated', 'multiple', 'layers', 'using', 'arbitrary', 'XML', '-', 'based', 'markup', 'languages', '.'], 'h': {'name': 'multiple layers', 'pos': [8, 10]}, 't': {'name': 'heterogeneous linguistic corpora', 'pos': [4, 7]}, 'relation': 'model-feature'}
{'token': ['OWL', 'ontology', 'provides', 'homogenising', 'view', 'conceptually', 'different', 'markup', 'languages', 'common', 'querying', 'framework', 'established', 'using', 'method', 'ontology', '-', 'based', 'query', 'expansion', '.'], 'h': {'name': 'OWL ontology', 'pos': [0, 2]}, 't': {'name': 'markup languages', 'pos': [7, 9]}, 'relation': 'usage'}
{'token': ['OWL', 'ontology', 'provides', 'homogenising', 'view', 'conceptually', 'different', 'markup', 'languages', 'common', 'querying', 'framework', 'established', 'using', 'method', 'ontology', '-', 'based', 'query', 'expansion', '.'], 'h': {'name': 'ontology-based query expansion', 'pos': [15, 20]}, 't': {'name': 'querying framework', 'pos': [10, 12]}, 'relation': 'usage'}
{'token': ['interface', 'also', 'used', 'ontology', '-', 'based', 'querying', 'multiple', 'corpora', 'simultaneously', '.'], 'h': {'name': 'ontology-based querying', 'pos': [3, 7]}, 't': {'name': 'corpora', 'pos': [8, 9]}, 'relation': 'usage'}
{'token': ['also', 'evaluate', 'model', 'related', 'role', '-', 'labelling', 'task', ',', 'compare', 'standard', 'role', 'labeller', '.'], 'h': {'name': 'model', 'pos': [2, 3]}, 't': {'name': 'standard role labeller', 'pos': [10, 13]}, 'relation': 'compare'}
{'token': ['tasks', ',', 'model', 'benefits', 'class', '-', 'based', 'smoothing', ',', 'allows', 'make', 'correct', 'argument', '-specific', 'predictions', 'despite', 'a', 'sparse', 'data', 'problem', '.'], 'h': {'name': 'class-based smoothing', 'pos': [4, 8]}, 't': {'name': 'model', 'pos': [2, 3]}, 'relation': 'result'}
{'token': ['standard', 'labeller', 'suffers', 'sparse', 'data', 'strong', 'reliance', 'syntactic', 'cues', ',', 'especially', 'prediction', 'task', '.'], 'h': {'name': 'sparse data', 'pos': [3, 5]}, 't': {'name': 'standard labeller', 'pos': [0, 2]}, 'relation': 'result'}
{'token': ['standard', 'labeller', 'suffers', 'sparse', 'data', 'strong', 'reliance', 'syntactic', 'cues', ',', 'especially', 'prediction', 'task', '.'], 'h': {'name': 'syntactic cues', 'pos': [7, 9]}, 't': {'name': 'prediction task', 'pos': [11, 13]}, 'relation': 'usage'}
{'token': ['bootstrapping', 'fashion', ',', '-', 'called', "'", 'Pendulum', 'Algorithm', "'", 'operates', 'word', 'sets', 'obtained', 'co-occurrence', 'statistics', 'large', 'un-', 'annotated', 'corpus', 'and', 'error', 'propagation', 'low', 'by', 'step', '.'], 'h': {'name': "'Pendulum Algorithm'", 'pos': [5, 9]}, 't': {'name': 'word sets', 'pos': [10, 12]}, 'relation': 'usage'}
{'token': ['bootstrapping', 'fashion', ',', '-', 'called', "'", 'Pendulum', 'Algorithm', "'", 'operates', 'word', 'sets', 'obtained', 'co-occurrence', 'statistics', 'large', 'un-', 'annotated', 'corpus', 'and', 'error', 'propagation', 'low', 'by', 'step', '.'], 'h': {'name': 'co-occurrence statistics', 'pos': [13, 15]}, 't': {'name': 'large un-annotated corpus', 'pos': [15, 19]}, 'relation': 'part_whole'}
{'token': ['first', 'algorithm', ',', 'phone', '-', 'dependent', 'cepstral', 'compensation', ',', 'similar', 'concept', 'previously', '-', 'described', 'MFCDCN', 'method', ',', 'except', 'cepstral', 'compensation', 'vectors', 'selected', 'according', 'current', 'phonetic', 'hypothesis', ',', 'rather', 'basis', 'SNR', 'VQ', 'codeword', 'identity', '.'], 'h': {'name': 'phone-dependent cepstral compensation', 'pos': [3, 8]}, 't': {'name': 'MFCDCN method', 'pos': [14, 16]}, 'relation': 'compare'}
{'token': ['Use', 'various', 'compensation', 'algorithms', 'consort', 'produces', 'reduction', 'error', 'rates', 'SPHINX', '-', 'II', 'much', '40', 'percent', 'relative', 'rate', 'achieved', 'cepstral', 'mean', 'normalization', 'alone', ',', 'development', 'test', 'sets', 'context', '1993', 'ARPA', 'CSR', 'evaluations', '.'], 'h': {'name': 'compensation algorithms', 'pos': [2, 4]}, 't': {'name': 'reduction of error rates', 'pos': [6, 9]}, 'relation': 'result'}
{'token': ['One', 'critical', 'components', 'CLT', 'speech', 'recognition', 'system', 'used', 'track', 'child', "'s", 'progress', 'oral', 'reading', 'provide', 'sufficient', 'information', 'detect', 'reading', 'miscues', '.'], 'h': {'name': 'reading miscues', 'pos': [18, 20]}, 't': {'name': 'oral reading', 'pos': [12, 14]}, 'relation': 'part_whole'}
{'token': ['paper', ',', 'extend', 'prior', 'work', 'examining', 'novel', 'labeling', 'children', "'s", 'oral', 'reading', 'audio', 'data', 'order', 'better', 'understand', 'factors', 'contribute', 'significantly', 'speech', 'recognition', 'errors', '.'], 'h': {'name': 'labeling', 'pos': [7, 8]}, 't': {'name': 'oral reading audio data', 'pos': [10, 14]}, 'relation': 'model-feature'}
{'token': ['Next', ',', 'consider', 'problem', 'detecting', 'miscues', 'oral', 'reading', '.'], 'h': {'name': 'miscues', 'pos': [5, 6]}, 't': {'name': 'oral reading', 'pos': [6, 8]}, 'relation': 'part_whole'}
{'token': ['paper', 'introduces', 'simple', 'mixture', 'language', 'model', 'attempts', 'capture', 'long', 'distance', 'constraints', 'sentence', 'paragraph', '.'], 'h': {'name': 'long distance constraints', 'pos': [8, 11]}, 't': {'name': 'sentence', 'pos': [11, 12]}, 'relation': 'part_whole'}
{'token': ['Using', 'BU', 'recognition', 'system', ',', 'experiments', 'show', '7', '%', 'improvement', 'recognition', 'accuracy', 'mixture', 'digram', 'models', 'compared', 'using', 'Digram', 'model', '.'], 'h': {'name': 'BU recognition system', 'pos': [1, 4]}, 't': {'name': 'recognition accuracy', 'pos': [10, 12]}, 'relation': 'result'}
{'token': ['Using', 'BU', 'recognition', 'system', ',', 'experiments', 'show', '7', '%', 'improvement', 'recognition', 'accuracy', 'mixture', 'digram', 'models', 'compared', 'using', 'Digram', 'model', '.'], 'h': {'name': 'mixture digram models', 'pos': [12, 15]}, 't': {'name': 'Digram model', 'pos': [17, 19]}, 'relation': 'compare'}
{'token': ['identification', 'unknown', 'proper', 'names', 'text', 'significant', 'challenge', 'NLP', 'systems', 'operating', 'unrestricted', 'text', '.'], 'h': {'name': 'proper names', 'pos': [2, 4]}, 't': {'name': 'text', 'pos': [4, 5]}, 'relation': 'part_whole'}
{'token': ['identification', 'unknown', 'proper', 'names', 'text', 'significant', 'challenge', 'NLP', 'systems', 'operating', 'unrestricted', 'text', '.'], 'h': {'name': 'NLP systems', 'pos': [7, 9]}, 't': {'name': 'unrestricted text', 'pos': [10, 12]}, 'relation': 'usage'}
{'token': ['system', 'indexes', 'documents', 'according', 'name', 'references', 'useful', 'information', 'retrieval', 'preprocessor', 'knowledge', 'intensive', 'tasks', 'database', 'extraction', '.'], 'h': {'name': 'name references', 'pos': [4, 6]}, 't': {'name': 'documents', 'pos': [2, 3]}, 'relation': 'model-feature'}
{'token': ['paper', 'describes', 'system', 'uses', 'text', 'skimming', 'techniques', 'deriving', 'proper', 'names', 'semantic', 'attributes', 'automatically', 'newswire', 'text', ',', 'without', 'relying', 'listing', 'name', 'elements', '.'], 'h': {'name': 'semantic attributes', 'pos': [10, 12]}, 't': {'name': 'proper names', 'pos': [8, 10]}, 'relation': 'model-feature'}
{'token': ['order', 'identify', 'new', 'names', ',', 'system', 'treats', 'proper', 'names', '(', 'potentially', ')', 'context-dependent', 'linguistic', 'expressions', '.'], 'h': {'name': 'context-dependent linguistic expressions', 'pos': [12, 15]}, 't': {'name': 'proper names', 'pos': [7, 9]}, 'relation': 'model-feature'}
{'token': ['addition', 'using', 'information', 'local', 'context', ',', 'system', 'exploits', 'computational', 'model', 'discourse', 'identifies', 'individuals', 'based', 'way', 'described', 'text', ',', 'instead', 'relying', 'description', 'pre-existing', 'knowledge', 'base', '.'], 'h': {'name': 'information', 'pos': [2, 3]}, 't': {'name': 'local context', 'pos': [3, 5]}, 'relation': 'part_whole'}
{'token': ['entities', 'belong', 'less', 'class', '.'], 'h': {'name': 'entities', 'pos': [0, 1]}, 't': {'name': 'class', 'pos': [3, 4]}, 'relation': 'part_whole'}
{'token': ['specify', 'whether', 'individual', 'entity', 'belonging', 'class', 'typical', ',', 'borrow', 'topological', 'concepts', 'interior', ',', 'border', ',', 'closure', ',', 'exterior', '.'], 'h': {'name': 'entity', 'pos': [3, 4]}, 't': {'name': 'class', 'pos': [5, 6]}, 'relation': 'part_whole'}
{'token': ['enables', 'define', 'levels', 'typicality', 'individual', 'entities', 'less', 'typical', 'elements', 'concept', '.'], 'h': {'name': 'entities', 'pos': [5, 6]}, 't': {'name': 'concept', 'pos': [9, 10]}, 'relation': 'model-feature'}
{'token': ['WordNet', 'used', 'extensively', 'resource', 'Word', 'Sense', 'Disambiguation', '(', 'WSD', ')', 'task', ',', 'sense', 'inventory', 'repository', 'semantic', 'relationships', '.'], 'h': {'name': 'WordNet', 'pos': [0, 1]}, 't': {'name': 'Word Sense Disambiguation (WSD) task', 'pos': [4, 11]}, 'relation': 'usage'}
{'token': ['found', 'would', 'useful', 'assign', 'geographical', 'entities', 'Word', 'Net', 'coordinates', ',', 'especially', 'order', 'implement', 'geometric', 'shape', '-', 'based', 'disambiguation', 'methods', '.'], 'h': {'name': 'geographical entities', 'pos': [4, 6]}, 't': {'name': 'WordNet', 'pos': [6, 8]}, 'relation': 'part_whole'}
{'token': ['annotation', 'carried', 'extracting', 'geographical', 'synsets', 'WordNet', ',', 'together', 'holonyms', 'hypernyms', ',', 'comparing', 'entries', 'Wikipedia', '-', 'World', 'geographical', 'database', '.'], 'h': {'name': 'geographical synsets', 'pos': [3, 5]}, 't': {'name': 'WordNet', 'pos': [5, 6]}, 'relation': 'part_whole'}
{'token': ['weight', 'calculated', 'candidate', 'annotations', ',', 'basis', 'matches', 'found', 'database', 'entries', 'synset', 'gloss', ',', 'holonyms', 'hypernyms', '.'], 'h': {'name': 'weight', 'pos': [0, 1]}, 't': {'name': 'candidate annotations', 'pos': [2, 4]}, 'relation': 'model-feature'}
{'token': ['"', 'present', 'robust', 'summarisation', 'system', 'developed', 'within', 'GATE', 'architecture', 'makes', 'use', 'robust', 'components', 'semantic', 'tagging', 'coreference', 'resolution', 'provided', 'GATE', '.'], 'h': {'name': 'robust components', 'pos': [11, 13]}, 't': {'name': 'semantic tagging', 'pos': [13, 15]}, 'relation': 'usage'}
{'token': ['system', 'combines', 'GATE', 'components', 'well', 'established', 'statistical', 'techniques', 'developed', 'purpose', 'text', 'summarisation', 'research', '.'], 'h': {'name': 'statistical techniques', 'pos': [6, 8]}, 't': {'name': 'text summarisation research', 'pos': [10, 13]}, 'relation': 'usage'}
{'token': ['Prior', 'MUC', '-4', ',', 'LINK', 'had', 'to', 'information', 'from', 'free', '-', 'form', 'texts', 'in', 'narrow', 'application', 'domains', '.'], 'h': {'name': 'information', 'pos': [7, 8]}, 't': {'name': 'free-form texts', 'pos': [9, 13]}, 'relation': 'part_whole'}
{'token': ['One', 'application', 'corpus', 'contained', 'terse', 'descriptions', 'symptoms', 'displayed', 'malfunctioning', 'automobiles', ',', 'repairs', 'fixed', '.'], 'h': {'name': 'terse descriptions', 'pos': [4, 6]}, 't': {'name': 'application corpus', 'pos': [1, 3]}, 'relation': 'part_whole'}
{'token': ['empirical', 'testing', 'two', 'domains', ',', 'LINK', 'correctly', 'processed', '70', '%', 'previously', 'unseen', 'descriptions', '.'], 'h': {'name': 'LINK', 'pos': [5, 6]}, 't': {'name': 'descriptions', 'pos': [12, 13]}, 'relation': 'usage'}
{'token': ['template', 'counted', 'correct', 'fillers', 'template', 'filled', 'correctly', '.'], 'h': {'name': 'fillers', 'pos': [3, 4]}, 't': {'name': 'template', 'pos': [4, 5]}, 'relation': 'part_whole'}
{'token': ['previous', 'domains', 'much', 'narrower', 'MUC', '-', '4', 'terrorism', 'domain', '.'], 'h': {'name': 'domains', 'pos': [1, 2]}, 't': {'name': 'MUC-4 terrorism domain', 'pos': [4, 9]}, 'relation': 'compare'}
{'token': ['comparison', ',', 'lexicons', 'previous', 'domains', 'contained', '300', '-', '500', 'words', ',', 'compared', '6700', 'words', 'MUC', '-', '4', 'test', 'configuration', '.'], 'h': {'name': 'words', 'pos': [9, 10]}, 't': {'name': 'lexicons', 'pos': [2, 3]}, 'relation': 'part_whole'}
{'token': ['Previous', 'grammar', 'size', 'ranged', '75', '-', '100', 'rules', ',', 'compared', '500', 'rules', 'MUC', '-', '4', 'knowledge', 'base', '.'], 'h': {'name': 'grammar size', 'pos': [1, 3]}, 't': {'name': 'MUC-4 knowledge base', 'pos': [12, 17]}, 'relation': 'compare'}
{'token': ['Thus', ',', 'integration', 'information', 'multiple', 'sentences', 'issue', 'previous', 'work', '.'], 'h': {'name': 'information', 'pos': [3, 4]}, 't': {'name': 'sentences', 'pos': [5, 6]}, 'relation': 'part_whole'}
{'token': ['Brief', 'Summary', 'Objectives', ':', 'three', 'objectives', 'contract', ':', 'perform', 'research', 'development', 'parallel', 'parsing', ',', 'semantic', 'representation', ',', 'ill', '-', 'formed', 'input', ',', 'discourse', ',', 'tools', 'linguistic', 'knowledge', 'acquisition', ',', 'integrate', 'software', 'components', 'BBN', 'elsewhere', 'produce', 'Janus', ',', 'DARPA', "'s", 'New', 'Generation', 'Natural', 'Language', 'Interface', ',', 'demonstrate', 'state', '-', '-', '-', 'art', 'natural', 'language', 'technology', 'DARPA', 'applications', '.'], 'h': {'name': 'language technology', 'pos': [52, 54]}, 't': {'name': 'DARPA applications', 'pos': [54, 56]}, 'relation': 'usage'}
{'token': ['paper', ',', 'introduce', 'Tree', '-', 'Based', 'Pattern', 'representation', 'pattern', 'denoted', 'path', 'dependency', 'tree', 'sentence', '.'], 'h': {'name': 'dependency tree', 'pos': [11, 13]}, 't': {'name': 'sentence', 'pos': [13, 14]}, 'relation': 'model-feature'}
{'token': ['outline', 'procedure', 'acquire', 'Tree', '-', 'Based', 'Patterns', 'Japanese', 'un', '-', 'annotated', 'text', '.'], 'h': {'name': 'Tree-Based Patterns', 'pos': [3, 7]}, 't': {'name': 'un-annotated text', 'pos': [8, 12]}, 'relation': 'part_whole'}
{'token': ['system', 'extracts', 'relevant', 'sentences', 'training', 'data', 'based', 'TF', '/', 'IDF', 'scoring', 'common', 'paths', 'parse', 'tree', 'relevant', 'sentences', 'taken', 'extracted', 'patterns', '.'], 'h': {'name': 'sentences', 'pos': [3, 4]}, 't': {'name': 'training data', 'pos': [4, 6]}, 'relation': 'part_whole'}
{'token': ['system', 'extracts', 'relevant', 'sentences', 'training', 'data', 'based', 'TF', '/', 'IDF', 'scoring', 'common', 'paths', 'parse', 'tree', 'relevant', 'sentences', 'taken', 'extracted', 'patterns', '.'], 'h': {'name': 'parse tree', 'pos': [13, 15]}, 't': {'name': 'sentences', 'pos': [16, 17]}, 'relation': 'model-feature'}
{'token': ['overcome', 'problem', ',', 'present', 'paper', 'procedure', 'automatic', 'extraction', 'application', '-', 'tuned', 'consistent', 'subgrammars', 'proved', 'large', '-', 'scale', 'generation', 'grammars', '.'], 'h': {'name': 'application-tuned consistent subgrammars', 'pos': [8, 13]}, 't': {'name': 'large-scale generation grammars', 'pos': [14, 19]}, 'relation': 'part_whole'}
{'token': ['procedure', 'implemented', 'large', '-', 'scale', 'systemic', 'grammars', 'builds', 'formal', 'equivalence', 'systemic', 'grammars', 'typed', 'unification', 'based', 'grammars', '.'], 'h': {'name': 'systemic grammars', 'pos': [10, 12]}, 't': {'name': 'typed unification based grammars', 'pos': [12, 16]}, 'relation': 'compare'}
{'token': ['First', ',', 'task', 'performed', 'traditionally', 'using', 'heuristics', 'domain', '.'], 'h': {'name': 'heuristics', 'pos': [6, 7]}, 't': {'name': 'task', 'pos': [2, 3]}, 'relation': 'usage'}
{'token': ['present', 'comparative', 'evaluation', 'several', 'machine', 'learning', 'algorithms', 'applied', 'spam', 'filtering', ',', 'considering', 'text', 'messages', 'set', 'heuristics', 'task', '.'], 'h': {'name': 'machine learning algorithms', 'pos': [4, 7]}, 't': {'name': 'spam filtering', 'pos': [8, 10]}, 'relation': 'usage'}
{'token': ['present', 'comparative', 'evaluation', 'several', 'machine', 'learning', 'algorithms', 'applied', 'spam', 'filtering', ',', 'considering', 'text', 'messages', 'set', 'heuristics', 'task', '.'], 'h': {'name': 'heuristics', 'pos': [15, 16]}, 't': {'name': 'task', 'pos': [16, 17]}, 'relation': 'usage'}
{'token': ['framework', 'includes', 'dialog', 'history', 'tracks', 'input', ',', 'output', ',', 'results', '.'], 'h': {'name': 'dialog history', 'pos': [2, 4]}, 't': {'name': 'framework', 'pos': [0, 1]}, 'relation': 'part_whole'}
{'token': ['present', 'framework', 'preliminary', 'results', 'two', 'application', 'domains', '.'], 'h': {'name': 'framework', 'pos': [1, 2]}, 't': {'name': 'application domains', 'pos': [5, 7]}, 'relation': 'usage'}
{'token': ['Near-perfect', 'automatic', 'accent', 'assignment', 'attainable', 'citation', '-', 'style', 'speech', ',', 'better', 'computational', 'models', 'needed', 'predict', 'accent', 'extended', ',', 'spontaneous', 'discourses', '.'], 'h': {'name': 'automatic accent assignment', 'pos': [1, 4]}, 't': {'name': 'citation-style speech', 'pos': [5, 9]}, 'relation': 'usage'}
{'token': ['Near-perfect', 'automatic', 'accent', 'assignment', 'attainable', 'citation', '-', 'style', 'speech', ',', 'better', 'computational', 'models', 'needed', 'predict', 'accent', 'extended', ',', 'spontaneous', 'discourses', '.'], 'h': {'name': 'computational models', 'pos': [11, 13]}, 't': {'name': 'extended, spontaneous discourses', 'pos': [16, 20]}, 'relation': 'usage'}
{'token': ['Machine', 'learning', 'experiments', '1031', 'noun', 'phrases', 'eighteen', 'spontaneous', 'direction', '-', 'giving', 'monologues', 'show', 'accent', 'assignment', 'significantly', 'improved', '4', '%', '-', '6', '%', 'relative', 'hypothetical', 'baseline', 'system', 'would', 'produce', 'citation', '-', 'form', 'accentuation', ',', 'giving', 'error', 'rate', 'reductions', '11', '%', '-', '25', '%', '.'], 'h': {'name': 'Machine learning experiments', 'pos': [0, 3]}, 't': {'name': 'noun phrases', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['key', 'task', 'extraction', 'system', 'query-oriented', 'multi-document', 'summarisation', ',', 'necessary', 'computing', 'relevance', 'redundancy', ',', 'modelling', 'text', 'semantics', '.'], 'h': {'name': 'extraction system', 'pos': [2, 4]}, 't': {'name': 'query-oriented multi-document summarisation', 'pos': [4, 7]}, 'relation': 'usage'}
{'token': ['Accurate', 'dependency', 'recovery', 'recently', 'reported', 'number', 'wide', '-', 'coverage', 'statistical', 'parsers', 'using', 'Combinatory', 'Categorial', 'Grammar', '(', 'ccg', ')', '.'], 'h': {'name': 'Combinatory Categorial Grammar (ccg)', 'pos': [12, 18]}, 't': {'name': 'wide-coverage statistical parsers', 'pos': [6, 11]}, 'relation': 'usage'}
{'token': ['However', ',', 'overall', 'figures', 'give', 'indication', 'parser', "'s", 'performance', 'specific', 'constructions', ',', 'suitable', 'parser', 'specific', 'applications', '.'], 'h': {'name': 'parser', 'pos': [13, 14]}, 't': {'name': 'applications', 'pos': [15, 16]}, 'relation': 'usage'}
{'token': ['paper', 'give', 'detailed', 'evaluation', 'ccg', 'parser', 'object', 'extraction', 'dependencies', 'found', 'wsj', 'text', '.'], 'h': {'name': 'object extraction dependencies', 'pos': [6, 9]}, 't': {'name': 'wsj text', 'pos': [10, 12]}, 'relation': 'part_whole'}
{'token': ['also', 'show', 'parser', 'used', 'parse', 'questions', 'Question', 'Answering', '.'], 'h': {'name': 'parser', 'pos': [2, 3]}, 't': {'name': 'questions', 'pos': [5, 6]}, 'relation': 'usage'}
{'token': ['accuracy', 'original', 'parser', 'questions', 'poor', ',', 'propose', 'novel', 'technique', 'porting', 'parser', 'new', 'domain', ',', 'creating', 'new', 'labelled', 'data', 'lexical', 'category', 'level', '.'], 'h': {'name': 'parser', 'pos': [2, 3]}, 't': {'name': 'accuracy', 'pos': [0, 1]}, 'relation': 'result'}
{'token': ['Using', 'supertagger', 'assign', 'categories', 'words', ',', 'trained', 'new', 'data', ',', 'leads', 'dramatic', 'increase', 'question', 'parsing', 'accuracy', '.'], 'h': {'name': 'categories', 'pos': [3, 4]}, 't': {'name': 'words', 'pos': [4, 5]}, 'relation': 'model-feature'}
{'token': ['paper', 'addresses', 'syntax', '-', 'based', 'paraphrasing', 'methods', 'Recognizing', 'Textual', 'Entailment', '(', 'RTE', ')', '.'], 'h': {'name': 'syntax-based paraphrasing methods', 'pos': [2, 7]}, 't': {'name': 'Recognizing Textual Entailment (RTE)', 'pos': [7, 13]}, 'relation': 'usage'}
{'token': ['particular', ',', 'describe', 'dependency', '-', 'based', 'paraphrasing', 'algorithm', ',', 'using', 'DIRT', 'data', 'set', ',', 'application', 'context', 'straightforward', 'RTE', 'system', 'based', 'aligning', 'dependency', 'trees', '.'], 'h': {'name': 'DIRT data set', 'pos': [10, 13]}, 't': {'name': 'dependency-based paraphrasing algorithm', 'pos': [3, 8]}, 'relation': 'usage'}
{'token': ['goal', 'project', 'provide', 'quantitative', 'description', 'Polish', 'preposition', '-', 'pronoun', 'contractions', 'taking', 'consideration', 'morphosyntactic', 'properties', 'components', '.'], 'h': {'name': 'morphosyntactic properties', 'pos': [12, 14]}, 't': {'name': 'Polish preposition-pronoun contractions', 'pos': [5, 10]}, 'relation': 'model-feature'}
{'token': ['results', 'corpus', '-', 'based', 'investigations', 'distribution', 'prepositions', 'within', 'preposition', '-', 'pronoun', 'contractions', 'used', 'grammar-theoretical', 'lexicographic', 'purposes', '.'], 'h': {'name': 'distribution', 'pos': [5, 6]}, 't': {'name': 'prepositions', 'pos': [6, 7]}, 'relation': 'model-feature'}
{'token': ['paper', 'presents', 'new', 'unsupervised', 'algorithm', '(', 'Word', 'Ends', ')', 'inferring', 'word', 'boundaries', 'transcribed', 'adult', 'conversations', '.'], 'h': {'name': 'unsupervised algorithm', 'pos': [3, 5]}, 't': {'name': 'word boundaries', 'pos': [10, 12]}, 'relation': 'usage'}
{'token': ['fast', 'algorithm', 'delivers', 'high', 'performance', 'even', 'morphologically', 'complex', 'words', 'English', 'Arabic', ',', 'promising', 'results', 'accurate', 'phonetic', 'transcriptions', 'extensive', 'pronunciation', 'variation', '.'], 'h': {'name': 'algorithm', 'pos': [1, 2]}, 't': {'name': 'performance', 'pos': [4, 5]}, 'relation': 'result'}
{'token': ['suggests', 'Word', 'Ends', 'viable', 'model', 'child', 'language', 'acquisition', 'might', 'useful', 'speech', 'understanding', '.'], 'h': {'name': 'model', 'pos': [4, 5]}, 't': {'name': 'speech understanding', 'pos': [10, 12]}, 'relation': 'usage'}
{'token': ['Speech-to-', 'text', 'systems', 'usually', 'take', 'as', 'input', 'the', 'output', 'of', 'an', 'automatic', '(', 'ASR', ')', 'system', 'that', 'is', 'affected', 'like', 'recognition', 'errors', ',', 'disfluencies', ',', 'or', 'difficulties', 'in', 'accurate', 'sentence', 'boundaries'], 'h': {'name': 'output', 'pos': [8, 9]}, 't': {'name': 'Speech-to-text summarization systems', 'pos': [0, 3]}, 'relation': 'usage'}
{'token': ['propose', 'inclusion', 'related', ',', 'solid', 'background', 'information', 'cope', 'difficulties', 'summarizing', 'spoken', 'language', 'use', 'multi-document', 'summarization', 'techniques', 'single', 'document', 'speech', '-', '-', 'text', 'summarization', '.'], 'h': {'name': 'multi-document summarization techniques', 'pos': [13, 16]}, 't': {'name': 'single document speech-to-text summarization', 'pos': [16, 23]}, 'relation': 'usage'}
{'token': ['present', 'improved', 'method', 'automated', 'word', 'alignment', 'parallel', 'texts', 'takes', 'advantage', 'knowledge', 'syntactic', 'divergences', ',', 'avoiding', 'need', 'syntactic', 'analysis', 'less', 'resource', 'rich', 'language', ',', 'retaining', 'robustness', 'syntactically', 'agnostic', 'approaches', 'IBM', 'word', 'alignment', 'models', '.'], 'h': {'name': 'automated word alignment', 'pos': [3, 6]}, 't': {'name': 'parallel texts', 'pos': [6, 8]}, 'relation': 'usage'}
{'token': ['present', 'improved', 'method', 'automated', 'word', 'alignment', 'parallel', 'texts', 'takes', 'advantage', 'knowledge', 'syntactic', 'divergences', ',', 'avoiding', 'need', 'syntactic', 'analysis', 'less', 'resource', 'rich', 'language', ',', 'retaining', 'robustness', 'syntactically', 'agnostic', 'approaches', 'IBM', 'word', 'alignment', 'models', '.'], 'h': {'name': 'syntactic analysis', 'pos': [16, 18]}, 't': {'name': 'less resource rich language', 'pos': [18, 22]}, 'relation': 'topic'}
{'token': ['present', 'improved', 'method', 'automated', 'word', 'alignment', 'parallel', 'texts', 'takes', 'advantage', 'knowledge', 'syntactic', 'divergences', ',', 'avoiding', 'need', 'syntactic', 'analysis', 'less', 'resource', 'rich', 'language', ',', 'retaining', 'robustness', 'syntactically', 'agnostic', 'approaches', 'IBM', 'word', 'alignment', 'models', '.'], 'h': {'name': 'robustness', 'pos': [24, 25]}, 't': {'name': 'syntactically agnostic approaches', 'pos': [25, 28]}, 'relation': 'model-feature'}
{'token': ['achieve', 'using', 'simple', ',', 'easily', '-', 'elicited', 'knowledge', 'produce', 'syntax', '-', 'based', 'heuristics', 'transform', 'target', 'language', '(', 'e.g.', 'English', ')', 'form', 'closely', 'resembling', 'source', 'language', ',', 'using', 'standard', 'alignment', 'methods', 'align', 'transformed', 'bitext', '.'], 'h': {'name': 'syntax-based heuristics', 'pos': [9, 13]}, 't': {'name': 'target language', 'pos': [14, 16]}, 'relation': 'usage'}
{'token': ['knowledge', 'representation', 'method', 'introduced', 'applied', 'ICAI', 'system', 'teach', 'programming', 'language', '.'], 'h': {'name': 'knowledge representation method', 'pos': [0, 3]}, 't': {'name': 'ICAI system', 'pos': [5, 7]}, 'relation': 'usage'}
{'token': ['directed', 'graph', 'concepts', 'mentioned', 'method', 'represent', 'instructional', 'structure', 'domain', 'knowledge', '.'], 'h': {'name': 'directed graph', 'pos': [0, 2]}, 't': {'name': 'concepts', 'pos': [2, 3]}, 'relation': 'model-feature'}
{'token': ['consider', 'problem', 'extracting', 'specified', 'types', 'information', 'natural', 'language', 'text', '.'], 'h': {'name': 'information', 'pos': [5, 6]}, 't': {'name': 'natural language text', 'pos': [6, 9]}, 'relation': 'part_whole'}
{'token': ['describe', 'specific', 'information', 'extraction', 'task', ',', 'report', 'benefits', 'using', 'preference', 'semantics', 'task', '.'], 'h': {'name': 'preference semantics', 'pos': [9, 11]}, 't': {'name': 'information extraction task', 'pos': [2, 5]}, 'relation': 'usage'}
{'token': ['studies', 'result', 'semantic', 'annotation', 'corpus', 'domain', '.'], 'h': {'name': 'semantic annotation', 'pos': [2, 4]}, 't': {'name': 'corpus', 'pos': [4, 5]}, 'relation': 'usage'}
{'token': ['begin', 'explaining', 'criteria', 'involved', 'annotation', 'process', ',', 'colour', 'categories', 'also', 'colour', 'groups', 'created', 'order', 'finer', '-', 'grained', 'analyses', ',', 'presenting', 'also', 'quantitative', 'data', 'regarding', 'categories', 'groups', '.'], 'h': {'name': 'quantitative data', 'pos': [21, 23]}, 't': {'name': 'categories', 'pos': [24, 25]}, 'relation': 'model-feature'}
{'token': ['end', 'explaining', 'user', 'wants', 'serious', 'studies', 'using', 'corpus', 'collaborate', 'enhancing', 'corpus', 'making', 'semantic', 'annotations', 'widely', 'available', 'well', '.'], 'h': {'name': 'semantic annotations', 'pos': [12, 14]}, 't': {'name': 'corpus', 'pos': [10, 11]}, 'relation': 'model-feature'}
{'token': ['processing', 'tasks', 'involved', 'reconstructing', 'temporal', 'structure', 'narrative', '(', 'Webber', "'s", 'e/s', 'structure', ')', 'formulated', 'terms', 'two', 'notions', '.'], 'h': {'name': 'temporal structure', 'pos': [4, 6]}, 't': {'name': 'narrative', 'pos': [6, 7]}, 'relation': 'model-feature'}
{'token': ['remainder', 'paper', 'analyzes', 'durational', 'aspectual', 'knowledge', 'needed', 'tasks', '.'], 'h': {'name': 'durational and aspectual knowledge', 'pos': [3, 6]}, 't': {'name': 'tasks', 'pos': [7, 8]}, 'relation': 'usage'}
{'token': ['paper', 'present', 'project', 'aims', 'standardise', 'format', 'set', 'bilingual', 'lexicons', 'order', 'make', 'available', 'potential', 'users', ',', 'facilitate', 'exchange', 'data', '(', 'among', 'resources', '(', 'monolingual', ')', 'resources', ')', 'enable', 'reuse', 'lexicons', 'NLP', 'applications', 'like', 'machine', 'translation', 'multilingual', 'information', 'retrieval', '.'], 'h': {'name': 'lexicons', 'pos': [28, 29]}, 't': {'name': 'NLP applications', 'pos': [29, 31]}, 'relation': 'usage'}
{'token': ['exploiting', 'linguistic', 'discrepancy', 'numbered', 'arguments', 'ARGMs', ',', 'built', 'semantic', 'role', 'classifier', 'based', 'hierarchical', 'feature', 'selection', 'strategy', '.'], 'h': {'name': 'linguistic discrepancy', 'pos': [1, 3]}, 't': {'name': 'arguments', 'pos': [4, 5]}, 'relation': 'model-feature'}
{'token': ['exploiting', 'linguistic', 'discrepancy', 'numbered', 'arguments', 'ARGMs', ',', 'built', 'semantic', 'role', 'classifier', 'based', 'hierarchical', 'feature', 'selection', 'strategy', '.'], 'h': {'name': 'hierarchical feature selection strategy', 'pos': [12, 16]}, 't': {'name': 'semantic role classifier', 'pos': [8, 11]}, 'relation': 'usage'}
{'token': ['recent', 'years', 'tree', 'kernels', 'proposed', 'automatic', 'learning', 'natural', 'language', 'applications', '.'], 'h': {'name': 'tree kernels', 'pos': [2, 4]}, 't': {'name': 'automatic learning', 'pos': [5, 7]}, 'relation': 'usage'}
{'token': ['paper', ',', 'show', 'tree', 'kernels', 'helpful', 'processing', 'natural', 'language', '(', ')', 'provide', 'simple', 'algorithm', 'compute', 'tree', 'kernels', 'linear', 'average', 'running', 'time', '(', 'b', ')', 'study', 'classification', 'properties', 'diverse', 'tree', 'kernels', 'show', 'kernel', 'combinations', 'always', 'improve', 'traditional', 'methods', '.'], 'h': {'name': 'tree kernels', 'pos': [3, 5]}, 't': {'name': 'processing of natural language', 'pos': [6, 9]}, 'relation': 'usage'}
{'token': ['paper', ',', 'show', 'tree', 'kernels', 'helpful', 'processing', 'natural', 'language', '(', ')', 'provide', 'simple', 'algorithm', 'compute', 'tree', 'kernels', 'linear', 'average', 'running', 'time', '(', 'b', ')', 'study', 'classification', 'properties', 'diverse', 'tree', 'kernels', 'show', 'kernel', 'combinations', 'always', 'improve', 'traditional', 'methods', '.'], 'h': {'name': 'classification properties', 'pos': [25, 27]}, 't': {'name': 'tree kernels', 'pos': [28, 30]}, 'relation': 'model-feature'}
{'token': ['Experiments', 'Support', 'Vector', 'Machines', 'predicate', 'argument', 'classification', 'task', 'provide', 'empirical', 'support', 'thesis', '.'], 'h': {'name': 'Support Vector Machines', 'pos': [1, 4]}, 't': {'name': 'argument classification task', 'pos': [5, 8]}, 'relation': 'usage'}
{'token': ['paper', 'presents', 'study', 'military', 'applications', 'advanced', 'speech', 'processing', 'technology', 'includes', 'three', 'major', 'elements', ':', '(', '1', ')', 'review', 'assessment', 'current', 'efforts', 'military', 'applications', 'speech', 'technology', ';', '(', '2', ')', 'identification', 'opportunities', 'future', 'military', 'applications', 'advanced', 'speech', 'technology', ';', '(', '3', ')', 'identification', 'problem', 'areas', 'research', 'speech', 'processing', 'needed', 'meet', 'application', 'requirements', ',', 'current', 'research', 'thrusts', 'appear', 'promising', '.'], 'h': {'name': 'speech processing technology', 'pos': [6, 9]}, 't': {'name': 'military applications', 'pos': [3, 5]}, 'relation': 'usage'}
{'token': ['paper', 'presents', 'study', 'military', 'applications', 'advanced', 'speech', 'processing', 'technology', 'includes', 'three', 'major', 'elements', ':', '(', '1', ')', 'review', 'assessment', 'current', 'efforts', 'military', 'applications', 'speech', 'technology', ';', '(', '2', ')', 'identification', 'opportunities', 'future', 'military', 'applications', 'advanced', 'speech', 'technology', ';', '(', '3', ')', 'identification', 'problem', 'areas', 'research', 'speech', 'processing', 'needed', 'meet', 'application', 'requirements', ',', 'current', 'research', 'thrusts', 'appear', 'promising', '.'], 'h': {'name': 'speech technology', 'pos': [23, 25]}, 't': {'name': 'military applications', 'pos': [21, 23]}, 'relation': 'usage'}
{'token': ['paper', 'presents', 'study', 'military', 'applications', 'advanced', 'speech', 'processing', 'technology', 'includes', 'three', 'major', 'elements', ':', '(', '1', ')', 'review', 'assessment', 'current', 'efforts', 'military', 'applications', 'speech', 'technology', ';', '(', '2', ')', 'identification', 'opportunities', 'future', 'military', 'applications', 'advanced', 'speech', 'technology', ';', '(', '3', ')', 'identification', 'problem', 'areas', 'research', 'speech', 'processing', 'needed', 'meet', 'application', 'requirements', ',', 'current', 'research', 'thrusts', 'appear', 'promising', '.'], 'h': {'name': 'speech technology', 'pos': [35, 37]}, 't': {'name': 'military applications', 'pos': [32, 34]}, 'relation': 'usage'}
{'token': ['relationship', 'study', 'previous', 'assessments', 'military', 'applications', 'speech', 'technology', 'discussed', ',', 'substantial', 'recent', 'progress', 'noted', '.'], 'h': {'name': 'speech technology', 'pos': [6, 8]}, 't': {'name': 'military applications', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['Current', 'efforts', 'military', 'applications', 'speech', 'technology', 'highlighted', 'include', ':', '(', '1', ')', 'narrowband', '(', '2400', 'b', '/', ')', 'low-rate', '(', '50', '-', '1200', 'b', '/', ')', 'secure', 'voice', 'communication', ';', '(', '2', ')', 'voice', '/', 'data', 'integration', 'computer', 'networks', ';', '(', '3', ')', 'speech', 'recognition', 'fighter', 'aircraft', ',', 'military', 'helicopters', ',', 'battle', 'management', ',', 'air', 'traffic', 'control', 'training', 'systems', ';', '(', '4', ')', 'noise', 'interference', 'removal', 'human', 'listeners', '.'], 'h': {'name': 'speech technology', 'pos': [4, 6]}, 't': {'name': 'military applications', 'pos': [2, 4]}, 'relation': 'usage'}
{'token': ['framework', 'demonstrates', 'uniform', 'approach', 'generation', 'transfer', 'based', 'declarative', 'lexico-structural', 'transformations', 'dependency', 'structures', 'syntactic', 'conceptual', 'levels', '(', '"', 'uniform', 'lexico-structural', 'processing', '"', ')', '.'], 'h': {'name': 'declarative lexico-structural transformations', 'pos': [7, 10]}, 't': {'name': 'generation and transfer', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['Lexical', 'co-occurrence', 'statistics', 'becoming', 'widely', 'used', 'syntactic', 'analysis', 'unconstrained', 'text', '.'], 'h': {'name': 'Lexical co-occurrence statistics', 'pos': [0, 3]}, 't': {'name': 'syntactic analysis', 'pos': [6, 8]}, 'relation': 'usage'}
{'token': ['However', ',', 'analyses', 'based', 'solely', 'lexical', 'relationships', 'suffer', 'sparseness', 'data', ':', 'sometimes', 'necessary', 'use', 'less', 'informed', 'model', 'order', 'reliably', 'estimate', 'statistical', 'parameters', '.'], 'h': {'name': 'sparseness', 'pos': [8, 9]}, 't': {'name': 'data', 'pos': [9, 10]}, 'relation': 'model-feature'}
{'token': ['However', ',', 'analyses', 'based', 'solely', 'lexical', 'relationships', 'suffer', 'sparseness', 'data', ':', 'sometimes', 'necessary', 'use', 'less', 'informed', 'model', 'order', 'reliably', 'estimate', 'statistical', 'parameters', '.'], 'h': {'name': 'less informed model', 'pos': [14, 17]}, 't': {'name': 'statistical parameters', 'pos': [20, 22]}, 'relation': 'usage'}
{'token': ['example', ',', '"', 'lexical', 'association', '"', 'strategy', 'resolving', 'ambiguous', 'prepositional', 'phrase', 'attachments', '[', 'Hindle', 'Rooth', '1991', ']', 'takes', 'account', 'attachment', 'site', '(', 'verb', 'direct', 'object', ')', 'preposition', ',', 'ignoring', 'object', 'preposition', '.', 'investigated', 'extension', 'lexical', 'association', 'strategy', 'make', 'use', 'noun', 'class', 'information', ',', 'thus', 'permitting', 'disambiguation', 'strategy', 'take', 'information', 'account', '.'], 'h': {'name': '"lexical association"', 'pos': [2, 6]}, 't': {'name': 'resolving ambiguous prepositional phrase attachments', 'pos': [7, 12]}, 'relation': 'usage'}
{'token': ['example', ',', '"', 'lexical', 'association', '"', 'strategy', 'resolving', 'ambiguous', 'prepositional', 'phrase', 'attachments', '[', 'Hindle', 'Rooth', '1991', ']', 'takes', 'account', 'attachment', 'site', '(', 'verb', 'direct', 'object', ')', 'preposition', ',', 'ignoring', 'object', 'preposition', '.', 'investigated', 'extension', 'lexical', 'association', 'strategy', 'make', 'use', 'noun', 'class', 'information', ',', 'thus', 'permitting', 'disambiguation', 'strategy', 'take', 'information', 'account', '.'], 'h': {'name': 'noun class information', 'pos': [39, 42]}, 't': {'name': 'disambiguation', 'pos': [45, 46]}, 'relation': 'usage'}
{'token': ['Although', 'preliminary', 'experiments', 'extended', 'strategy', 'yield', 'improved', 'performance', 'lexical', 'association', 'alone', ',', 'qualitative', 'analysis', 'results', 'suggests', 'problem', 'lies', 'noun', 'class', 'information', ',', 'rather', 'multiplicity', 'classes', 'available', 'noun', 'absence', 'sense', 'disambiguation', '.'], 'h': {'name': 'qualitative analysis', 'pos': [12, 14]}, 't': {'name': 'results', 'pos': [14, 15]}, 'relation': 'topic'}
{'token': ['Although', 'preliminary', 'experiments', 'extended', 'strategy', 'yield', 'improved', 'performance', 'lexical', 'association', 'alone', ',', 'qualitative', 'analysis', 'results', 'suggests', 'problem', 'lies', 'noun', 'class', 'information', ',', 'rather', 'multiplicity', 'classes', 'available', 'noun', 'absence', 'sense', 'disambiguation', '.'], 'h': {'name': 'multiplicity of classes', 'pos': [23, 25]}, 't': {'name': 'noun', 'pos': [26, 27]}, 'relation': 'model-feature'}
{'token': ['paper', 'proposes', 'error-driven', 'HMM', '-', 'based', 'text', 'chunk', 'tagger', 'context', '-dependent', 'lexicon', '.'], 'h': {'name': 'context-dependent lexicon', 'pos': [9, 12]}, 't': {'name': 'error-driven HMM-based text chunk tagger', 'pos': [2, 9]}, 'relation': 'part_whole'}
{'token': ['Compared', 'standard', 'HMM', '-', 'based', 'tagger', ',', 'tagger', 'incorporates', 'contextual', 'information', 'lexical', 'entry', '.'], 'h': {'name': 'contextual information', 'pos': [9, 11]}, 't': {'name': 'tagger', 'pos': [7, 8]}, 'relation': 'usage'}
{'token': ['Finally', ',', 'memory', '-', 'based', 'learning', 'adopted', 'improve', 'performance', 'chunk', 'tagger', '.'], 'h': {'name': 'memory-based learning', 'pos': [2, 6]}, 't': {'name': 'chunk tagger', 'pos': [9, 11]}, 'relation': 'usage'}
{'token': ['However', ',', 'recent', 'evaluations', 'prototype', 'prediction', 'system', 'showed', 'significantly', 'decreased', 'productivity', 'translators', 'used', '.'], 'h': {'name': 'productivity', 'pos': [10, 11]}, 't': {'name': 'translators', 'pos': [11, 12]}, 'relation': 'model-feature'}
{'token': ['paper', ',', 'analyze', 'reasons', 'propose', 'solution', 'consists', 'seeking', 'predictions', 'maximize', 'expected', 'benefit', 'translator', ',', 'rather', 'trying', 'anticipate', 'amount', 'upcoming', 'text', '.'], 'h': {'name': 'predictions', 'pos': [8, 9]}, 't': {'name': 'expected benefit', 'pos': [10, 12]}, 'relation': 'result'}
{'token': ['Using', 'model', '“', 'typical', 'translator', '”', 'constructed', 'data', 'collected', 'evaluations', 'prediction', 'prototype', ',', 'show', 'approach', 'potential', 'turn', 'text', 'prediction', 'help', 'rather', 'hindrance', 'translator', '.'], 'h': {'name': 'data', 'pos': [7, 8]}, 't': {'name': 'prediction prototype', 'pos': [10, 12]}, 'relation': 'part_whole'}
{'token': ['"', 'describe', 'experimental', 'text', '-', '-', 'speech', 'system', 'uses', 'information', 'syntactic', 'constituency', ',', 'adjacency', 'verb', ',', 'constituent', 'length', 'determine', 'prosodic', 'phrasing', 'synthetic', 'speech', '.'], 'h': {'name': 'syntactic constituency', 'pos': [10, 12]}, 't': {'name': 'text-to-speech system', 'pos': [3, 8]}, 'relation': 'usage'}
{'token': ['Results', 'far', 'indicate', 'current', 'system', 'performs', 'well', 'measured', 'corpus', 'judgments', 'prosodic', 'phrasing', '.', '"'], 'h': {'name': 'judgments of prosodic phrasing', 'pos': [9, 12]}, 't': {'name': 'corpus', 'pos': [8, 9]}, 'relation': 'part_whole'}
{'token': ['paper', ',', 'present', 'algorithm', 'extracting', 'potential', 'entries', 'category', '-', 'line', 'corpus', ',', 'based', 'upon', 'small', 'set', 'exemplars', '.'], 'h': {'name': 'potential entries', 'pos': [5, 7]}, 't': {'name': 'on-line corpus', 'pos': [8, 11]}, 'relation': 'part_whole'}
{'token': ['paper', ',', 'describe', 'experiments', 'statistical', 'word', 'sense', 'disambiguation', '(', 'WSD', ')', 'using', 'two', 'systems', 'based', 'different', 'approaches', ':', 'Naive', 'Bayes', 'word', 'tokens', 'Maximum', 'Entropy', 'local', 'syntactic', 'semantic', 'features', '.'], 'h': {'name': 'word tokens', 'pos': [20, 22]}, 't': {'name': 'Naive Bayes', 'pos': [18, 20]}, 'relation': 'usage'}
{'token': ['paper', ',', 'describe', 'experiments', 'statistical', 'word', 'sense', 'disambiguation', '(', 'WSD', ')', 'using', 'two', 'systems', 'based', 'different', 'approaches', ':', 'Naive', 'Bayes', 'word', 'tokens', 'Maximum', 'Entropy', 'local', 'syntactic', 'semantic', 'features', '.'], 'h': {'name': 'local syntactic and semantic features', 'pos': [24, 28]}, 't': {'name': 'Maximum Entropy', 'pos': [22, 24]}, 'relation': 'usage'}
{'token': ['first', 'approach', ',', 'consider', 'context', 'window', 'sub', '-', 'window', 'within', 'around', 'word', 'disambiguate', '.'], 'h': {'name': 'sub-window', 'pos': [6, 9]}, 't': {'name': 'context window', 'pos': [4, 6]}, 'relation': 'part_whole'}
{'token': ['second', 'system', ',', 'sense', 'resolution', 'done', 'using', 'approximate', 'syntactic', 'structure', 'well', 'semantics', 'neighboring', 'nouns', 'features', 'Maximum', 'Entropy', 'learner', '.'], 'h': {'name': 'syntactic structure', 'pos': [8, 10]}, 't': {'name': 'sense resolution', 'pos': [3, 5]}, 'relation': 'usage'}
{'token': ['second', 'system', ',', 'sense', 'resolution', 'done', 'using', 'approximate', 'syntactic', 'structure', 'well', 'semantics', 'neighboring', 'nouns', 'features', 'Maximum', 'Entropy', 'learner', '.'], 'h': {'name': 'semantics', 'pos': [11, 12]}, 't': {'name': 'neighboring nouns', 'pos': [12, 14]}, 'relation': 'model-feature'}
{'token': ['Document', 'Understanding', 'Conference', '(', 'DUC', ')', '2005', 'evaluation', 'single', 'user-oriented', ',', 'question', '-', 'focused', 'summarization', 'task', ',', 'synthesize', 'set', '25', '-', '50', 'documents', 'well', '-', 'organized', ',', 'fluent', 'answer', 'complex', 'question', '.'], 'h': {'name': 'user-oriented, question-focused summarization task', 'pos': [9, 16]}, 't': {'name': 'documents', 'pos': [22, 23]}, 'relation': 'usage'}
{'token': ['evaluation', 'shows', 'best', 'summarization', 'systems', 'difficulty', 'extracting', 'relevant', 'sentences', 'response', 'complex', 'questions', '(', 'opposed', 'representative', 'sentences', 'might', 'appropriate', 'generic', 'summary', ')', '.'], 'h': {'name': 'summarization systems', 'pos': [3, 5]}, 't': {'name': 'extracting relevant sentences', 'pos': [6, 9]}, 'relation': 'usage'}
{'token': ['paper', 'presents', 'two', 'systems', 'textual', 'entailment', ',', 'employing', 'decision', 'trees', 'supervised', 'learning', 'algorithm', '.'], 'h': {'name': 'decision trees', 'pos': [8, 10]}, 't': {'name': 'textual entailment', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['first', 'one', 'based', 'primarily', 'concept', 'lexical', 'overlap', ',', 'considering', 'bag', 'words', 'similarity', 'overlap', 'measure', 'form', 'mapping', 'terms', 'hypothesis', 'source', 'text', '.'], 'h': {'name': 'bag of words similarity overlap measure', 'pos': [9, 14]}, 't': {'name': 'mapping', 'pos': [15, 16]}, 'relation': 'usage'}
{'token': ['contrast', 'MT', 'condition', ',', 'text', 'audio', 'data', 'types', ',', 'high', 'quality', 'human', 'reference', 'Gold', 'Standard', '(', 'GS', ')', 'translations', '.'], 'h': {'name': 'MT condition', 'pos': [1, 3]}, 't': {'name': 'human reference Gold Standard (GS) translations', 'pos': [11, 19]}, 'relation': 'compare'}
{'token': ['Overall', ',', 'subjects', 'achieved', '95', '%', 'comprehension', 'GS', '74', '%', 'MT', ',', 'across', '4', 'genres', '3', 'difficulty', 'levels', '.'], 'h': {'name': 'GS', 'pos': [7, 8]}, 't': {'name': 'MT', 'pos': [10, 11]}, 'relation': 'compare'}
{'token': ['paper', 'describes', 'novel', 'event-matching', 'strategy', 'using', 'features', 'obtained', 'transitive', 'closure', 'dependency', 'relations', '.'], 'h': {'name': 'features', 'pos': [6, 7]}, 't': {'name': 'event-matching strategy', 'pos': [3, 5]}, 'relation': 'usage'}
{'token': ['paper', 'describes', 'novel', 'event-matching', 'strategy', 'using', 'features', 'obtained', 'transitive', 'closure', 'dependency', 'relations', '.'], 'h': {'name': 'transitive closure', 'pos': [8, 10]}, 't': {'name': 'dependency relations', 'pos': [10, 12]}, 'relation': 'usage'}
{'token': ['method', 'yields', 'model', 'capable', 'matching', 'events', 'F-measure', '66.5', '%.'], 'h': {'name': 'model', 'pos': [2, 3]}, 't': {'name': 'matching events', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['objective', 'paper', 'demonstrate', 'existing', 'web', 'application', 'modified', 'using', 'VoiceXML', 'enable', 'non-', 'visual', 'access', 'from', '.'], 'h': {'name': 'VoiceXML', 'pos': [8, 9]}, 't': {'name': 'web application', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['order', 'elucidate', 'entire', 'process', ',', 'present', 'sample', 'Package', 'Tracking', 'System', 'application', ',', 'based', 'existing', 'website', 'provides', 'functionality', 'website', '.'], 'h': {'name': 'website', 'pos': [14, 15]}, 't': {'name': 'Package Tracking System application', 'pos': [7, 11]}, 'relation': 'usage'}
{'token': ['paper', 'reports', 'development', 'log-linear', 'models', 'disambiguation', 'wide', '-', 'coverage', 'HPSG', 'parsing', '.'], 'h': {'name': 'log-linear models', 'pos': [3, 5]}, 't': {'name': 'disambiguation in wide-coverage HPSG parsing', 'pos': [5, 11]}, 'relation': 'usage'}
{'token': ['estimation', 'log', '-', 'linear', 'models', 'requires', 'high', 'computational', 'cost', ',', 'especially', 'wide', '-', 'coverage', 'grammars', '.'], 'h': {'name': 'computational cost', 'pos': [7, 9]}, 't': {'name': 'log-linear models', 'pos': [1, 5]}, 'relation': 'model-feature'}
{'token': ['series', 'experiments', 'empirically', 'evaluated', 'estimation', 'techniques', ',', 'also', 'examined', 'performance', 'disambiguation', 'models', 'parsing', 'real', '-', 'world', 'sentences', '.'], 'h': {'name': 'disambiguation models', 'pos': [10, 12]}, 't': {'name': 'parsing', 'pos': [12, 13]}, 'relation': 'usage'}
{'token': ['Text', 'normalization', 'important', 'aspect', 'successful', 'information', 'retrieval', 'medical', 'documents', 'clinical', 'notes', ',', 'radiology', 'reports', 'discharge', 'summaries'], 'h': {'name': 'information retrieval', 'pos': [5, 7]}, 't': {'name': 'medical documents', 'pos': [7, 9]}, 'relation': 'usage'}
{'token': ['medical', 'domain', ',', 'significant', 'part', 'general', 'problem', 'text', 'normalization', 'abbreviation', 'acronym', 'disambiguation', '.'], 'h': {'name': 'abbreviation and acronym disambiguation', 'pos': [9, 12]}, 't': {'name': 'text normalization', 'pos': [7, 9]}, 'relation': 'part_whole'}
{'token': ['Numerous', 'abbreviations', 'used', 'routinely', 'throughout', 'texts', 'knowing', 'meaning', 'critical', 'data', 'retrieval', 'document', '.'], 'h': {'name': 'abbreviations', 'pos': [1, 2]}, 't': {'name': 'texts', 'pos': [5, 6]}, 'relation': 'part_whole'}
{'token': ['Numerous', 'abbreviations', 'used', 'routinely', 'throughout', 'texts', 'knowing', 'meaning', 'critical', 'data', 'retrieval', 'document', '.'], 'h': {'name': 'data retrieval', 'pos': [9, 11]}, 't': {'name': 'document', 'pos': [11, 12]}, 'relation': 'usage'}
{'token': ['paper', 'demonstrate', 'method', 'automatically', 'generating', 'training', 'data', 'Maximum', 'Entropy', '(', ')', 'modeling', 'abbreviations', 'acronyms', 'show', 'using', 'modeling', 'promising', 'technique', 'abbreviation', 'acronym', 'normalization', '.'], 'h': {'name': 'automatically generating training data', 'pos': [3, 7]}, 't': {'name': 'Maximum Entropy (ME) modeling', 'pos': [7, 12]}, 'relation': 'usage'}
{'token': ['paper', 'demonstrate', 'method', 'automatically', 'generating', 'training', 'data', 'Maximum', 'Entropy', '(', ')', 'modeling', 'abbreviations', 'acronyms', 'show', 'using', 'modeling', 'promising', 'technique', 'abbreviation', 'acronym', 'normalization', '.'], 'h': {'name': 'ME modeling', 'pos': [16, 17]}, 't': {'name': 'abbreviation and acronym normalization', 'pos': [19, 22]}, 'relation': 'usage'}
{'token': ['report', 'results', 'experiment', 'involving', 'training', 'number', 'models', 'used', 'normalize', 'abbreviations', 'acronyms', 'sample', '10,000', 'rheumatology', 'notes', '~', '89', '%', 'accuracy', '.'], 'h': {'name': 'ME models', 'pos': [6, 7]}, 't': {'name': 'abbreviations', 'pos': [9, 10]}, 'relation': 'usage'}
{'token': ['paper', 'describe', 'roots', 'Controlled', 'English', '(', 'CE', ')', ',', 'analysis', 'several', 'existing', 'CE', 'grammars', ',', 'development', 'well', '-', 'founded', '150', '-', 'rule', 'CE', 'grammar', '(', 'COGRAM', ')', ',', 'elaboration', 'algorithmic', 'variant', '(', 'ALCOGRAM', ')', 'basis', 'NLP', 'applications', ',', 'use', 'ALCOGRAM', 'CA1', 'program', 'teaching', 'writers', 'use', 'effectively', ',', 'preparatory', 'study', 'Controlled', 'English', 'grammar', 'style', 'checker', 'within', 'desktop', 'publishing', '(', 'DTP', ')', 'environment', '.'], 'h': {'name': 'algorithmic variant (ALCOGRAM)', 'pos': [29, 34]}, 't': {'name': 'NLP applications', 'pos': [35, 37]}, 'relation': 'usage'}
{'token': ['paper', 'describe', 'roots', 'Controlled', 'English', '(', 'CE', ')', ',', 'analysis', 'several', 'existing', 'CE', 'grammars', ',', 'development', 'well', '-', 'founded', '150', '-', 'rule', 'CE', 'grammar', '(', 'COGRAM', ')', ',', 'elaboration', 'algorithmic', 'variant', '(', 'ALCOGRAM', ')', 'basis', 'NLP', 'applications', ',', 'use', 'ALCOGRAM', 'CA1', 'program', 'teaching', 'writers', 'use', 'effectively', ',', 'preparatory', 'study', 'Controlled', 'English', 'grammar', 'style', 'checker', 'within', 'desktop', 'publishing', '(', 'DTP', ')', 'environment', '.'], 'h': {'name': 'ALCOGRAM', 'pos': [39, 40]}, 't': {'name': 'CA1 program', 'pos': [40, 42]}, 'relation': 'usage'}
{'token': ['paper', 'describe', 'roots', 'Controlled', 'English', '(', 'CE', ')', ',', 'analysis', 'several', 'existing', 'CE', 'grammars', ',', 'development', 'well', '-', 'founded', '150', '-', 'rule', 'CE', 'grammar', '(', 'COGRAM', ')', ',', 'elaboration', 'algorithmic', 'variant', '(', 'ALCOGRAM', ')', 'basis', 'NLP', 'applications', ',', 'use', 'ALCOGRAM', 'CA1', 'program', 'teaching', 'writers', 'use', 'effectively', ',', 'preparatory', 'study', 'Controlled', 'English', 'grammar', 'style', 'checker', 'within', 'desktop', 'publishing', '(', 'DTP', ')', 'environment', '.'], 'h': {'name': 'style checker', 'pos': [52, 54]}, 't': {'name': 'desktop publishing (DTP) environment', 'pos': [55, 61]}, 'relation': 'part_whole'}
{'token': ['present', 'discriminative', ',', 'latent', 'variable', 'approach', 'syntactic', 'parsing', 'rules', 'exist', 'multiple', 'scales', 'refinement', '.'], 'h': {'name': 'discriminative, latent variable approach', 'pos': [1, 6]}, 't': {'name': 'syntactic parsing', 'pos': [6, 8]}, 'relation': 'usage'}
{'token': ['present', 'discriminative', ',', 'latent', 'variable', 'approach', 'syntactic', 'parsing', 'rules', 'exist', 'multiple', 'scales', 'refinement', '.'], 'h': {'name': 'refinement', 'pos': [12, 13]}, 't': {'name': 'rules', 'pos': [8, 9]}, 'relation': 'model-feature'}
{'token': ['model', 'formally', 'latent', 'variable', 'CRF', 'grammar', 'trees', ',', 'learned', 'iteratively', 'splitting', 'grammar', 'productions', '(', 'categories', ')', '.'], 'h': {'name': 'grammar productions', 'pos': [11, 13]}, 't': {'name': 'latent variable CRF grammar', 'pos': [2, 6]}, 'relation': 'usage'}
{'token': ['variety', 'domains', 'languages', ',', 'method', 'produces', 'best', 'published', 'parsing', 'accuracies', 'smallest', 'reported', 'grammars', '.'], 'h': {'name': 'method', 'pos': [4, 5]}, 't': {'name': 'parsing accuracies', 'pos': [8, 10]}, 'relation': 'result'}
{'token': ['paper', 'presents', 'extended', 'GLR', 'parsing', 'algorithm', 'grammar', 'PCFG', '*', 'based', 'Tomita', "'s", 'GLR', 'parsing', 'algorithm', 'extends', '.'], 'h': {'name': 'grammar PCFG*', 'pos': [6, 9]}, 't': {'name': 'extended GLR parsing algorithm', 'pos': [2, 6]}, 'relation': 'usage'}
{'token': ['paper', 'presents', 'extended', 'GLR', 'parsing', 'algorithm', 'grammar', 'PCFG', '*', 'based', 'Tomita', "'s", 'GLR', 'parsing', 'algorithm', 'extends', '.'], 'h': {'name': "Tomita's GLR parsing algorithm", 'pos': [10, 15]}, 't': {'name': 'grammar PCFG*', 'pos': [6, 9]}, 'relation': 'usage'}
{'token': ['also', 'define', 'new', 'grammar', 'PCFG', '*', 'based', 'PCFG', 'assigns', 'probability', 'also', 'frequency', 'associated', 'rule', '.'], 'h': {'name': 'PCFG', 'pos': [7, 8]}, 't': {'name': 'grammar PCFG*', 'pos': [3, 6]}, 'relation': 'usage'}
{'token': ['also', 'define', 'new', 'grammar', 'PCFG', '*', 'based', 'PCFG', 'assigns', 'probability', 'also', 'frequency', 'associated', 'rule', '.'], 'h': {'name': 'frequency', 'pos': [11, 12]}, 't': {'name': 'rule', 'pos': [13, 14]}, 'relation': 'model-feature'}
{'token': ['syntactic', 'parsing', 'system', 'implemented', 'based', 'rule', '-', 'based', 'approach', 'statistics', 'approach', '.'], 'h': {'name': 'rule-based approach', 'pos': [5, 9]}, 't': {'name': 'syntactic parsing system', 'pos': [0, 3]}, 'relation': 'usage'}
{'token': ['paper', 'method', 'controlling', 'dialog', 'natural', 'language', '(', 'NL', ')', 'system', 'presented', '.'], 'h': {'name': 'controlling the dialog', 'pos': [2, 4]}, 't': {'name': 'natural language (NL) system', 'pos': [4, 10]}, 'relation': 'part_whole'}
{'token': ['provides', 'deep', 'modeling', 'information', 'processing', 'based', 'time', 'dependent', 'propositional', 'attitudes', 'interacting', 'agents', '.'], 'h': {'name': 'time dependent propositional attitudes', 'pos': [6, 10]}, 't': {'name': 'modeling', 'pos': [2, 3]}, 'relation': 'usage'}
{'token': ['Knowledge', 'state', 'dialog', 'represented', 'dedicated', 'language', 'changes', 'state', 'described', 'compact', 'set', 'rules', '.'], 'h': {'name': 'state', 'pos': [1, 2]}, 't': {'name': 'dialog', 'pos': [2, 3]}, 'relation': 'model-feature'}
{'token': ['appropriate', 'organization', 'rule', 'application', 'introduced', 'including', 'initiation', 'adequate', 'system', 'reaction', '.'], 'h': {'name': 'initiation', 'pos': [6, 7]}, 't': {'name': 'rule application', 'pos': [2, 4]}, 'relation': 'part_whole'}
{'token': ['paper', 'reports', 'principles', 'behind', 'designing', 'tagset', 'cover', 'Russian', 'morphosyntactic', 'phenomena', ',', 'modifications', 'core', 'tagset', ',', 'evaluation', '.'], 'h': {'name': 'tagset', 'pos': [5, 6]}, 't': {'name': 'Russian morphosyntactic phenomena', 'pos': [7, 10]}, 'relation': 'model-feature'}
{'token': ['final', 'tagset', 'contains', '600', 'tags', 'achieves', '95', '%', 'accuracy', 'disambiguated', 'portion', 'Russian', 'National', 'Corpus', '.'], 'h': {'name': 'tags', 'pos': [4, 5]}, 't': {'name': 'tagset', 'pos': [1, 2]}, 'relation': 'part_whole'}
{'token': ['Within', 'framework', 'translation', 'knowledge', 'acquisition', 'WWW', 'news', 'sites', ',', 'paper', 'studies', 'issues', 'effect', 'cross', '-language', 'retrieval', 'of', 'texts', 'in', 'lexicon', 'acquisition', 'from', 'corpora', '.'], 'h': {'name': 'translation knowledge acquisition', 'pos': [2, 5]}, 't': {'name': 'WWW news sites', 'pos': [5, 8]}, 'relation': 'usage'}
{'token': ['Within', 'framework', 'translation', 'knowledge', 'acquisition', 'WWW', 'news', 'sites', ',', 'paper', 'studies', 'issues', 'effect', 'cross', '-language', 'retrieval', 'of', 'texts', 'in', 'lexicon', 'acquisition', 'from', 'comparable', 'corpora', '.'], 'h': {'name': 'texts', 'pos': [17, 18]}, 't': {'name': 'comparable corpora', 'pos': [22, 24]}, 'relation': 'part_whole'}
{'token': ['experimentally', 'show', 'quite', 'effective', 'reduce', 'candidate', 'bilingual', 'term', 'pairs', 'bilingual', 'term', 'correspondences', 'estimated', ',', 'terms', 'computational', 'complexity', 'performance', 'precise', 'estimation', 'bilingual', 'term', 'correspondences', '.'], 'h': {'name': 'estimation', 'pos': [19, 20]}, 't': {'name': 'bilingual term correspondences', 'pos': [20, 23]}, 'relation': 'model-feature'}
{'token': ['present', 'approach', 'building', 'test', 'collection', 'research', 'papers', '.'], 'h': {'name': 'research papers', 'pos': [5, 7]}, 't': {'name': 'test collection', 'pos': [3, 5]}, 'relation': 'part_whole'}
{'token': ['resultant', 'test', 'collection', 'different', 'TREC', "'s", 'comprises', 'scientific', 'articles', 'rather', 'newspaper', 'text', ',', 'thus', ',', 'allows', 'IR', 'experiments', 'include', 'citation', 'information', '.'], 'h': {'name': 'scientific articles', 'pos': [7, 9]}, 't': {'name': 'test collection', 'pos': [1, 3]}, 'relation': 'part_whole'}
{'token': ['test', 'collection', 'currently', 'consists', '170', 'queries', 'relevance', 'judgements', ';', 'document', 'collection', 'ACL', 'Anthology', '.'], 'h': {'name': 'queries', 'pos': [5, 6]}, 't': {'name': 'test collection', 'pos': [0, 2]}, 'relation': 'part_whole'}
{'token': ['paper', 'presents', 'model', 'generating', 'prosodically', 'appropriate', 'synthesized', 'responses', 'database', 'queries', 'using', 'Combinatory', 'Categorial', 'Grammar', '(', 'CCG', '-', 'cf.'], 'h': {'name': 'Combinatory Categorial Grammar', 'pos': [11, 14]}, 't': {'name': 'prosodically appropriate synthesized responses', 'pos': [4, 8]}, 'relation': 'usage'}
{'token': ['part', 'TIPSTER', 'III', 'research', 'program', ',', 'continued', 'research', 'strategies', 'resolve', 'coreferences', 'within', 'free', 'text', 'document', ';', 'research', 'begun', 'TIPSTER', 'II', 'research', 'program', '.'], 'h': {'name': 'coreferences', 'pos': [10, 11]}, 't': {'name': 'free text document', 'pos': [12, 15]}, 'relation': 'part_whole'}
{'token': ['also', 'raised', 'importance', 'understanding', 'structure', 'document', 'order', 'guide', 'coreference', 'resolution', 'process', '.'], 'h': {'name': 'structure', 'pos': [4, 5]}, 't': {'name': 'document', 'pos': [5, 6]}, 'relation': 'model-feature'}
{'token': ['describe', 'design', 'implementation', 'dialogue', 'management', 'module', 'voice', 'operated', 'car-driver', 'information', 'system', '.'], 'h': {'name': 'dialogue management module', 'pos': [3, 6]}, 't': {'name': 'voice operated car-driver information system', 'pos': [6, 11]}, 'relation': 'part_whole'}
{'token': ['paper', ',', 'show', 'constraints', 'influence', 'design', 'subsequent', 'implementation', 'Dialogue', 'Manager', 'module', ',', 'additional', 'requirements', 'fit', '7', 'commandments', '.'], 'h': {'name': 'constraints', 'pos': [3, 4]}, 't': {'name': 'Dialogue Manager module', 'pos': [8, 11]}, 'relation': 'result'}
{'token': ['HMM', '-', 'based', 'models', 'developed', 'alignment', 'words', 'phrases', 'bitext'], 'h': {'name': 'HMM-based models', 'pos': [0, 4]}, 't': {'name': 'alignment', 'pos': [5, 6]}, 'relation': 'usage'}
{'token': ['find', 'Chinese', '-', 'English', 'word', 'alignment', 'performance', 'comparable', 'IBM', 'Model', '-4', 'even', 'large', 'training', 'bitexts', '.'], 'h': {'name': 'Chinese-English word alignment performance', 'pos': [1, 7]}, 't': {'name': 'IBM Model-4', 'pos': [8, 11]}, 'relation': 'compare'}
{'token': ['Phrase', 'pairs', 'extracted', 'word', 'alignments', 'generated', 'model', 'also', 'used', 'phrase', '-', 'based', 'translation', ',', 'Chinese', 'English', 'Arabic', 'English', 'translation', ',', 'performance', 'comparable', 'systems', 'based', 'Model', '-', '4', 'alignments', '.'], 'h': {'name': 'Phrase pairs', 'pos': [0, 2]}, 't': {'name': 'word alignments', 'pos': [3, 5]}, 'relation': 'part_whole'}
{'token': ['Phrase', 'pairs', 'extracted', 'word', 'alignments', 'generated', 'model', 'also', 'used', 'phrase', '-', 'based', 'translation', ',', 'Chinese', 'English', 'Arabic', 'English', 'translation', ',', 'performance', 'comparable', 'systems', 'based', 'Model', '-', '4', 'alignments', '.'], 'h': {'name': 'Model-4 alignments', 'pos': [24, 28]}, 't': {'name': 'systems', 'pos': [22, 23]}, 'relation': 'usage'}
{'token': ['paper', 'proposed', 'new', 'query', 'translation', 'method', 'based', 'mutual', 'information', 'matrices', 'terms', 'Chinese', 'English', 'corpora', '.'], 'h': {'name': 'mutual information matrices', 'pos': [7, 10]}, 't': {'name': 'query translation method', 'pos': [3, 6]}, 'relation': 'usage'}
{'token': ['novel', 'selection', 'method', 'translations', 'query', 'terms', 'also', 'presented', 'detail', '.'], 'h': {'name': 'selection method', 'pos': [1, 3]}, 't': {'name': 'translations', 'pos': [3, 4]}, 'relation': 'usage'}
{'token': ['evaluation', 'results', 'show', 'retrieval', 'performance', 'achieved', 'query', 'translation', 'method', '73', '%', 'monolingual', 'information', 'retrieval', '28', '%', 'higher', 'simple', 'word', '-', '-', 'word', 'translation', 'way', '.'], 'h': {'name': 'query translation method', 'pos': [6, 9]}, 't': {'name': 'retrieval performance', 'pos': [3, 5]}, 'relation': 'result'}
{'token': ['First', ',', 'describe', 'method', 'classifying', 'facts', '(', 'information', ')', 'categories', 'levels', ';', 'level', 'signifies', 'different', 'degree', 'difficulty', 'extracting', 'fact', 'piece', 'text', 'containing', '.'], 'h': {'name': 'level', 'pos': [12, 13]}, 't': {'name': 'degree of difficulty', 'pos': [15, 17]}, 'relation': 'model-feature'}
{'token': ['First', ',', 'describe', 'method', 'classifying', 'facts', '(', 'information', ')', 'categories', 'levels', ';', 'level', 'signifies', 'different', 'degree', 'difficulty', 'extracting', 'fact', 'piece', 'text', 'containing', '.'], 'h': {'name': 'fact', 'pos': [18, 19]}, 't': {'name': 'text', 'pos': [20, 21]}, 'relation': 'part_whole'}
{'token': ['two', 'main', 'factors', 'characterize', 'text', 'content', 'style', ',', 'used', 'means', 'categorization', '.'], 'h': {'name': 'categorization', 'pos': [10, 11]}, 't': {'name': 'text', 'pos': [4, 5]}, 'relation': 'usage'}
{'token': ['paper', 'present', 'approach', 'text', 'categorization', 'terms', 'genre', 'author', 'Modern', 'Greek', '.'], 'h': {'name': 'genre', 'pos': [6, 7]}, 't': {'name': 'text categorization', 'pos': [3, 5]}, 'relation': 'usage'}
{'token': ['end', ',', 'propose', 'set', 'style', 'markers', 'including', 'analysis-level', 'measures', 'represent', 'way', 'input', 'text', 'analyzed', 'capture', 'useful', 'stylistic', 'information', 'without', 'additional', 'cost', '.'], 'h': {'name': 'analysis-level measures', 'pos': [7, 9]}, 't': {'name': 'style markers', 'pos': [4, 6]}, 'relation': 'part_whole'}
{'token': ['present', 'set', 'small', '-', 'scale', 'reasonable', 'experiments', 'text', 'genre', 'detection', ',', 'author', 'identification', ',', 'author', 'verification', 'tasks', 'show', 'proposed', 'method', 'performs', 'better', 'popular', 'distributional', 'lexical', 'measures', ',', 'i.e.', ',', 'functions', 'vocabulary', 'richness', 'frequencies', 'occurrence', 'frequent', 'words', '.'], 'h': {'name': 'proposed method', 'pos': [18, 20]}, 't': {'name': 'distributional lexical measures', 'pos': [23, 26]}, 'relation': 'compare'}
{'token': ['present', 'set', 'small', '-', 'scale', 'reasonable', 'experiments', 'text', 'genre', 'detection', ',', 'author', 'identification', ',', 'author', 'verification', 'tasks', 'show', 'proposed', 'method', 'performs', 'better', 'popular', 'distributional', 'lexical', 'measures', ',', 'i.e.', ',', 'functions', 'vocabulary', 'richness', 'frequencies', 'occurrence', 'frequent', 'words', '.'], 'h': {'name': 'frequencies of occurrence', 'pos': [32, 34]}, 't': {'name': 'words', 'pos': [35, 36]}, 'relation': 'model-feature'}
{'token': ['presented', 'experiments', 'based', 'unrestricted', 'text', 'downloaded', 'World', 'Wide', 'Web', 'without', 'manual', 'text', 'preprocessing', 'text', 'sampling', '.'], 'h': {'name': 'unrestricted text', 'pos': [3, 5]}, 't': {'name': 'World Wide Web', 'pos': [6, 9]}, 'relation': 'part_whole'}
{'token': ['system', 'used', 'application', 'requires', 'fast', 'easily', 'adaptable', 'text', 'categorization', 'terms', 'stylistically', 'homogeneous', 'categories', '.'], 'h': {'name': 'system', 'pos': [0, 1]}, 't': {'name': 'application', 'pos': [2, 3]}, 'relation': 'usage'}
{'token': ['first', 'split', 'dataset', 'consisting', 'pairs', 'sentences', 'clusters', 'according', 'similarities', ',', 'construct', 'classifier', 'cluster', 'identify', 'equivalence', 'relations', '.'], 'h': {'name': 'sentences', 'pos': [5, 6]}, 't': {'name': 'dataset', 'pos': [2, 3]}, 'relation': 'part_whole'}
{'token': ['paper', ',', 'propose', 'new', 'learning', 'method', 'solve', 'sparse', 'data', 'problem', 'automatic', 'extraction', 'bilingual', 'word', 'pairs', 'parallel', 'corpora', 'various', 'languages', '.'], 'h': {'name': 'learning method', 'pos': [4, 6]}, 't': {'name': 'sparse data problem', 'pos': [7, 10]}, 'relation': 'usage'}
{'token': ['paper', ',', 'propose', 'new', 'learning', 'method', 'solve', 'sparse', 'data', 'problem', 'automatic', 'extraction', 'bilingual', 'word', 'pairs', 'parallel', 'corpora', 'various', 'languages', '.'], 'h': {'name': 'bilingual word pairs', 'pos': [12, 15]}, 't': {'name': 'parallel corpora', 'pos': [15, 17]}, 'relation': 'part_whole'}
{'token': ['learning', 'method', 'automatically', 'acquires', 'rules', ',', 'effective', 'solve', 'sparse', 'data', 'problem', ',', 'parallel', 'corpora', 'without', 'bilingual', 'resource', '(', 'e.g.', ',', 'bilingual', 'dictionary', ',', 'machine', 'translation', 'systems', ')', 'beforehand', '.'], 'h': {'name': 'rules', 'pos': [4, 5]}, 't': {'name': 'sparse data problem', 'pos': [8, 11]}, 'relation': 'usage'}
{'token': ['Using', 'ICL', ',', 'recall', 'three', 'systems', 'based', 'similarity', 'measures', 'improved', 'respectively', '8.0', ',', '6.1', '6.0', 'percentage', 'points', '.'], 'h': {'name': 'similarity measures', 'pos': [7, 9]}, 't': {'name': 'systems', 'pos': [5, 6]}, 'relation': 'usage'}
{'token': ['NLP', 'systems', 'tasks', 'question', 'answering', 'information', 'extraction', 'typically', 'rely', 'statistical', 'parsers'], 'h': {'name': 'statistical parsers', 'pos': [9, 11]}, 't': {'name': 'NLP systems', 'pos': [0, 2]}, 'relation': 'usage'}
{'token': ['efficacy', 'parsers', 'surprisingly', 'low', ',', 'particularly', 'sentences', 'drawn', 'heterogeneous', 'corpora', 'Web', '.'], 'h': {'name': 'sentences', 'pos': [6, 7]}, 't': {'name': 'heterogeneous corpora', 'pos': [8, 10]}, 'relation': 'part_whole'}
{'token': ['observed', 'incorrect', 'parses', 'often', 'result', 'wildly', 'implausible', 'semantic', 'interpretations', 'sentences', ',', 'detected', 'automatically', 'using', 'semantic', 'information', 'obtained', 'Web', '.'], 'h': {'name': 'semantic interpretations', 'pos': [7, 9]}, 't': {'name': 'sentences', 'pos': [9, 10]}, 'relation': 'model-feature'}
{'token': ['observed', 'incorrect', 'parses', 'often', 'result', 'wildly', 'implausible', 'semantic', 'interpretations', 'sentences', ',', 'detected', 'automatically', 'using', 'semantic', 'information', 'obtained', 'Web', '.'], 'h': {'name': 'semantic information', 'pos': [14, 16]}, 't': {'name': 'Web', 'pos': [17, 18]}, 'relation': 'part_whole'}
{'token': ['demonstrate', 'previously', 'defined', 'formal', 'algebra', 'applies', 'grammar', 'engineering', 'across', 'much', 'greater', 'range', 'frameworks', 'originally', 'envisaged', '.'], 'h': {'name': 'formal algebra', 'pos': [3, 5]}, 't': {'name': 'grammar engineering', 'pos': [6, 8]}, 'relation': 'usage'}
{'token': ['show', 'algebra', 'adapted', 'composition', 'grammar', 'frameworks', 'lexicon', 'assumed', ',', 'underlies', 'practical', 'implementation', 'semantic', 'construction', 'RASP', 'system', '.'], 'h': {'name': 'semantic construction', 'pos': [12, 14]}, 't': {'name': 'RASP system', 'pos': [14, 16]}, 'relation': 'usage'}
{'token': ['explore', 'use', 'Wikipedia', 'external', 'knowledge', 'improve', 'named', 'entity', 'recognition', '(', 'NER', ')', '.'], 'h': {'name': 'Wikipedia', 'pos': [2, 3]}, 't': {'name': 'named entity recognition (NER)', 'pos': [6, 12]}, 'relation': 'usage'}
{'token': ['method', 'retrieves', 'corresponding', 'Wikipedia', 'entry', 'candidate', 'word', 'sequence', 'extracts', 'category', 'label', 'first', 'sentence', 'entry', ',', 'thought', 'definition', 'part', '.'], 'h': {'name': 'category label', 'pos': [9, 11]}, 't': {'name': 'sentence', 'pos': [12, 13]}, 'relation': 'part_whole'}
{'token': ['category', 'labels', 'used', 'features', 'CRF', '-', 'based', 'NE', 'tagger', '.'], 'h': {'name': 'features', 'pos': [3, 4]}, 't': {'name': 'CRF-based NE tagger', 'pos': [4, 9]}, 'relation': 'usage'}
{'token': ['argue', 'criticism', 'aimed', 'HMM', 'performance', 'languages', 'rich', 'morphology', 'properly', 'directed', 'TnT', "'s", 'peculiar', 'license', ',', 'free', 'open', 'source', ',', 'since', 'details', 'implementation', 'hidden', 'user', 'hold', 'key', 'improved', 'POS', 'tagging', 'across', 'wider', 'variety', 'languages', '.'], 'h': {'name': 'POS tagging', 'pos': [27, 29]}, 't': {'name': 'languages', 'pos': [32, 33]}, 'relation': 'usage'}
{'token': ['present', 'novel', 'approach', 'word', 'reordering', 'successfully', 'integrates', 'syntactic', 'structural', 'knowledge', 'phrase', '-', 'based', 'SMT', '.'], 'h': {'name': 'syntactic structural knowledge', 'pos': [7, 10]}, 't': {'name': 'word reordering', 'pos': [3, 5]}, 'relation': 'usage'}
{'token': ['done', 'constructing', 'lattice', 'alternatives', 'based', 'automatically', 'learned', 'probabilistic', 'syntactic', 'rules', '.'], 'h': {'name': 'probabilistic syntactic rules', 'pos': [7, 10]}, 't': {'name': 'lattice of alternatives', 'pos': [2, 4]}, 'relation': 'usage'}
{'token': ['decoding', ',', 'alternatives', 'scored', 'based', 'output', 'word', 'order', ',', 'order', 'input', '.'], 'h': {'name': 'output word order', 'pos': [5, 8]}, 't': {'name': 'alternatives', 'pos': [2, 3]}, 'relation': 'model-feature'}
{'token': ['Manual', 'evaluation', 'supports', 'claim', 'present', 'approach', 'significantly', 'superior', 'previous', 'approaches', '.'], 'h': {'name': 'approach', 'pos': [5, 6]}, 't': {'name': 'approaches', 'pos': [9, 10]}, 'relation': 'compare'}
{'token': ['previous', 'Korean', 'noun', 'extraction', 'systems', 'use', 'morphological', 'analyzer', 'Part-of', '-', '(', 'POS', ')', 'tagger', '.'], 'h': {'name': 'morphological analyzer', 'pos': [6, 8]}, 't': {'name': 'Korean noun extraction systems', 'pos': [1, 5]}, 'relation': 'usage'}
{'token': ['paper', 'proposes', 'new', 'noun', 'extraction', 'method', 'uses', 'syllable', 'based', 'word', 'recognition', 'model', '.'], 'h': {'name': 'syllable based word recognition model', 'pos': [7, 12]}, 't': {'name': 'noun extraction method', 'pos': [3, 6]}, 'relation': 'usage'}
{'token': ['finds', 'probable', 'syllable', '-', 'tag', 'sequence', 'input', 'sentence', 'using', 'automatically', 'acquired', 'statistical', 'information', 'POS', 'tagged', 'corpus', 'extracts', 'nouns', 'detecting', 'word', 'boundaries', '.'], 'h': {'name': 'syllable-tag sequence', 'pos': [2, 6]}, 't': {'name': 'input sentence', 'pos': [6, 8]}, 'relation': 'model-feature'}
{'token': ['finds', 'probable', 'syllable', '-', 'tag', 'sequence', 'input', 'sentence', 'using', 'automatically', 'acquired', 'statistical', 'information', 'POS', 'tagged', 'corpus', 'extracts', 'nouns', 'detecting', 'word', 'boundaries', '.'], 'h': {'name': 'automatically acquired statistical information', 'pos': [9, 13]}, 't': {'name': 'POS tagged corpus', 'pos': [13, 16]}, 'relation': 'part_whole'}
{'token': ['experimental', 'results', 'show', 'without', 'morphological', 'analysis', 'POS', 'tagging', ',', 'proposed', 'method', 'achieves', 'comparable', 'performance', 'previous', 'methods', '.'], 'h': {'name': 'proposed method', 'pos': [9, 11]}, 't': {'name': 'performance', 'pos': [13, 14]}, 'relation': 'result'}
{'token': ['paper', 'proposes', 'approach', 'improve', 'word', 'alignment', 'languages', 'scarce', 'resources', 'using', 'bilingual', 'corpora', 'language', 'pairs', '.'], 'h': {'name': 'word alignment', 'pos': [4, 6]}, 't': {'name': 'languages with scarce resources', 'pos': [6, 9]}, 'relation': 'usage'}
{'token': ['Based', 'two', 'additional', 'corpora', 'L3', 'pivot', 'language', ',', 'build', 'word', 'alignment', 'model', 'L1', 'L2', '.'], 'h': {'name': 'word alignment model', 'pos': [9, 12]}, 't': {'name': 'L1 and L2', 'pos': [12, 14]}, 'relation': 'usage'}
{'token': ['approach', 'build', 'word', 'alignment', 'model', 'two', 'languages', 'even', 'bilingual', 'corpus', 'available', 'language', 'pair', '.'], 'h': {'name': 'word alignment model', 'pos': [2, 5]}, 't': {'name': 'languages', 'pos': [6, 7]}, 'relation': 'usage'}
{'token': ['addition', ',', 'build', 'another', 'word', 'alignment', 'model', 'L1', 'L2', 'using', 'small', 'L1', '-', 'L2', 'bilingual', 'corpus', '.'], 'h': {'name': 'L1-L2 bilingual corpus', 'pos': [11, 16]}, 't': {'name': 'word alignment model', 'pos': [4, 7]}, 'relation': 'usage'}
{'token': ['paper', 'provides', 'approach', 'semi-automatic', 'extraction', 'collocations', 'corpora', 'using', 'statistics', '.'], 'h': {'name': 'collocations', 'pos': [5, 6]}, 't': {'name': 'corpora', 'pos': [6, 7]}, 'relation': 'part_whole'}
{'token': ['paper', ',', 'address', 'problem', 'nested', 'collocations', ';', ',', 'part', 'longer', 'collocations', '.'], 'h': {'name': 'nested collocations', 'pos': [4, 6]}, 't': {'name': 'collocations', 'pos': [10, 11]}, 'relation': 'part_whole'}
{'token': ['approaches', 'till', ',', 'treated', 'substring', 'collocations', 'collocations', 'appeared', 'frequently', 'enough', 'corpus', '.'], 'h': {'name': 'collocations', 'pos': [6, 7]}, 't': {'name': 'corpus', 'pos': [10, 11]}, 'relation': 'part_whole'}
{'token': ['Surprisingly', ',', 'students', 'initiative', 'time', 'didactic', 'dialogues', '(', '21', '%', 'turns', ')', 'Socratic', 'dialogues', '(', '10', '%', 'turns', ')', ',', 'direct', 'relationship', 'student', 'initiative', 'learning', '.'], 'h': {'name': 'initiative', 'pos': [3, 4]}, 't': {'name': 'didactic dialogues', 'pos': [5, 7]}, 'relation': 'model-feature'}
{'token': ['However', ',', 'Socratic', 'dialogues', 'interactive', 'didactic', 'dialogues', 'measured', 'percentage', 'tutor', 'utterances', 'questions', 'percentage', 'words', 'dialogue', 'uttered', 'student', ',', 'interactivity', 'positive', 'correlation', 'learning', '.'], 'h': {'name': 'Socratic dialogues', 'pos': [2, 4]}, 't': {'name': 'didactic dialogues', 'pos': [5, 7]}, 'relation': 'compare'}
{'token': ['present', 'several', 'statistical', 'models', 'syntactic', 'constituent', 'order', 'sentence', 'realization', '.'], 'h': {'name': 'statistical models', 'pos': [2, 4]}, 't': {'name': 'syntactic constituent order', 'pos': [4, 7]}, 'relation': 'model-feature'}
{'token': ['compare', 'several', 'models', ',', 'including', 'simple', 'joint', 'models', 'inspired', 'existing', 'statistical', 'parsing', 'models', ',', 'several', 'novel', 'conditional', 'models', '.'], 'h': {'name': 'joint models', 'pos': [6, 8]}, 't': {'name': 'conditional models', 'pos': [16, 18]}, 'relation': 'compare'}
{'token': ['employ', 'version', 'model', 'evaluation', 'unordered', 'trees', 'Penn', 'Tree', 'Bank', '.'], 'h': {'name': 'model', 'pos': [2, 3]}, 't': {'name': 'unordered trees', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['system', 'would', 'accomplish', 'speech', 'reconstruction', 'spontaneous', 'speech', 'input', 'output', 'represent', ',', 'flawless', ',', 'fluent', ',', 'content', '-', 'preserving', 'English', ',', 'message', 'speaker', 'intended', 'convey', '.'], 'h': {'name': 'speech reconstruction', 'pos': [3, 5]}, 't': {'name': 'spontaneous speech input', 'pos': [5, 8]}, 'relation': 'usage'}
{'token': ['cleaner', 'speech', 'transcripts', 'would', 'allow', 'accurate', 'language', 'processing', 'needed', 'NLP', 'tasks', 'machine', 'translation', 'conversation', 'summarization', ',', 'often', 'rely', 'grammatical', 'input', '.'], 'h': {'name': 'grammatical input', 'pos': [18, 20]}, 't': {'name': 'conversation summarization', 'pos': [13, 15]}, 'relation': 'usage'}
{'token': ['small', 'corpus', 'reconstructed', 'aligned', 'conversational', 'telephone', 'speech', 'transcriptions', 'Fisher', 'conversational', 'telephone', 'speech', 'corpus', '(', 'Strassel', 'Walker', ',', '2004', ')', 'annotated', 'several', 'levels', 'including', 'string', 'transformations', 'predicate', '-', 'argument', 'structure', ',', 'shared', 'linguistic', 'research', 'community', '.'], 'h': {'name': 'reconstructed and aligned conversational telephone speech transcriptions', 'pos': [2, 8]}, 't': {'name': 'corpus', 'pos': [1, 2]}, 'relation': 'part_whole'}
{'token': ['corpus', 'contains', 'recordings', 'approximately', '77', 'hours', 'broadcast', 'news', 'shows', 'Norwegian', 'broadcasting', 'company', 'NRK', '.'], 'h': {'name': 'recordings', 'pos': [2, 3]}, 't': {'name': 'corpus', 'pos': [0, 1]}, 'relation': 'part_whole'}
{'token': ['corpus', 'covers', 'read', 'spontaneous', 'speech', 'well', 'spontaneous', 'dialogues', 'multipart', 'discussions', ',', 'including', 'frequent', 'occurrences', 'non-', 'speech', 'material', '(', 'e.g.', 'music', ',', 'jingles', ')', '.'], 'h': {'name': 'read and spontaneous speech', 'pos': [2, 5]}, 't': {'name': 'corpus', 'pos': [0, 1]}, 'relation': 'part_whole'}
{'token': ['RUNDKAST', 'corpus', 'planned', 'included', 'future', 'national', 'Norwegian', 'language', 'resource', 'bank', '.'], 'h': {'name': 'RUNDKAST corpus', 'pos': [0, 2]}, 't': {'name': 'Norwegian language resource bank', 'pos': [6, 10]}, 'relation': 'part_whole'}
{'token': ['Statistical', 'measures', 'word', 'similarity', 'application', 'many', 'areas', 'natural', 'language', 'processing', ',', 'language', 'modeling', 'information', 'retrieval'], 'h': {'name': 'Statistical measures', 'pos': [0, 2]}, 't': {'name': 'word similarity', 'pos': [2, 4]}, 'relation': 'model-feature'}
{'token': ['frequency', 'estimates', 'generated', 'terabyte', '-', 'sized', 'corpus', 'Web', 'data', ',', 'study', 'impact', 'corpus', 'size', 'effectiveness', 'measures', '.'], 'h': {'name': 'Web data', 'pos': [7, 9]}, 't': {'name': 'corpus', 'pos': [6, 7]}, 'relation': 'part_whole'}
{'token': ['frequency', 'estimates', 'generated', 'terabyte', '-', 'sized', 'corpus', 'Web', 'data', ',', 'study', 'impact', 'corpus', 'size', 'effectiveness', 'measures', '.'], 'h': {'name': 'corpus size', 'pos': [12, 14]}, 't': {'name': 'measures', 'pos': [15, 16]}, 'relation': 'result'}
{'token': ['base', 'evaluation', 'one', 'TOEFL', 'question', 'set', 'two', 'practice', 'questions', 'sets', ',', 'consisting', 'number', 'multiple', 'choice', 'questions', 'seeking', 'best', 'synonym', 'given', 'target', 'word', '.'], 'h': {'name': 'multiple choice questions', 'pos': [13, 16]}, 't': {'name': 'practice questions sets', 'pos': [7, 10]}, 'relation': 'part_whole'}
{'token': ['stack', 'decoder', 'attractive', 'algorithm', 'controlling', 'acoustic', 'language', 'model', 'matching', 'continuous', 'speech', 'recognizer', '.'], 'h': {'name': 'stack decoder', 'pos': [0, 2]}, 't': {'name': 'acoustic and language model', 'pos': [5, 8]}, 'relation': 'usage'}
{'token': ['previous', 'paper', 'described', 'near-optimal', 'admissible', 'Viterbi', 'A*', 'search', 'algorithm', 'use', 'non-', 'cross', '-', 'word', 'acoustic', 'models', 'and', 'language', 'models', '[', '16', ']', '.'], 'h': {'name': 'non-cross-word acoustic models', 'pos': [10, 16]}, 't': {'name': 'Viterbi A* search algorithm', 'pos': [5, 9]}, 'relation': 'usage'}
{'token': ['addition', ',', 'make', 'proposal', 'organising', 'intermodule', 'communication', 'NLG', 'system', 'central', 'server', 'information', '.'], 'h': {'name': 'NLG system', 'pos': [7, 9]}, 't': {'name': 'intermodule communication', 'pos': [5, 7]}, 'relation': 'usage'}
{'token': ['paper', 'describes', 'sense', 'tagging', 'technique', 'automatic', 'sense', 'tagging', 'running', 'Chinese', 'text', '.'], 'h': {'name': 'automatic sense tagging', 'pos': [5, 8]}, 't': {'name': 'running Chinese text', 'pos': [8, 11]}, 'relation': 'usage'}
{'token': ['Whereas', 'previous', 'work', '(', 'Yarowsky', ',', '1992', ';', 'Gale', 'et', 'al.', ',', '1992', ',', '1993', ')', 'relies', 'heavily', 'role', 'statistics', ',', 'present', 'system', 'makes', 'use', 'Machine', 'Readable', '/', 'Tractable', 'Dictionaries', '(', 'Wilks', 'et', 'al.', ',', '1990', ';', 'Guo', ',', 'press', ')', 'example', '-', 'based', 'reasoning', 'technique', '(', 'Nagao', ',', '1984', ';', 'Sumita', 'et', 'al.', ',', '1990', ')', 'treat', 'novel', 'words', ',', 'compound', 'words', ',', 'phrases', 'found', 'input', 'text', '.'], 'h': {'name': 'phrases', 'pos': [64, 65]}, 't': {'name': 'input text', 'pos': [66, 68]}, 'relation': 'part_whole'}
{'token': ['syntactic', 'description', 'autonomous', 'sense', 'certain', 'explicit', 'formal', 'properties', '.'], 'h': {'name': 'formal properties', 'pos': [6, 8]}, 't': {'name': 'syntactic description', 'pos': [0, 2]}, 'relation': 'model-feature'}
{'token': ['description', 'relates', 'semantic', 'interpretation', 'sentences', ',', 'surface', 'text', '.'], 'h': {'name': 'semantic interpretation', 'pos': [2, 4]}, 't': {'name': 'sentences', 'pos': [4, 5]}, 'relation': 'model-feature'}
{'token': ['formalism', 'implemented', 'broad', '-', 'coverage', 'syntactic', 'parser', ',', 'concentrate', 'issues', 'must', 'resolved', 'practical', 'system', 'uses', 'models', '.'], 'h': {'name': 'formalism', 'pos': [0, 1]}, 't': {'name': 'broad-coverage syntactic parser', 'pos': [2, 7]}, 'relation': 'usage'}
{'token': ['present', 'algorithm', 'systematic', 'evaluation', 'system', 'recognize', 'salient', 'textual', 'properties', 'contribute', 'global', 'argumentative', 'structure', 'text', '.'], 'h': {'name': 'argumentative structure', 'pos': [11, 13]}, 't': {'name': 'text', 'pos': [13, 14]}, 'relation': 'model-feature'}
{'token': ['operates', 'either', 'interactively', ',', 'allowing', 'word', '-', '-', 'word', 'evaluation', 'hypothesized', 'sound', 'changes', 'semantic', 'shifts', ',', '"', 'batch', '"', 'mode', ',', 'processing', 'entire', 'multilingual', 'lexicons', '.'], 'h': {'name': 'word-by-word evaluation', 'pos': [5, 10]}, 't': {'name': 'hypothesized sound changes', 'pos': [10, 13]}, 'relation': 'usage'}
{'token': ['describe', 'algorithms', 'implemented', ',', 'specifically', 'parsing', 'combinatorial', 'techniques', 'used', 'make', 'projections', 'upstream', 'downstream', 'sense', 'time', ',', 'procedures', 'creating', 'consolidating', 'cognate', 'sets', 'based', 'projections', ',', 'ad', 'hoc', 'techniques', 'developed', 'handling', 'semantic', 'component', 'comparative', 'method', '.'], 'h': {'name': 'combinatorial techniques', 'pos': [6, 8]}, 't': {'name': 'projections', 'pos': [10, 11]}, 'relation': 'usage'}
{'token': ['describe', 'algorithms', 'implemented', ',', 'specifically', 'parsing', 'combinatorial', 'techniques', 'used', 'make', 'projections', 'upstream', 'downstream', 'sense', 'time', ',', 'procedures', 'creating', 'consolidating', 'cognate', 'sets', 'based', 'projections', ',', 'ad', 'hoc', 'techniques', 'developed', 'handling', 'semantic', 'component', 'comparative', 'method', '.'], 'h': {'name': 'projections', 'pos': [22, 23]}, 't': {'name': 'cognate sets', 'pos': [19, 21]}, 'relation': 'usage'}
{'token': ['describe', 'algorithms', 'implemented', ',', 'specifically', 'parsing', 'combinatorial', 'techniques', 'used', 'make', 'projections', 'upstream', 'downstream', 'sense', 'time', ',', 'procedures', 'creating', 'consolidating', 'cognate', 'sets', 'based', 'projections', ',', 'ad', 'hoc', 'techniques', 'developed', 'handling', 'semantic', 'component', 'comparative', 'method', '.'], 'h': {'name': 'semantic component', 'pos': [29, 31]}, 't': {'name': 'comparative method', 'pos': [31, 33]}, 'relation': 'part_whole'}
{'token': ['Finally', ',', 'discuss', 'features', 'make', 'possible', 'handle', 'complex', 'sometimes', 'imprecise', 'representations', 'lexical', 'items', ',', 'speculate', 'possible', 'directions', 'future', 'research', '.'], 'h': {'name': 'representations', 'pos': [10, 11]}, 't': {'name': 'lexical items', 'pos': [11, 13]}, 'relation': 'model-feature'}
{'token': ['paper', ',', 'present', 'chunk', 'based', 'partial', 'parsing', 'system', 'spontaneous', ',', 'conversational', 'speech', 'unrestricted', 'domains', '.'], 'h': {'name': 'chunk based partial parsing system', 'pos': [3, 8]}, 't': {'name': 'spontaneous, conversational speech', 'pos': [8, 12]}, 'relation': 'usage'}
{'token': ['input', 'system', 'N-best', 'lists', 'generated', 'speech', 'recognizer', 'lattices', '.'], 'h': {'name': 'speech recognizer lattices', 'pos': [5, 8]}, 't': {'name': 'N-best lists', 'pos': [2, 4]}, 'relation': 'usage'}
{'token': ['hypotheses', 'N-best', 'lists', 'tagged', 'part', 'speech', ',', '"', 'cleaned', '"', 'preprocessing', 'pipe', ',', 'parsed', 'part', 'speech', 'based', 'chunk', 'parser', ',', 'rescored', 'using', 'backpropagation', 'neural', 'net', 'trained', 'chunk', 'based', 'scores', '.'], 'h': {'name': 'chunk based scores', 'pos': [26, 29]}, 't': {'name': 'backpropagation neural net', 'pos': [22, 25]}, 'relation': 'usage'}
{'token': ['paper', ',', 'study', 'generate', 'features', 'various', 'data', 'representations', ',', 'surface', 'texts', 'parse', 'trees', ',', 'answer', 'extraction', '.'], 'h': {'name': 'features', 'pos': [4, 5]}, 't': {'name': 'data representations', 'pos': [6, 8]}, 'relation': 'part_whole'}
{'token': ['Besides', 'features', 'generated', 'surface', 'texts', ',', 'mainly', 'discuss', 'feature', 'generation', 'parse', 'trees', '.'], 'h': {'name': 'features', 'pos': [1, 2]}, 't': {'name': 'surface texts', 'pos': [3, 5]}, 'relation': 'part_whole'}
{'token': ['propose', 'compare', 'three', 'methods', ',', 'including', 'feature', 'vector', ',', 'string', 'kernel', 'tree', 'kernel', ',', 'represent', 'syntactic', 'features', 'Support', 'Vector', 'Machines', '.'], 'h': {'name': 'syntactic features', 'pos': [15, 17]}, 't': {'name': 'Support Vector Machines', 'pos': [17, 20]}, 'relation': 'usage'}
{'token': ['experiment', 'TREC', 'question', 'answering', 'task', 'shows', 'features', 'generated', 'structured', 'data', 'representations', 'significantly', 'improve', 'performance', 'based', 'features', 'generated', 'surface', 'texts', '.'], 'h': {'name': 'features', 'pos': [6, 7]}, 't': {'name': 'data representations', 'pos': [9, 11]}, 'relation': 'part_whole'}
{'token': ['experiment', 'TREC', 'question', 'answering', 'task', 'shows', 'features', 'generated', 'structured', 'data', 'representations', 'significantly', 'improve', 'performance', 'based', 'features', 'generated', 'surface', 'texts', '.'], 'h': {'name': 'features', 'pos': [15, 16]}, 't': {'name': 'surface texts', 'pos': [17, 19]}, 'relation': 'part_whole'}
{'token': ['paper', ',', 'explore', 'use', 'structured', 'content', 'semantic', 'constraints', 'enhancing', 'performance', 'traditional', 'term', '-', 'based', 'document', 'retrieval', 'special', 'domains', '.'], 'h': {'name': 'semantic constraints', 'pos': [6, 8]}, 't': {'name': 'term-based document retrieval', 'pos': [11, 16]}, 'relation': 'usage'}
{'token': ['First', ',', 'describe', 'method', 'automatic', 'extraction', 'semantic', 'content', 'form', 'attribute', '-', 'value', '(', 'AV', ')', 'pairs', 'natural', 'language', 'texts', 'based', 'domain', 'models', 'constructed', 'semi-structured', 'web', 'resource', '.'], 'h': {'name': 'attribute-value (AV) pairs', 'pos': [9, 16]}, 't': {'name': 'semantic content', 'pos': [6, 8]}, 'relation': 'model-feature'}
{'token': ['First', ',', 'describe', 'method', 'automatic', 'extraction', 'semantic', 'content', 'form', 'attribute', '-', 'value', '(', 'AV', ')', 'pairs', 'natural', 'language', 'texts', 'based', 'domain', 'models', 'constructed', 'semi-structured', 'web', 'resource', '.'], 'h': {'name': 'domain models', 'pos': [20, 22]}, 't': {'name': 'semi-structured web resource', 'pos': [23, 26]}, 'relation': 'part_whole'}
{'token': [',', 'explore', 'effect', 'combining', 'state', '-', '-', '-', 'art', 'term', '-', 'based', 'IR', 'system', 'simple', 'constraint', '-', 'based', 'search', 'system', 'uses', 'extracted', 'AV', 'pairs', '.'], 'h': {'name': 'AV pairs', 'pos': [22, 24]}, 't': {'name': 'constraint-based search system', 'pos': [15, 20]}, 'relation': 'usage'}
{'token': ['evaluation', 'results', 'shown', 'combination', 'produces', 'improvement', 'IR', 'performance', 'term', '-', 'based', 'IR', 'system', 'test', 'collection', '.'], 'h': {'name': 'IR performance', 'pos': [6, 8]}, 't': {'name': 'term-based IR system', 'pos': [8, 13]}, 'relation': 'compare'}
{'token': ['networks', 'induced', 'treebanks', ':', 'vertices', 'denote', 'word', 'forms', 'occur', 'nuclei', 'dependency', 'trees', '.'], 'h': {'name': 'networks', 'pos': [0, 1]}, 't': {'name': 'treebanks', 'pos': [2, 3]}, 'relation': 'part_whole'}
{'token': ['networks', 'induced', 'treebanks', ':', 'vertices', 'denote', 'word', 'forms', 'occur', 'nuclei', 'dependency', 'trees', '.'], 'h': {'name': 'vertices', 'pos': [4, 5]}, 't': {'name': 'word forms', 'pos': [6, 8]}, 'relation': 'model-feature'}
{'token': ['edges', 'connect', 'pairs', 'vertices', 'least', 'two', 'instance', 'nuclei', 'vertices', 'linked', 'dependency', 'structure', 'sentence', '.'], 'h': {'name': 'dependency structure', 'pos': [10, 12]}, 't': {'name': 'sentence', 'pos': [12, 13]}, 'relation': 'model-feature'}
{'token': ['examine', 'syntactic', 'dependency', 'networks', 'seven', 'languages', '.'], 'h': {'name': 'syntactic dependency networks', 'pos': [1, 4]}, 't': {'name': 'languages', 'pos': [5, 6]}, 'relation': 'model-feature'}
{'token': ['Secondly', ',', 'mean', 'clustering', 'vertices', 'decreases', 'degree', '-', 'finding', 'suggests', 'presence', 'hierarchical', 'network', 'organization', '.'], 'h': {'name': 'mean clustering', 'pos': [2, 4]}, 't': {'name': 'vertices', 'pos': [4, 5]}, 'relation': 'model-feature'}
{'token': ['Thirdly', ',', 'mean', 'degree', 'nearest', 'neighbors', 'vertex', 'x', 'tends', 'decrease', 'degree', 'x', 'grows', '-', 'finding', 'indicates', 'disassortative', 'mixing', 'sense', 'links', 'tend', 'connect', 'vertices', 'dissimilar', 'degrees', '.'], 'h': {'name': 'mean degree', 'pos': [2, 4]}, 't': {'name': 'nearest neighbors', 'pos': [4, 6]}, 'relation': 'model-feature'}
{'token': ['Dependency', '-', 'based', 'representations', 'natural', 'language', 'syntax', 'require', 'fine', 'balance', 'structural', 'flexibility', 'computational', 'complexity'], 'h': {'name': 'Dependency-based representations', 'pos': [0, 4]}, 't': {'name': 'natural language syntax', 'pos': [4, 7]}, 'relation': 'model-feature'}
{'token': ['constraints', 'formulated', 'fully', 'specified', 'structures', ',', 'makes', 'hard', 'integrate', 'models', 'structures', 'composed', 'lexical', 'information', '.'], 'h': {'name': 'lexical information', 'pos': [12, 14]}, 't': {'name': 'structures', 'pos': [10, 11]}, 'relation': 'usage'}
{'token': ['show', 'morphological', 'decomposition', 'Arabic', 'source', 'beneficial', ',', 'especially', 'smaller', '-', 'size', 'corpora', ',', 'investigate', 'different', 'recombination', 'techniques', '.'], 'h': {'name': 'morphological decomposition', 'pos': [1, 3]}, 't': {'name': 'Arabic', 'pos': [3, 4]}, 'relation': 'usage'}
{'token': ['also', 'report', 'use', 'Factored', 'Translation', 'Models', 'English', '-to', 'Arabic', 'translation', '.'], 'h': {'name': 'Factored Translation Models', 'pos': [3, 6]}, 't': {'name': 'English-to-Arabic translation', 'pos': [6, 10]}, 'relation': 'usage'}
{'token': ['first', 'algorithm', 'uses', 'machine', 'learning', 'methods', 'identify', 'semantic', 'dependencies', 'four', 'stages', ':', 'identification', 'labeling', 'predicates', ',', 'identification', 'labeling', 'arguments', '.'], 'h': {'name': 'labeling', 'pos': [13, 14]}, 't': {'name': 'predicates', 'pos': [14, 15]}, 'relation': 'usage'}
{'token': ['first', 'algorithm', 'uses', 'machine', 'learning', 'methods', 'identify', 'semantic', 'dependencies', 'four', 'stages', ':', 'identification', 'labeling', 'predicates', ',', 'identification', 'labeling', 'arguments', '.'], 'h': {'name': 'labeling', 'pos': [17, 18]}, 't': {'name': 'arguments', 'pos': [18, 19]}, 'relation': 'usage'}
{'token': ['hybrid', 'algorithm', 'combining', 'best', 'stages', 'two', 'algorithms', 'attains', '86.62', '%', 'labeled', 'syntactic', 'attachment', 'accuracy', ',', '73.24', '%', 'labeled', 'semantic', 'dependency', 'F1', '79.93', '%', 'labeled', 'macro', 'Fl', 'score', 'combined', 'WSJ', 'Brown', 'test', 'sets', '.'], 'h': {'name': 'hybrid algorithm', 'pos': [0, 2]}, 't': {'name': 'labeled syntactic attachment accuracy', 'pos': [10, 14]}, 'relation': 'result'}
{'token': ['paper', 'presents', 'experiments', 'modelling', 'substitutability', 'discourse', 'connectives', '.'], 'h': {'name': 'substitutability', 'pos': [4, 5]}, 't': {'name': 'discourse connectives', 'pos': [5, 7]}, 'relation': 'model-feature'}
{'token': ['new', 'Theory', 'Names', 'Descriptions', 'offers', 'uniform', 'treatment', 'many', 'types', 'non-singular', 'concepts', 'found', 'natural', 'language', 'discourse', 'presented', '.'], 'h': {'name': 'non-singular concepts', 'pos': [9, 11]}, 't': {'name': 'natural language discourse', 'pos': [12, 15]}, 'relation': 'part_whole'}
{'token': ['paper', 'proposes', 'novel', ',', 'corpus', '-', 'based', 'method', 'producing', 'mappings', 'lexical', 'resources', '.'], 'h': {'name': 'corpus-based method', 'pos': [4, 8]}, 't': {'name': 'mappings', 'pos': [9, 10]}, 'relation': 'usage'}
{'token': ['propose', 'novel', 'method', 'predict', 'inter-paragraph', 'discourse', 'structure', 'text', ',', 'i.e.'], 'h': {'name': 'inter-paragraph discourse structure', 'pos': [4, 7]}, 't': {'name': 'text', 'pos': [7, 8]}, 'relation': 'model-feature'}
{'token': ['method', 'combines', 'clustering', 'algorithm', 'model', 'segment', '"', 'relatedness', '"', 'acquired', 'machine', 'learning', 'step', '.'], 'h': {'name': 'model', 'pos': [4, 5]}, 't': {'name': 'segment "relatedness"', 'pos': [5, 9]}, 'relation': 'model-feature'}
{'token': ['improves', 'recent', 'analyses', 'computational', 'linguistics', 'literature', 'three', 'respects', ':', '(', ')', 'uses', 'tree', '-', 'logical', '-', 'form', 'rewriting', 'devices', 'building', 'meaning', 'representations', '(', 'ii', ')', 'results', 'fully', 'reversible', 'linguistic', 'description', ',', 'equally', 'suited', 'analysis', 'generation', '(', 'iii', ')', 'analysis', 'extends', 'types', 'elliptical', 'comparative', 'elsewhere', 'treated', '.'], 'h': {'name': 'tree- or logical-form rewriting devices', 'pos': [12, 19]}, 't': {'name': 'meaning representations', 'pos': [20, 22]}, 'relation': 'usage'}
{'token': ['contrast', 'earlier', 'dialectology', ',', 'seek', 'comprehensive', 'characterization', '(', 'potentially', 'gradual', ')', 'differences', 'dialects', ',', 'rather', 'geographic', 'delineation', '(', 'discrete', ')', 'features', 'individual', 'words', 'pronunciations', '.'], 'h': {'name': '(discrete) features', 'pos': [17, 21]}, 't': {'name': 'individual words', 'pos': [21, 23]}, 'relation': 'model-feature'}
{'token': ['measure', 'phonetic', '(', 'un', ')', 'relatedness', 'dialects', 'using', 'Levenshtein', 'distance', ',', 'classify', 'clustering', 'distances', 'also', 'analysis', 'multidimensional', 'scaling', '.'], 'h': {'name': 'Levenshtein distance', 'pos': [8, 10]}, 't': {'name': 'phonetic (un)relatedness', 'pos': [1, 6]}, 'relation': 'usage'}
{'token': ['Experimental', 'results', 'using', 'threaded', 'discussion', 'corpus', 'undergraduate', 'class', 'show', 'achieves', 'significant', 'performance', 'improvements', 'compared', 'baseline', 'system', '.'], 'h': {'name': 'performance improvements', 'pos': [11, 13]}, 't': {'name': 'baseline system', 'pos': [14, 16]}, 'relation': 'compare'}
{'token': ['method', 'anaphoral', 'resolution', 'zero', 'pronouns', 'Japanese', 'language', 'texts', 'using', 'verbal', 'semantic', 'attributes', 'suggested', '.'], 'h': {'name': 'anaphoral resolution', 'pos': [1, 3]}, 't': {'name': 'Japanese language texts', 'pos': [5, 8]}, 'relation': 'usage'}
{'token': ['method', 'focuses', 'attention', 'semantic', 'attributes', 'verbs', 'examines', 'context', 'relationship', 'semantic', 'attributes', 'verbs', 'governing', 'zero', 'pronouns', 'semantic', 'attributes', 'verbs', 'governing', 'referents', '.'], 'h': {'name': 'semantic attributes', 'pos': [3, 5]}, 't': {'name': 'verbs', 'pos': [5, 6]}, 'relation': 'model-feature'}
{'token': ['method', 'focuses', 'attention', 'semantic', 'attributes', 'verbs', 'examines', 'context', 'relationship', 'semantic', 'attributes', 'verbs', 'governing', 'zero', 'pronouns', 'semantic', 'attributes', 'verbs', 'governing', 'referents', '.'], 'h': {'name': 'semantic attributes', 'pos': [9, 11]}, 't': {'name': 'verbs', 'pos': [11, 12]}, 'relation': 'model-feature'}
{'token': ['method', 'focuses', 'attention', 'semantic', 'attributes', 'verbs', 'examines', 'context', 'relationship', 'semantic', 'attributes', 'verbs', 'governing', 'zero', 'pronouns', 'semantic', 'attributes', 'verbs', 'governing', 'referents', '.'], 'h': {'name': 'semantic attributes', 'pos': [15, 17]}, 't': {'name': 'verbs', 'pos': [17, 18]}, 'relation': 'model-feature'}
{'token': ['semantic', 'attributes', 'verbs', 'created', 'using', '2', 'different', 'viewpoints', ':', 'dynamic', 'characteristics', 'verbs', 'relationship', 'verbs', 'cases', '.'], 'h': {'name': 'semantic attributes', 'pos': [0, 2]}, 't': {'name': 'verbs', 'pos': [2, 3]}, 'relation': 'model-feature'}
{'token': ['semantic', 'attributes', 'verbs', 'created', 'using', '2', 'different', 'viewpoints', ':', 'dynamic', 'characteristics', 'verbs', 'relationship', 'verbs', 'cases', '.'], 'h': {'name': 'dynamic characteristics', 'pos': [9, 11]}, 't': {'name': 'verbs', 'pos': [11, 12]}, 'relation': 'model-feature'}
{'token': ['using', 'method', ',', 'shown', ',', 'case', 'translating', 'newspaper', 'articles', ',', 'major', 'portion', '(', '93', '%', ')', 'anaphoral', 'resolution', 'zero', 'pronouns', 'necessary', 'machine', 'translation', 'achieved', 'using', 'linguistic', 'knowledge', '.', 'Factors', 'given', 'special', 'attention', 'incorporating', 'method', 'machine', 'translation', 'system', 'examined', ',', 'together', 'suggested', 'conditions', 'detection', 'zero', 'pronouns', 'methods', 'conversion', '.'], 'h': {'name': 'linguistic knowledge', 'pos': [25, 27]}, 't': {'name': 'anaphoral resolution', 'pos': [16, 18]}, 'relation': 'usage'}
{'token': ['Implementation', 'proposed', 'method', 'due', 'consideration', 'points', 'leads', 'viable', 'method', 'anaphoral', 'resolution', 'zero', 'pronouns', 'practical', 'machine', 'translation', 'system', '.'], 'h': {'name': 'anaphoral resolution', 'pos': [9, 11]}, 't': {'name': 'machine translation system', 'pos': [14, 17]}, 'relation': 'usage'}
{'token': ['primary', 'objective', 'project', 'develop', 'robust', ',', 'high', '-', 'performance', 'parser', 'English', 'automatically', 'extracting', 'grammar', 'annotated', 'corpus', 'bracketed', 'sentences', ',', 'called', 'Treebank', '.'], 'h': {'name': 'high-performance parser', 'pos': [6, 10]}, 't': {'name': 'English', 'pos': [10, 11]}, 'relation': 'usage'}
{'token': ['primary', 'objective', 'project', 'develop', 'robust', ',', 'high', '-', 'performance', 'parser', 'English', 'automatically', 'extracting', 'grammar', 'annotated', 'corpus', 'bracketed', 'sentences', ',', 'called', 'Treebank', '.'], 'h': {'name': 'grammar', 'pos': [13, 14]}, 't': {'name': 'annotated corpus', 'pos': [14, 16]}, 'relation': 'part_whole'}
{'token': ['test', 'collection', 'consists', '1', 'million', 'documents', 'diverse', 'full', '-', 'text', 'sources', ',', '250', 'topics', ',', 'set', 'relevant', 'documents', '"', 'right', 'answers', '"', 'topics', '.'], 'h': {'name': 'documents', 'pos': [5, 6]}, 't': {'name': 'test collection', 'pos': [0, 2]}, 'relation': 'part_whole'}
{'token': ['results', 'TREC', '-2', 'showed', 'significant', 'improvements', 'TREC', '-', '1', 'results', ',', 'viewed', 'appropriate', 'baseline', 'representing', 'state', '-', '-', '-', 'art', 'retrieval', 'techniques', 'scaled', 'handling', '2', 'gigabyte', 'collection', '.'], 'h': {'name': 'TREC-2', 'pos': [1, 3]}, 't': {'name': 'TREC-1 results', 'pos': [6, 10]}, 'relation': 'compare'}
{'token': ['paper', 'outline', 'lexical', 'organization', 'Turkish', 'makes', 'use', 'lexical', 'rules', 'inflections', ',', 'derivations', ',', 'lexical', 'category', 'changes', 'control', 'proliferation', 'lexical', 'entries', '.'], 'h': {'name': 'lexical rules', 'pos': [7, 9]}, 't': {'name': 'inflections', 'pos': [9, 10]}, 'relation': 'usage'}
{'token': ['lexical', 'inheritance', 'hierarchy', 'facilitates', 'enforcement', 'type', 'constraints', '.'], 'h': {'name': 'lexical inheritance hierarchy', 'pos': [0, 3]}, 't': {'name': 'type constraints', 'pos': [5, 7]}, 'relation': 'usage'}
{'token': ['Semantic', 'compositions', 'inflections', 'derivations', 'constrained', 'properties', 'terms', 'predicates', '.', 'design', 'tested', 'part', 'HPSG', 'grammar', 'Turkish', '.'], 'h': {'name': 'Semantic compositions ', 'pos': [0, 2]}, 't': {'name': 'inflections', 'pos': [2, 3]}, 'relation': 'model-feature'}
{'token': ['bigram', 'language', 'models', 'popular', ',', 'much', 'language', 'processing', 'applications', ',', 'Indo', '-', 'European', 'Asian', 'languages', '.'], 'h': {'name': 'bigram language models', 'pos': [0, 3]}, 't': {'name': 'language processing applications', 'pos': [6, 9]}, 'relation': 'usage'}
{'token': ['However', ',', 'language', 'model', 'Chinese', 'applied', 'novel', 'domain', ',', 'accuracy', 'reduced', 'significantly', ',', '96', '%', '78', '%', 'evaluation', '.'], 'h': {'name': 'language model', 'pos': [2, 4]}, 't': {'name': 'domain', 'pos': [7, 8]}, 'relation': 'usage'}
{'token': ['evaluation', ',', 'Bayesian', 'classifiers', 'produce', 'best', 'recall', 'performance', '80', '%', 'precision', 'low', '(', '60', '%', ')', '.'], 'h': {'name': 'Bayesian classifiers', 'pos': [2, 4]}, 't': {'name': 'recall performance', 'pos': [6, 8]}, 'relation': 'result'}
{'token': ['Neural', 'network', 'produced', 'good', 'recall', '(', '75', '%', ')', 'precision', '(', '80', '%', ')', 'Bayesian', 'Neural', 'network', 'low', 'skip', 'ratio', '(', '65', '%', ')', '.'], 'h': {'name': 'Neural network', 'pos': [0, 2]}, 't': {'name': 'recall', 'pos': [4, 5]}, 'relation': 'result'}
{'token': ['decision', 'tree', 'classifier', 'produced', 'best', 'precision', '(', '81', '%', ')', 'skip', 'ratio', '(', '76', '%', ')', 'recall', 'lowest', '(', '73', '%', ')', '.'], 'h': {'name': 'decision tree classifier', 'pos': [0, 3]}, 't': {'name': 'precision', 'pos': [5, 6]}, 'relation': 'result'}
{'token': ['Tokenization', 'process', 'mapping', 'sentences', 'character', 'strings', 'strings', 'words', '.'], 'h': {'name': 'mapping sentences', 'pos': [2, 4]}, 't': {'name': 'character strings', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['paper', 'reports', 'empirical', 'evaluation', 'comparison', 'several', 'popular', 'goodness', 'measures', 'unsupervised', 'segmentation', 'Chinese', 'texts', 'using', 'Bakeoff', '-', '3', 'data', 'sets', 'unified', 'framework', '.'], 'h': {'name': 'goodness measures', 'pos': [7, 9]}, 't': {'name': 'unsupervised segmentation', 'pos': [9, 11]}, 'relation': 'usage'}
{'token': ['Assuming', 'prior', 'knowledge', 'Chinese', ',', 'framework', 'relies', 'goodness', 'measure', 'identify', 'word', 'candidates', 'unlabeled', 'texts', 'applies', 'generalized', 'decoding', 'algorithm', 'find', 'optimal', 'segmentation', 'sentence', 'candidates', 'greatest', 'sum', 'goodness', 'scores', '.'], 'h': {'name': 'word candidates', 'pos': [10, 12]}, 't': {'name': 'unlabeled texts', 'pos': [12, 14]}, 'relation': 'part_whole'}
{'token': ['Assuming', 'prior', 'knowledge', 'Chinese', ',', 'framework', 'relies', 'goodness', 'measure', 'identify', 'word', 'candidates', 'unlabeled', 'texts', 'applies', 'generalized', 'decoding', 'algorithm', 'find', 'optimal', 'segmentation', 'sentence', 'candidates', 'greatest', 'sum', 'goodness', 'scores', '.'], 'h': {'name': 'decoding algorithm', 'pos': [16, 18]}, 't': {'name': 'segmentation', 'pos': [20, 21]}, 'relation': 'usage'}
{'token': ['Assuming', 'prior', 'knowledge', 'Chinese', ',', 'framework', 'relies', 'goodness', 'measure', 'identify', 'word', 'candidates', 'unlabeled', 'texts', 'applies', 'generalized', 'decoding', 'algorithm', 'find', 'optimal', 'segmentation', 'sentence', 'candidates', 'greatest', 'sum', 'goodness', 'scores', '.'], 'h': {'name': 'goodness scores', 'pos': [25, 27]}, 't': {'name': 'candidates', 'pos': [22, 23]}, 'relation': 'model-feature'}
{'token': ['Building', 'state', '-', '-', '-', 'art', 'set', 'features', ',', 'binary', 'classifier', 'label', 'trained', 'using', 'Ada', 'Boost', 'fixed', 'depth', 'decision', 'trees', '.'], 'h': {'name': 'decision trees', 'pos': [18, 20]}, 't': {'name': 'AdaBoost', 'pos': [14, 16]}, 'relation': 'usage'}
{'token': ['paper', 'propose', 'two', 'metrics', 'used', 'various', 'fields', 'computational', 'linguistics', 'area', '.'], 'h': {'name': 'metrics', 'pos': [3, 4]}, 't': {'name': 'computational linguistics', 'pos': [7, 9]}, 'relation': 'usage'}
{'token': ['Finally', ',', 'short', 'application', 'presented', ':', 'investigate', 'similarity', 'Romance', 'languages', 'computing', 'scaled', 'total', 'rank', 'distance', 'digram', 'rankings', 'language', '.'], 'h': {'name': 'scaled total rank distance', 'pos': [11, 15]}, 't': {'name': 'similarity', 'pos': [7, 8]}, 'relation': 'usage'}
{'token': ['First', ',', 'formalize', 'task', 'identifying', 'Japanese', 'compound', 'functional', 'expressions', 'text', 'machine', 'learning', 'based', 'chunking', 'problem', '.'], 'h': {'name': 'Japanese compound functional expressions', 'pos': [5, 9]}, 't': {'name': 'text', 'pos': [9, 10]}, 'relation': 'part_whole'}
{'token': ['Next', ',', 'results', 'identifying', 'compound', 'functional', 'expressions', ',', 'apply', 'method', 'dependency', 'analysis', 'based', 'cascaded', 'chunking', 'model', '.'], 'h': {'name': 'cascaded chunking model', 'pos': [13, 16]}, 't': {'name': 'dependency analysis', 'pos': [10, 12]}, 'relation': 'usage'}
{'token': ['introduce', 'relation', 'extraction', 'method', 'identify', 'sentences', 'biomedical', 'text', 'indicate', 'interaction', 'among', 'protein', 'names', 'mentioned', '.'], 'h': {'name': 'relation extraction method', 'pos': [1, 4]}, 't': {'name': 'biomedical text', 'pos': [6, 8]}, 'relation': 'usage'}
{'token': ['approach', 'based', 'analysis', 'paths', 'two', 'protein', 'names', 'dependency', 'parse', 'trees', 'sentences', '.'], 'h': {'name': 'dependency parse trees', 'pos': [7, 10]}, 't': {'name': 'sentences', 'pos': [10, 11]}, 'relation': 'model-feature'}
{'token': ['Given', 'two', 'dependency', 'trees', ',', 'define', 'two', 'separate', 'similarity', 'functions', '(', 'kernels', ')', 'based', 'cosine', 'similarity', 'edit', 'distance', 'among', 'paths', 'protein', 'names', '.'], 'h': {'name': 'cosine similarity', 'pos': [14, 16]}, 't': {'name': 'similarity functions (kernels)', 'pos': [8, 13]}, 'relation': 'usage'}
{'token': ['Semi-supervised', 'algorithms', 'perform', 'better', 'supervised', 'version', 'wide', 'margin', 'especially', 'amount', 'labeled', 'data', 'limited', '.'], 'h': {'name': 'Semi-supervised algorithms', 'pos': [0, 2]}, 't': {'name': 'labeled data', 'pos': [10, 12]}, 'relation': 'usage'}
{'token': ['Language', 'model', '(', 'LM', ')', 'adaptation', 'important', 'speech', 'language', 'processing'], 'h': {'name': 'Language model (LM) adaptation', 'pos': [0, 6]}, 't': {'name': 'speech and language processing', 'pos': [7, 10]}, 'relation': 'usage'}
{'token': ['addition', ',', 'new', 'dynamically', 'adapted', 'weighting', 'scheme', 'topic', 'mixture', 'models', 'proposed', 'based', 'LDA', 'topic', 'analysis', '.'], 'h': {'name': 'LDA topic analysis', 'pos': [12, 15]}, 't': {'name': 'weighting scheme', 'pos': [5, 7]}, 'relation': 'usage'}
{'token': ['experimental', 'results', 'show', 'NE', '-', 'driven', 'LM', 'adaptation', 'framework', 'outperforms', 'baseline', 'generic', 'LM', '.'], 'h': {'name': 'NE-driven LM adaptation', 'pos': [3, 8]}, 't': {'name': 'LM', 'pos': [12, 13]}, 'relation': 'compare'}
{'token': ['state', '-', '-', '-', 'art', 'system', 'combination', 'method', 'machine', 'translation', '(', 'MT', ')', 'word', '-', 'based', 'combination', 'using', 'confusion', 'networks', '.'], 'h': {'name': 'combination method', 'pos': [6, 8]}, 't': {'name': 'machine translation (MT)', 'pos': [8, 13]}, 'relation': 'usage'}
{'token': ['state', '-', '-', '-', 'art', 'system', 'combination', 'method', 'machine', 'translation', '(', 'MT', ')', 'word', '-', 'based', 'combination', 'using', 'confusion', 'networks', '.'], 'h': {'name': 'confusion networks', 'pos': [18, 20]}, 't': {'name': 'word-based combination', 'pos': [13, 17]}, 'relation': 'usage'}
{'token': ['paper', ',', 'present', 'new', 'methods', 'improve', 'alignment', 'hypotheses', 'using', 'word', 'synonyms', 'two', '-', 'pass', 'alignment', 'strategy', '.'], 'h': {'name': 'word synonyms', 'pos': [9, 11]}, 't': {'name': 'alignment', 'pos': [6, 7]}, 'relation': 'usage'}
{'token': ['present', 'novel', 'method', 'creating', 'A*', 'estimates', 'structured', 'search', 'problems', '.'], 'h': {'name': 'A* estimates', 'pos': [4, 6]}, 't': {'name': 'structured search problems', 'pos': [6, 9]}, 'relation': 'usage'}
{'token': ['DPA', 'algorithm', 'works', 'assumption', 'Direct', 'Correspondence', 'simply', 'means'], 'h': {'name': 'assumption of Direct Correspondence', 'pos': [3, 6]}, 't': {'name': 'DPA algorithm', 'pos': [0, 2]}, 'relation': 'usage'}
{'token': ['leads', 'wrong', 'parsed', 'structure', 'target', 'language', 'sentence', '.'], 'h': {'name': 'parsed structure ', 'pos': [2, 4]}, 't': {'name': 'target language sentence', 'pos': [4, 7]}, 'relation': 'model-feature'}
{'token': ['parser', 'algorithm', 'assigns', 'structural', 'description', 'string', 'according', 'grammar', '.'], 'h': {'name': 'structural description', 'pos': [3, 5]}, 't': {'name': 'string', 'pos': [5, 6]}, 'relation': 'model-feature'}
{'token': ['Common', 'parsers', 'employ', 'phrase', 'structure', 'descriptions', ',', 'rule', '-', 'based', 'grammars', ',', 'derivation', 'transition', 'oriented', 'recognition', '.'], 'h': {'name': 'phrase structure descriptions', 'pos': [3, 6]}, 't': {'name': 'parsers', 'pos': [1, 2]}, 'relation': 'usage'}
{'token': ['syntactical', 'relationships', 'stated', 'part', 'lexical', 'descriptions', 'elements', 'language', '.'], 'h': {'name': 'syntactical relationships', 'pos': [0, 2]}, 't': {'name': 'lexical descriptions', 'pos': [4, 6]}, 'relation': 'part_whole'}
{'token': ['going', 'describe', 'design', 'implementation', 'communication', 'system', 'large', 'AI', 'projects', ',', 'capable', 'supporting', 'various', 'software', 'components', 'heterogeneous', 'hardware', 'programming', '-', 'language', 'environment', '.'], 'h': {'name': 'communication system', 'pos': [4, 6]}, 't': {'name': 'AI', 'pos': [7, 8]}, 'relation': 'usage'}
{'token': ['present', 'preliminary', 'results', 'Czech', '-', 'English', 'translation', 'system', 'based', 'dependency', 'trees', '.'], 'h': {'name': 'dependency trees', 'pos': [9, 11]}, 't': {'name': 'Czech-English translation system', 'pos': [3, 8]}, 'relation': 'usage'}
{'token': ['fully', 'automated', 'process', 'includes', ':', 'morphological', 'tagging', ',', 'analytical', 'tectogrammatical', 'parsing', 'Czech', ',', 'tectogrammatical', 'transfer', 'based', 'lexical', 'substitution', 'using', 'word', '-', '-', 'word', 'translation', 'dictionaries', 'enhanced', 'information', 'English', '-', 'Czech', 'parallel', 'corpus', 'WSJ', ',', 'simple', 'rule', '-', 'based', 'system', 'generation', 'English', 'tectogrammatical', 'representation', '.'], 'h': {'name': 'word-to-word translation dictionaries', 'pos': [19, 25]}, 't': {'name': 'lexical substitution', 'pos': [16, 18]}, 'relation': 'usage'}
{'token': ['fully', 'automated', 'process', 'includes', ':', 'morphological', 'tagging', ',', 'analytical', 'tectogrammatical', 'parsing', 'Czech', ',', 'tectogrammatical', 'transfer', 'based', 'lexical', 'substitution', 'using', 'word', '-', '-', 'word', 'translation', 'dictionaries', 'enhanced', 'information', 'English', '-', 'Czech', 'parallel', 'corpus', 'WSJ', ',', 'simple', 'rule', '-', 'based', 'system', 'generation', 'English', 'tectogrammatical', 'representation', '.'], 'h': {'name': 'rule-based system', 'pos': [35, 39]}, 't': {'name': 'generation', 'pos': [39, 40]}, 'relation': 'usage'}
{'token': ['ADOMIT', 'algorithm', 'Automatic', 'Detection', 'OMIssions', 'Translations', '.'], 'h': {'name': 'Automatic Detection', 'pos': [2, 4]}, 't': {'name': 'Translations', 'pos': [5, 6]}, 'relation': 'usage'}
{'token': ['algorithm', 'relies', 'solely', 'geometric', 'analysis', 'bitext', 'maps', 'uses', 'linguistic', 'information', '.'], 'h': {'name': 'geometric analysis', 'pos': [3, 5]}, 't': {'name': 'bitext maps', 'pos': [5, 7]}, 'relation': 'topic'}
{'token': ['end', ',', 'aim', 'locate', 'eventualities', 'text', 'time', 'axis', '/', 'map', 'ensure', 'optimal', 'base', 'automatic', 'temporal', 'geospatial', 'reasoning', '.'], 'h': {'name': 'optimal base', 'pos': [11, 13]}, 't': {'name': 'automatic temporal and geospatial reasoning', 'pos': [13, 17]}, 'relation': 'part_whole'}
{'token': ['world', 'knowledge', 'MiniSTEx', 'uses', 'contained', 'interconnected', 'tables', 'database', '.'], 'h': {'name': 'interconnected tables', 'pos': [5, 7]}, 't': {'name': 'database', 'pos': [7, 8]}, 'relation': 'part_whole'}
{'token': ['propose', 'semantic', 'construction', 'method', 'Feature', '-', 'Based', 'Tree', 'Adjoining', 'Grammar', 'based', 'derived', 'tree', ',', 'compare', 'related', 'proposals', 'briefly', 'discuss', 'implementation', 'possibilities', '.'], 'h': {'name': 'derived tree', 'pos': [11, 13]}, 't': {'name': 'semantic construction method', 'pos': [1, 4]}, 'relation': 'usage'}
{'token': ['Traditional', 'approaches', 'problem', 'extracting', 'data', 'texts', 'emphasized', 'handcrafted', 'linguistic', 'knowledge'], 'h': {'name': 'data', 'pos': [4, 5]}, 't': {'name': 'texts', 'pos': [5, 6]}, 'relation': 'part_whole'}
{'token': ['previously', 'performed', 'experiments', 'components', 'system', 'texts', 'Wall', 'Street', 'Journal', ',', 'however', ',', 'MUC', '-', '3', 'task', 'first', 'end', '-', '-', 'end', 'application', 'plum', '.'], 'h': {'name': 'texts', 'pos': [5, 6]}, 't': {'name': 'Wall Street Journal', 'pos': [6, 9]}, 'relation': 'part_whole'}
{'token': ['central', 'assumption', 'approach', 'processing', 'unrestricted', 'text', 'data', 'extraction', ',', 'non-trivial', 'amount', 'text', 'understood', '.'], 'h': {'name': 'data extraction', 'pos': [6, 8]}, 't': {'name': 'unrestricted text', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['present', 'novel', 'sentence', 'reduction', 'system', 'automatically', 'removing', 'extraneous', 'phrases', 'sentences', 'extracted', 'document', 'summarization', 'purpose', '.'], 'h': {'name': 'sentences', 'pos': [9, 10]}, 't': {'name': 'document', 'pos': [11, 12]}, 'relation': 'part_whole'}
{'token': ['system', 'uses', 'multiple', 'sources', 'knowledge', 'decide', 'phrases', 'extracted', 'sentence', 'removed', ',', 'including', 'syntactic', 'knowledge', ',', 'context', 'information', ',', 'statistics', 'computed', 'corpus', 'consists', 'examples', 'written', 'human', 'professionals', '.'], 'h': {'name': 'statistics', 'pos': [18, 19]}, 't': {'name': 'corpus', 'pos': [20, 21]}, 'relation': 'part_whole'}
{'token': ['Reduction', 'significantly', 'improve', 'conciseness', 'automatic', 'summaries', '.'], 'h': {'name': 'conciseness', 'pos': [3, 4]}, 't': {'name': 'automatic summaries', 'pos': [4, 6]}, 'relation': 'model-feature'}
{'token': ['method', 'automatically', 'trainable', ',', 'acquiring', 'information', 'positive', 'negative', 'examples', '.'], 'h': {'name': 'information', 'pos': [5, 6]}, 't': {'name': 'positive and negative examples', 'pos': [6, 9]}, 'relation': 'part_whole'}
{'token': ['paper', 'introduces', 'algorithm', 'automatically', 'acquiring', 'conceptual', 'structure', 'word', 'corpus', '.'], 'h': {'name': 'conceptual structure', 'pos': [5, 7]}, 't': {'name': 'word', 'pos': [7, 8]}, 'relation': 'model-feature'}
{'token': ['lexical', 'concept', 'obtained', 'Collocation', 'Map', 'best', 'reflects', 'subdomain', 'language', 'usage', '.'], 'h': {'name': 'lexical concept', 'pos': [0, 2]}, 't': {'name': 'Collocation Map', 'pos': [3, 5]}, 'relation': 'part_whole'}
{'token': ['potential', 'application', 'conditional', 'probabilities', 'Collocation', 'Map', 'provides', 'may', 'extend', 'cover', 'diverse', 'areas', 'language', 'processing', 'sense', 'disambiguation', ',', 'thesaurus', 'construction', ',', 'automatic', 'indexing', ',', 'document', 'classification', '.'], 'h': {'name': 'conditional probabilities', 'pos': [2, 4]}, 't': {'name': 'language processing', 'pos': [12, 14]}, 'relation': 'usage'}
{'token': ['discuss', '"', 'strapping', '"', 'methods', 'general', ',', 'exhibit', 'particular', 'method', 'strapping', 'word', '-', 'sense', 'classifiers', 'ambiguous', 'words', '.'], 'h': {'name': '"strapping" methods', 'pos': [1, 5]}, 't': {'name': 'word-sense classifiers', 'pos': [11, 15]}, 'relation': 'usage'}
{'token': ['experiments', 'Canadian', 'Hansards', 'show', 'unsupervised', 'technique', 'significantly', 'effective', 'picking', 'seeds', 'hand', '(', 'Yarowsky', ',', '1995', ')', ',', 'turn', 'known', 'rival', 'supervised', 'methods', '.', '"'], 'h': {'name': 'unsupervised technique', 'pos': [4, 6]}, 't': {'name': 'supervised methods', 'pos': [20, 22]}, 'relation': 'compare'}
{'token': ['word', 'association', 'information', 'added', 'system', 'time', 'automatic', 'creation', 'translation', 'pattern', 'database', ',', 'thereby', 'making', 'database', 'domain', 'specific', '.'], 'h': {'name': 'word association information', 'pos': [0, 3]}, 't': {'name': 'system', 'pos': [4, 5]}, 'relation': 'usage'}
{'token': ['technique', 'significantly', 'improves', 'overall', 'quality', 'translation', ',', 'measured', 'independent', 'blind', 'evaluation', '.'], 'h': {'name': 'technique', 'pos': [0, 1]}, 't': {'name': 'translation', 'pos': [5, 6]}, 'relation': 'result'}
{'token': ['describe', 'experiments', 'UC', 'Berkeley', 'team', 'improving', 'English', '-', 'Spanish', 'machine', 'translation', 'news', 'text', ',', 'part', "WMT'08", 'Shared', 'Translation', 'Task', '.'], 'h': {'name': 'English-Spanish machine translation', 'pos': [6, 11]}, 't': {'name': 'news text', 'pos': [11, 13]}, 'relation': 'usage'}
{'token': ['add', 'third', 'phrase', 'translation', 'model', 'trained', 'version', 'news', 'bi-text', 'augmented', 'monolingual', 'sentence', '-', 'level', 'syntactic', 'paraphrases', 'source', '-', 'language', 'side', ',', 'combine', 'models', 'log', '-', 'linear', 'model', 'using', 'minimum', 'error', 'rate', 'training', '.'], 'h': {'name': 'monolingual sentence-level syntactic paraphrases', 'pos': [10, 16]}, 't': {'name': 'news bi-text', 'pos': [7, 9]}, 'relation': 'part_whole'}
{'token': ['Several', 'recently', 'reported', 'techniques', 'automatic', 'acquisition', 'Information', 'Extraction', '(', 'IE', ')', 'systems', 'used', 'dependency', 'trees', 'basis', 'extraction', 'pattern', 'representation', '.'], 'h': {'name': 'dependency trees', 'pos': [13, 15]}, 't': {'name': 'Information Extraction (IE) systems', 'pos': [6, 12]}, 'relation': 'usage'}
{'token': ['appropriate', 'model', 'expressive', 'enough', 'represent', 'information', 'extracted', 'text', 'without', 'overly', 'complicated', '.'], 'h': {'name': 'information', 'pos': [5, 6]}, 't': {'name': 'text', 'pos': [7, 8]}, 'relation': 'part_whole'}
{'token': ['number', 'control', 'actions', 'needed', 'switch', 'languages', 'decreased', '93', '%', 'using', 'Type', 'rather', 'conventional', 'method', '.'], 'h': {'name': 'TypeAny', 'pos': [10, 11]}, 't': {'name': 'conventional method', 'pos': [12, 14]}, 'relation': 'compare'}
{'token': ['builds', 'earlier', 'system', 'based', 'relatively', 'deep', 'linguistic', 'analysis', ',', 'complement', 'shallow', 'component', 'based', 'word', 'overlap', '.'], 'h': {'name': 'word overlap', 'pos': [13, 15]}, 't': {'name': 'shallow component', 'pos': [10, 12]}, 'relation': 'usage'}
{'token': ['However', ',', 'earlier', 'observations', 'combination', 'features', 'improves', 'overall', 'accuracy', 'could', 'replicated', 'partly', '.'], 'h': {'name': 'features', 'pos': [5, 6]}, 't': {'name': 'overall accuracy', 'pos': [7, 9]}, 'relation': 'result'}
{'token': ['paper', ',', 'address', 'problem', 'extracting', 'data', 'records', 'attributes', 'unstructured', 'biomedical', 'full', 'text', '.'], 'h': {'name': 'data records', 'pos': [5, 7]}, 't': {'name': 'unstructured biomedical full text', 'pos': [8, 12]}, 'relation': 'part_whole'}
{'token': ['evaluate', 'approach', 'perspective', 'Information', 'Extraction', 'achieve', 'significant', 'improvements', 'system', 'performance', 'compared', 'baseline', 'systems', '.'], 'h': {'name': 'system performance', 'pos': [8, 10]}, 't': {'name': 'baseline systems', 'pos': [11, 13]}, 'relation': 'compare'}
{'token': ['paper', ',', 'describe', 'system', 'multilingual', 'characteristics', 'Wikipedia', 'utilized', 'annotate', 'large', 'corpus', 'text', 'Named', 'Entity', 'Recognition', '(', 'NER', ')', 'tags', 'requiring', 'minimal', 'human', 'intervention', 'linguistic', 'expertise', '.'], 'h': {'name': 'multilingual characteristics', 'pos': [4, 6]}, 't': {'name': 'Wikipedia', 'pos': [6, 7]}, 'relation': 'model-feature'}
{'token': ['paper', ',', 'describe', 'system', 'multilingual', 'characteristics', 'Wikipedia', 'utilized', 'annotate', 'large', 'corpus', 'text', 'Named', 'Entity', 'Recognition', '(', 'NER', ')', 'tags', 'requiring', 'minimal', 'human', 'intervention', 'linguistic', 'expertise', '.'], 'h': {'name': 'text', 'pos': [11, 12]}, 't': {'name': 'large corpus', 'pos': [9, 11]}, 'relation': 'part_whole'}
{'token': ['describe', 'methods', 'English', 'language', 'data', 'used', 'bootstrap', 'NER', 'process', 'languages', '.'], 'h': {'name': 'English language data', 'pos': [2, 5]}, 't': {'name': 'NER process', 'pos': [7, 9]}, 'relation': 'usage'}
{'token': ['Central', 'approach', 'entity', '-', 'grid', 'representation', 'discourse', ',', 'captures', 'patterns', 'entity', 'distribution', 'text', '.'], 'h': {'name': 'entity-grid representation', 'pos': [2, 6]}, 't': {'name': 'discourse', 'pos': [6, 7]}, 'relation': 'model-feature'}
{'token': ['algorithm', 'introduced', 'article', 'automatically', 'abstracts', 'text', 'set', 'entity', 'transition', 'sequences', 'records', 'distributional', ',', 'syntactic', ',', 'referential', 'information', 'discourse', 'entities', '.'], 'h': {'name': 'entity transition sequences', 'pos': [7, 10]}, 't': {'name': 'text', 'pos': [5, 6]}, 'relation': 'model-feature'}
{'token': ['paper', 'describes', 'discriminative', 'language', 'modeling', 'large', 'vocabulary', 'speech', 'recognition', 'task', '.'], 'h': {'name': 'discriminative language modeling', 'pos': [2, 5]}, 't': {'name': 'vocabulary speech recognition task', 'pos': [6, 10]}, 'relation': 'usage'}
{'token': ['contrast', 'two', 'parameter', 'estimation', 'methods', ':', 'perceptron', 'algorithm', ',', 'method', 'based', 'conditional', 'random', 'fields', '(', 'CRFs', ')', '.'], 'h': {'name': 'perceptron algorithm', 'pos': [6, 8]}, 't': {'name': 'conditional random fields (CRFs)', 'pos': [11, 17]}, 'relation': 'compare'}
{'token': ['perceptron', 'algorithm', 'benefit', 'automatically', 'selecting', 'relatively', 'small', 'feature', 'set', 'couple', 'passes', 'training', 'data', '.'], 'h': {'name': 'feature set', 'pos': [7, 9]}, 't': {'name': 'training data', 'pos': [11, 13]}, 'relation': 'part_whole'}
{'token': ['However', ',', 'using', 'feature', 'set', 'output', 'perceptron', 'algorithm', '(', 'initialized', 'weights', ')', ',', 'CRF', 'training', 'provides', 'additional', '0.5', '%', 'reduction', 'word', 'error', 'rate', ',', 'total', '1.8', '%', 'absolute', 'reduction', 'baseline', '39.2', '%.'], 'h': {'name': 'CRF training', 'pos': [13, 15]}, 't': {'name': 'word error rate', 'pos': [20, 23]}, 'relation': 'result'}
{'token': ['briefly', 'describe', 'design', 'implementation', 'status', 'system', ',', 'focus', 'system', 'used', 'elicit', 'useful', 'data', 'supporting', 'hypotheses', 'multimodal', 'interaction', 'domain', 'meeting', 'retrieval', 'developing', 'NLP', 'modules', 'specific', 'domain', '.'], 'h': {'name': 'system', 'pos': [8, 9]}, 't': {'name': 'useful data', 'pos': [11, 13]}, 'relation': 'usage'}
{'token': ['show', 'possibility', 'label', 'distinctions', 'names', 'major', 'advantages', 'use', 'feature', 'logic', 'computational', 'linguistics', 'implementation', '.'], 'h': {'name': 'feature logic', 'pos': [8, 10]}, 't': {'name': 'computational linguistics', 'pos': [10, 12]}, 'relation': 'usage'}
{'token': ['give', 'open', 'world', 'semantics', 'feature', 'terms', ',', 'denotation', 'term', 'determined', 'dependence', 'disjunctive', 'context', ',', 'i.e.'], 'h': {'name': 'denotation', 'pos': [7, 8]}, 't': {'name': 'term', 'pos': [8, 9]}, 'relation': 'model-feature'}
{'token': ['Acquiring', 'source', 'language', 'documents', 'testing', ',', 'creating', 'training', 'datasets', 'customized', 'MT', 'lexicons', ',', 'building', 'parallel', 'corpora', 'MT', 'evaluation', 'require', 'translators', 'non-', 'native', 'speaking', 'analysts', 'to', 'large', 'document', 'collections', '.'], 'h': {'name': 'source language documents', 'pos': [1, 4]}, 't': {'name': 'training datasets', 'pos': [7, 9]}, 'relation': 'usage'}
{'token': ['particular', ',', 'discuss', 'development', 'use', 'MTriage', ',', 'application', 'environment', 'enables', 'translator', 'markup', 'documents', 'metadata', 'MT', 'parameterization', 'routing', '.'], 'h': {'name': 'metadata', 'pos': [13, 14]}, 't': {'name': 'documents', 'pos': [12, 13]}, 'relation': 'model-feature'}
{'token': ['use', 'MTriage', 'web-enabled', 'front', 'end', 'multiple', 'MT', 'engines', 'leveraged', 'capabilities', 'human', 'translators', 'creating', 'lexicons', 'NFW', '(', '-', 'Word', ')', 'lists', ',', 'writing', 'reference', 'translations', ',', 'and', 'parallel', 'corpora', 'for', 'development', 'and', '.'], 'h': {'name': 'lexicons', 'pos': [13, 14]}, 't': {'name': 'NFW (Not-Found-Word) lists', 'pos': [14, 20]}, 'relation': 'part_whole'}
{'token': ['use', 'MTriage', 'web-enabled', 'front', 'end', 'multiple', 'MT', 'engines', 'leveraged', 'capabilities', 'human', 'translators', 'creating', 'lexicons', 'NFW', '(', '-', 'Word', ')', 'lists', ',', 'writing', 'reference', 'translations', ',', 'and', 'parallel', 'corpora', 'for', 'MT', 'development', 'and', '.'], 'h': {'name': 'parallel corpora', 'pos': [26, 28]}, 't': {'name': 'MT', 'pos': [29, 30]}, 'relation': 'usage'}
{'token': ['paper', 'describes', 'method', 'analyzing', 'Japanese', 'double', '-', 'subject', 'construction', 'adjective', 'predicate', 'based', 'valency', 'structure', '.'], 'h': {'name': 'adjective predicate', 'pos': [9, 11]}, 't': {'name': 'Japanese double-subject construction', 'pos': [4, 9]}, 'relation': 'model-feature'}
{'token': ['simple', 'sentence', 'usually', 'one', 'subjective', 'case', 'languages', '.'], 'h': {'name': 'subjective case', 'pos': [4, 6]}, 't': {'name': 'simple sentence', 'pos': [0, 2]}, 'relation': 'model-feature'}
{'token': ['paper', 'proposes', 'method', 'analyzing', 'Japanese', 'double', '-', 'subject', 'construction', 'adjective', 'predicate', 'order', 'overcome', 'thee', 'problems', 'described', '.'], 'h': {'name': 'adjective predicate', 'pos': [9, 11]}, 't': {'name': 'Japanese double-subject construction', 'pos': [4, 9]}, 'relation': 'model-feature'}
{'token': ['Classification', 'Hierarchies', '(', 'CHs', ')', 'widely', 'used', 'organize', 'documents', 'way', 'makes', 'retrieval', 'easier'], 'h': {'name': 'Classification Hierarchies (CHs)', 'pos': [0, 5]}, 't': {'name': 'retrieval', 'pos': [11, 12]}, 'relation': 'usage'}
{'token': ['paper', 'discuss', 'evaluate', 'Ctx', 'Match', ',', 'approach', 'interoperability', 'discovers', 'mappings', 'among', 'CHs', 'considering', 'semantic', 'interpretation', 'nodes', '.'], 'h': {'name': 'semantic interpretation', 'pos': [13, 15]}, 't': {'name': 'nodes', 'pos': [15, 16]}, 'relation': 'model-feature'}
{'token': ['CtxMatch', 'performs', 'a', 'linguistic', 'processing', 'of', 'labels', 'attached', 'to', ',', 'including', 'tokenization', ',', 'Part', 'of', 'tagging', ',', 'multiword', 'recognition', 'and', 'sense', 'disambiguation', '.'], 'h': {'name': 'linguistic processing', 'pos': [3, 5]}, 't': {'name': 'labels', 'pos': [6, 7]}, 'relation': 'usage'}
{'token': ['second', 'contribution', 'use', 'clustering', 'make', 'retrieval', 'best', 'matching', 'example', 'database', 'efficient', '.'], 'h': {'name': 'clustering', 'pos': [3, 4]}, 't': {'name': 'retrieval', 'pos': [5, 6]}, 'relation': 'usage'}
{'token': ['second', 'contribution', 'use', 'clustering', 'make', 'retrieval', 'best', 'matching', 'example', 'database', 'efficient', '.'], 'h': {'name': 'best matching example', 'pos': [6, 9]}, 't': {'name': 'database', 'pos': [9, 10]}, 'relation': 'part_whole'}
{'token': ['time', ',', 'higher', 'level', 'collective', 'knowledge', 'often', 'published', 'using', 'graphical', 'notation', 'representing', 'entities', 'pathway', 'interactions', '.'], 'h': {'name': 'graphical notation', 'pos': [9, 11]}, 't': {'name': 'entities', 'pos': [12, 13]}, 'relation': 'model-feature'}
