{'token': ['Semantic', 'Role', 'Labeling', '(', 'SRL', ')', ',', 'arguments', 'usually', 'limited', 'syntax', 'subtree', '.'], 'h': {'name': 'arguments', 'pos': [7, 8]}, 't': {'name': 'syntax subtree', 'pos': [10, 12]}, 'relation': 'part_whole'}
{'token': ['reasonable', 'label', 'arguments', 'locally', 'sub', '-', 'tree', 'rather', 'whole', 'tree', '.'], 'h': {'name': 'arguments', 'pos': [2, 3]}, 't': {'name': 'sub-tree', 'pos': [4, 7]}, 'relation': 'part_whole'}
{'token': ['anchor', 'group', 'approach', 'achieves', 'accuracy', '87.75', '%', 'single', 'anchor', 'approach', 'achieves', '83.63', '%.'], 'h': {'name': 'anchor group approach', 'pos': [0, 3]}, 't': {'name': 'accuracy', 'pos': [4, 5]}, 'relation': 'result'}
{'token': ['Experimental', 'results', 'also', 'indicate', 'prediction', 'MP', 'improves', 'semantic', 'role', 'labeling', '.'], 'h': {'name': 'prediction of MP', 'pos': [4, 6]}, 't': {'name': 'semantic role labeling', 'pos': [7, 10]}, 'relation': 'result'}
{'token': ['Recently', 'LATL', 'undertaken', 'development', 'multilingual', 'translation', 'system', 'based', 'symbolic', 'parsing', 'technology', 'transfer', '-', 'based', 'translation', 'model', '.'], 'h': {'name': 'symbolic parsing technology', 'pos': [8, 11]}, 't': {'name': 'multilingual translation system', 'pos': [4, 7]}, 'relation': 'usage'}
{'token': ['paper', 'describes', 'unsupervised', 'learning', 'algorithm', 'disambiguating', 'verbal', 'word', 'senses', 'using', 'term', 'weight', 'learning', '.'], 'h': {'name': 'term weight learning', 'pos': [10, 13]}, 't': {'name': 'verbal word senses', 'pos': [6, 9]}, 'relation': 'usage'}
{'token': ['quite', 'different', 'current', 'approaches', 'semantic', 'parsing', 'chunking', 'depend', 'full', 'statistical', 'syntactic', 'parsers', 'require', 'tree', 'bank', 'style', 'annotation', '.'], 'h': {'name': 'statistical syntactic parsers', 'pos': [9, 12]}, 't': {'name': 'chunking', 'pos': [6, 7]}, 'relation': 'usage'}
{'token': ['compare', 'recently', 'proposed', 'word', '-', 'word', 'semantic', 'chunker', 'and', 'results', 'that', 'that', 'phrase', '-', 'by-', 'approach', 'performs', 'better', 'than', 'its', '-', 'by', '-', 'counterpart', '.'], 'h': {'name': 'phrase-by-phrase approach', 'pos': [12, 16]}, 't': {'name': 'word-by-word counterpart', 'pos': [20, 24]}, 'relation': 'compare'}
{'token': ['primary', 'objective', 'basic', 'research', 'develop', 'improved', 'methods', 'models', 'acoustic', 'recognition', 'continuous', 'speech', '.'], 'h': {'name': 'acoustic recognition', 'pos': [8, 10]}, 't': {'name': 'continuous speech', 'pos': [10, 12]}, 'relation': 'usage'}
{'token': ['work', 'focussed', 'developing', 'accurate', 'detailed', 'mathematical', 'models', 'phonemes', 'coarticulation', 'purpose', 'large', '-', 'vocabulary', 'continuous', 'speech', 'recognition', '.'], 'h': {'name': 'phonemes', 'pos': [7, 8]}, 't': {'name': 'large-vocabulary continuous speech recognition', 'pos': [10, 16]}, 'relation': 'usage'}
{'token': ['KeyWords', 'compares', 'a', 'word', 'list', 'extracted', 'from', "'", 'the', 'corpus', "'", '(', 'the', 'which', 'is', 'in', ')', 'with', 'list', 'made', 'from', 'corpus', '.'], 'h': {'name': 'word list', 'pos': [3, 5]}, 't': {'name': 'corpus', 'pos': [9, 10]}, 'relation': 'part_whole'}
{'token': ['KeyWords', 'compares', 'a', 'list', 'extracted', 'from', "'", 'the', 'corpus', "'", '(', 'the', 'which', 'is', 'in', ')', 'with', 'word', 'list', 'made', 'from', 'reference', 'corpus', '.'], 'h': {'name': 'word list', 'pos': [17, 19]}, 't': {'name': 'reference corpus', 'pos': [21, 23]}, 'relation': 'part_whole'}
{'token': ['Five', 'English', 'corpora', 'compared', 'reference', 'corpora', 'various', 'sizes', '(', 'varying', 'two', '100', 'times', 'larger', 'study', 'corpus', ')', '.'], 'h': {'name': 'English corpora', 'pos': [1, 3]}, 't': {'name': 'reference corpora', 'pos': [4, 6]}, 'relation': 'compare'}
{'token': ['results', 'indicate', 'reference', 'corpus', 'five', 'times', 'large', 'study', 'corpus', 'yielded', 'larger', 'number', 'keywords', 'smaller', 'reference', 'corpus', '.'], 'h': {'name': 'keywords', 'pos': [12, 13]}, 't': {'name': 'corpus', 'pos': [8, 9]}, 'relation': 'part_whole'}
{'token': ['implication', 'larger', 'reference', 'corpus', 'always', 'better', 'smaller', 'one', ',', 'WordSmith', 'Tools', 'Keywords', 'analysis', ',', 'reference', 'corpus', 'less', 'five', 'times', 'size', 'study', 'corpus', 'may', 'reliable', '.'], 'h': {'name': 'reference corpus', 'pos': [14, 16]}, 't': {'name': 'study corpus', 'pos': [20, 22]}, 'relation': 'compare'}
{'token': ['paper', 'report', 'qualitative', 'evaluation', 'performance', 'dependency', 'analyser', 'Italian', 'runs', 'non-lexicalised', 'lexicalised', 'mode', '.'], 'h': {'name': 'dependency analyser', 'pos': [5, 7]}, 't': {'name': 'Italian', 'pos': [7, 8]}, 'relation': 'usage'}
{'token': ['Results', 'shed', 'light', 'contribution', 'types', 'lexical', 'information', 'parsing', '.'], 'h': {'name': 'lexical information', 'pos': [5, 7]}, 't': {'name': 'parsing', 'pos': [7, 8]}, 'relation': 'usage'}
{'token': ['international', 'phonology', 'speech', 'synthesis', 'research', ',', 'suggested', 'relative', 'informativeness', 'word', 'used', 'predict', 'pitch', 'prominence', '.'], 'h': {'name': 'relative informativeness', 'pos': [7, 9]}, 't': {'name': 'word', 'pos': [9, 10]}, 'relation': 'model-feature'}
{'token': ['paper', ',', 'provide', 'empirical', 'evidence', 'support', 'existence', 'correlation', 'employing', 'two', 'widely', 'accepted', 'measures', 'informativeness', '.'], 'h': {'name': 'measures', 'pos': [12, 13]}, 't': {'name': 'informativeness', 'pos': [13, 14]}, 'relation': 'model-feature'}
{'token': ['experiments', 'show', 'positive', 'correlation', 'informativeness', 'word', 'pitch', 'accent', 'assignment', '.'], 'h': {'name': 'informativeness', 'pos': [4, 5]}, 't': {'name': 'word', 'pos': [5, 6]}, 'relation': 'model-feature'}
{'token': ['computation', 'word', 'informativeness', 'inexpensive', 'incorporated', 'speech', 'synthesis', 'systems', 'easily', '.'], 'h': {'name': 'word informativeness', 'pos': [1, 3]}, 't': {'name': 'speech synthesis systems', 'pos': [5, 8]}, 'relation': 'usage'}
{'token': ['"', 'efficient', 'parsing', 'algorithm', 'augmented', 'context', '-', 'free', 'grammars', 'introduced', ',', 'application', 'line', 'natural', 'language', 'interfaces', 'discussed', '.'], 'h': {'name': 'parsing algorithm', 'pos': [2, 4]}, 't': {'name': 'augmented context-free grammars', 'pos': [4, 9]}, 'relation': 'usage'}
{'token': ['algorithm', 'generalized', 'LR', 'parsing', 'algorithm', ',', 'precomputes', 'LR', 'shift', '-', 'reduce', 'parsing', 'table', '(', 'possibly', 'multiple', 'entries', ')', 'given', 'augmented', 'context', '-', 'free', 'grammar', '.'], 'h': {'name': 'generalized LR parsing algorithm', 'pos': [1, 5]}, 't': {'name': 'LR shift-reduce parsing table', 'pos': [7, 13]}, 'relation': 'usage'}
{'token': ['also', 'view', 'parsing', 'algorithm', 'extended', 'chart', 'parsing', 'algorithm', 'efficiently', 'guided', 'LR', 'parsing', 'tables', '.'], 'h': {'name': 'LR parsing tables', 'pos': [10, 13]}, 't': {'name': 'chart parsing algorithm', 'pos': [5, 8]}, 'relation': 'usage'}
{'token': ['Also', ',', 'commercial', '-', 'line', 'parser', 'Japanese', 'language', 'built', 'Intelligent', 'Technology', 'Incorporation', ',', 'based', 'technique', 'developed', 'CMU', '.', '"'], 'h': {'name': 'on-line parser', 'pos': [3, 6]}, 't': {'name': 'Japanese language', 'pos': [6, 8]}, 'relation': 'usage'}
{'token': ['article', 'proposes', 'hybrid', 'statistical', 'structural', 'semantic', 'model', 'multi-stage', 'spoken', 'language', 'understanding', '(', 'SLU', ')', '.'], 'h': {'name': 'hybrid statistical and structural semantic model', 'pos': [2, 7]}, 't': {'name': 'multi-stage spoken language understanding (SLU)', 'pos': [7, 14]}, 'relation': 'usage'}
{'token': ['first', 'stage', 'SLU', 'utilizes', 'weighted', 'finite', '-', 'state', 'transducer', '(', 'WFST', ')', '-', 'based', 'parser', ',', 'encodes', 'regular', 'grammar', 'concepts', 'extracted', '.'], 'h': {'name': 'weighted finite-state transducer (WFST)-based parser', 'pos': [4, 15]}, 't': {'name': 'SLU', 'pos': [2, 3]}, 'relation': 'usage'}
{'token': ['proposed', 'method', 'improves', 'regular', 'grammar', 'model', 'incorporating', 'well', '-', 'known', 'n-gram', 'semantic', 'tagger', '.'], 'h': {'name': 'n-gram semantic tagger', 'pos': [10, 13]}, 't': {'name': 'regular grammar', 'pos': [3, 5]}, 'relation': 'usage'}
{'token': ['paper', 'presents', 'corpus', '-', 'based', 'account', 'structural', 'priming', 'human', 'sentence', 'processing', ',', 'focusing', 'role', 'syntactic', 'representations', 'play', 'account', '.'], 'h': {'name': 'structural priming', 'pos': [6, 8]}, 't': {'name': 'sentence processing', 'pos': [9, 11]}, 'relation': 'model-feature'}
{'token': ['estimate', 'strength', 'structural', 'priming', 'effects', 'corpus', 'spontaneous', 'spoken', 'dialogue', ',', 'annotated', 'syntactically', 'Combinatory', 'Categorial', 'Grammar', '(', 'CCG', ')', 'derivations', '.'], 'h': {'name': 'spontaneous spoken dialogue', 'pos': [6, 9]}, 't': {'name': 'corpus', 'pos': [5, 6]}, 'relation': 'part_whole'}
{'token': ['particular', ',', 'present', 'evidence', 'priming', 'lexical', 'syntactic', 'categories', 'encoding', 'partially', 'satisfied', 'sub-categorization', 'frames', ',', 'show', 'priming', 'effects', 'exist', 'incremental', 'normal', '-', 'form', 'CCG', 'derivations', '.'], 'h': {'name': 'priming effects', 'pos': [15, 17]}, 't': {'name': 'incremental and normal-form CCG derivations', 'pos': [18, 24]}, 'relation': 'model-feature'}
{'token': ['paper', 'describes', 'application', 'ensemble', 'indexing', 'classification', 'systems', ',', 'shown', 'successful', 'information', 'retrieval', 'classification', 'medical', 'literature', ',', 'new', 'task', 'assigning', 'ICD-9', '-', 'CM', 'codes', 'to', 'the', 'and', 'impression', 'of', 'radiology', '.'], 'h': {'name': 'information retrieval', 'pos': [10, 12]}, 't': {'name': 'medical literature', 'pos': [13, 15]}, 'relation': 'usage'}
{'token': ['type', 'summary', 'could', 'serve', 'effective', 'navigation', 'tool', 'accessing', 'information', 'long', 'texts', ',', 'books', '.'], 'h': {'name': 'summary', 'pos': [1, 2]}, 't': {'name': 'texts', 'pos': [10, 11]}, 'relation': 'model-feature'}
{'token': ['generate', 'coherent', 'table', '-', '-', 'contents', ',', 'need', 'capture', 'global', 'dependencies', 'across', 'different', 'titles', 'table', 'local', 'constraints', 'within', 'sections', '.'], 'h': {'name': 'titles', 'pos': [13, 14]}, 't': {'name': 'table-of-contents', 'pos': [2, 6]}, 'relation': 'usage'}
{'token': ['First', ',', 'compare', 'cruiser', 'baseline', 'system', '-', 'initiative', 'DS', ',', 'show', 'users', 'prefer', 'cruiser', '.'], 'h': {'name': 'cruiser', 'pos': [3, 4]}, 't': {'name': 'system-initiative DS', 'pos': [5, 9]}, 'relation': 'compare'}
{'token': ['improve', 'Mandarin', 'large', 'vocabulary', 'continuous', 'speech', 'recognition', '(', 'LVCSR', ')', ',', 'unified', 'framework', 'based', 'approach', 'introduced', 'exploit', 'multi-level', 'linguistic', 'knowledge', '.'], 'h': {'name': 'multi-level linguistic knowledge', 'pos': [17, 20]}, 't': {'name': 'large vocabulary continuous speech recognition (LVCSR)', 'pos': [2, 10]}, 'relation': 'usage'}
{'token': ['framework', ',', 'knowledge', 'source', 'represented', 'Weighted', 'Finite', 'State', 'Transducer', '(', 'WFST', ')', ',', 'combined', 'obtain', 'so-called', 'analyzer', 'integrating', 'multi-level', 'knowledge', 'sources', '.'], 'h': {'name': 'Weighted Finite State Transducer (WFST)', 'pos': [5, 12]}, 't': {'name': 'knowledge source', 'pos': [2, 4]}, 'relation': 'model-feature'}
{'token': ['Due', 'uniform', 'transducer', 'representation', ',', 'knowledge', 'source', 'easily', 'integrated', 'analyzer', ',', 'long', 'encoded', 'WFSTs', '.'], 'h': {'name': 'knowledge source', 'pos': [5, 7]}, 't': {'name': 'WFSTs', 'pos': [13, 14]}, 'relation': 'usage'}
{'token': ['paper', 'discuss', 'algorithms', 'clustering', 'words', 'classes', 'unlabeled', 'text', 'using', 'unsupervised', 'algorithms', ',', 'based', 'distributional', 'morphological', 'information', '.'], 'h': {'name': 'words', 'pos': [4, 5]}, 't': {'name': 'unlabeled text', 'pos': [6, 8]}, 'relation': 'part_whole'}
{'token': ['"', 'paper', 'presents', 'unsupervised', 'relation', 'extraction', 'algorithm', ',', 'induces', 'relations', 'entity', 'pairs', 'grouping', '"', 'natural', '"', 'number', 'clusters', 'based', 'similarity', 'contexts', '.'], 'h': {'name': 'unsupervised relation extraction algorithm', 'pos': [3, 7]}, 't': {'name': 'entity pairs', 'pos': [10, 12]}, 'relation': 'usage'}
{'token': ['paper', 'presents', 'method', 'measures', 'similarity', 'compound', 'nouns', 'different', 'languages', 'locate', 'translation', 'equivalents', 'corpora', '.'], 'h': {'name': 'translation equivalents', 'pos': [10, 12]}, 't': {'name': 'corpora', 'pos': [12, 13]}, 'relation': 'part_whole'}
{'token': ['method', 'uses', 'information', 'unrelated', 'corpora', 'different', 'languages', 'parallel', '.'], 'h': {'name': 'corpora', 'pos': [4, 5]}, 't': {'name': 'languages', 'pos': [6, 7]}, 'relation': 'model-feature'}
{'token': ['method', 'compares', 'contexts', 'target', 'compound', 'nouns', 'translation', 'candidates', 'word', 'semantic', 'attribute', 'level', '.'], 'h': {'name': 'contexts', 'pos': [2, 3]}, 't': {'name': 'translation candidates', 'pos': [6, 8]}, 'relation': 'compare'}
{'token': ['paper', ',', 'show', 'measuring', 'method', 'applied', 'select', 'best', 'English', 'translation', 'candidate', 'Japanese', 'compound', 'nouns', '70', '%', 'cases', '.'], 'h': {'name': 'English translation', 'pos': [8, 10]}, 't': {'name': 'Japanese compound nouns', 'pos': [11, 14]}, 'relation': 'usage'}
{'token': ['Applications', 'statistical', 'Arabic', 'NLP', 'general', ',', 'text', 'mining', 'specific', ',', 'along', 'tools', 'underneath', 'perform', 'much', 'better', 'statistical', 'processing', 'operates', 'deeper', 'language', 'factorization', '(', ')', 'raw', 'text'], 'h': {'name': 'text mining', 'pos': [6, 8]}, 't': {'name': 'statistical Arabic NLP', 'pos': [1, 4]}, 'relation': 'part_whole'}
{'token': ['Applications', 'statistical', 'Arabic', 'NLP', 'general', ',', 'text', 'mining', 'specific', ',', 'along', 'tools', 'underneath', 'perform', 'much', 'better', 'statistical', 'processing', 'operates', 'deeper', 'language', 'factorization', '(', ')', 'raw', 'text'], 'h': {'name': 'statistical processing', 'pos': [16, 18]}, 't': {'name': 'language factorization(s)', 'pos': [20, 24]}, 'relation': 'usage'}
{'token': ['building', 'LR', ',', 'go', 'beyond', 'conventional', 'exclusive', 'collection', 'words', 'dictionaries', 'thesauri', 'cannot', 'alone', 'produce', 'satisfactory', 'coverage', 'highly', 'inflective', 'derivative', 'language', '.'], 'h': {'name': 'words', 'pos': [8, 9]}, 't': {'name': 'dictionaries', 'pos': [9, 10]}, 'relation': 'part_whole'}
{'token': ['aid', 'large', '-', 'scale', 'Arabic', 'morphological', 'analyzer', 'PoS', 'tagger', 'runtime', ',', 'possible', 'senses', 'virtually', 'given', 'Arabic', 'word', 'retrievable', '.'], 'h': {'name': 'PoS tagger', 'pos': [7, 9]}, 't': {'name': 'Arabic word', 'pos': [15, 17]}, 'relation': 'usage'}
{'token': ['Similarly', 'well', '-', 'established', 'ROVER', 'approach', '(', 'Fiscus', ',', '1997', ')', 'combining', 'speech', 'recognition', 'hypotheses', ',', 'consensus', 'translation', 'computed', 'voting', 'confusion', 'network', '.'], 'h': {'name': 'confusion network', 'pos': [20, 22]}, 't': {'name': 'consensus translation', 'pos': [16, 18]}, 'relation': 'usage'}
{'token': ['create', 'confusion', 'network', ',', 'produce', 'pairwise', 'word', 'alignments', 'original', 'machine', 'translation', 'hypotheses', 'enhanced', 'statistical', 'alignment', 'algorithm', 'explicitly', 'models', 'word', 'reordering', '.'], 'h': {'name': 'statistical alignment algorithm', 'pos': [13, 16]}, 't': {'name': 'word alignments', 'pos': [6, 8]}, 'relation': 'usage'}
{'token': ['context', 'whole', 'document', 'translations', 'rather', 'single', 'sentence', 'taken', 'account', 'produce', 'alignment', '.'], 'h': {'name': 'document', 'pos': [2, 3]}, 't': {'name': 'alignment', 'pos': [10, 11]}, 'relation': 'usage'}
{'token': ['method', 'also', 'tested', 'framework', 'multi-source', 'speech', 'translation', '.'], 'h': {'name': 'method', 'pos': [0, 1]}, 't': {'name': 'multi-source and speech translation', 'pos': [4, 7]}, 'relation': 'usage'}
{'token': ['present', 'two', 'stage', 'parser', 'recovers', 'Penn', 'Treebank', 'style', 'syntactic', 'analyses', 'new', 'sentences', 'including', 'skeletal', 'syntactic', 'structure', ',', ',', 'first', 'time', ',', 'function', 'tags', 'empty', 'categories', '.'], 'h': {'name': 'syntactic analyses', 'pos': [8, 10]}, 't': {'name': 'sentences', 'pos': [11, 12]}, 'relation': 'usage'}
{'token': ['accuracy', 'first', '-', 'stage', 'parser', 'standard', 'Parseval', 'metric', 'matches', '(', 'Collins', ',', '2003', ')', 'parser', 'based', ',', 'despite', 'data', 'fragmentation', 'caused', 'greatly', 'enriched', 'space', 'possible', 'node', 'labels', '.'], 'h': {'name': 'parser', 'pos': [4, 5]}, 't': {'name': 'parser', 'pos': [14, 15]}, 'relation': 'compare'}
{'token': ['anaphora', 'resolution', 'prepositional', 'phrase', '(', 'PP', ')', 'attachment', 'frequent', 'ambiguities', 'natural', 'language', 'processing', '.'], 'h': {'name': 'ambiguities', 'pos': [9, 10]}, 't': {'name': 'natural language processing', 'pos': [10, 13]}, 'relation': 'model-feature'}
{'token': ['speaker', 'adaptation', 'speaker', '-', 'independent', 'system', ',', 'two', 'vocabulary', 'adaptation', 'algorithms', '[', '5', ']', 'implemented', 'order', 'tailor', 'VI', 'subword', 'models', 'target', 'vocabulary', '.'], 'h': {'name': 'vocabulary adaptation algorithms', 'pos': [8, 11]}, 't': {'name': 'VI subword models', 'pos': [17, 20]}, 'relation': 'usage'}
{'token': ['past', '9', 'years', ',', 'Applied', 'Science', 'Engineering', 'Laboratories', '(', 'ASEL', ')', 'University', 'Delaware', 'duPont', 'Hospital', 'Children', ',', 'involved', 'applying', 'natural', 'language', 'processing', '(', 'NLP', ')', 'technologies', 'field', 'AAC', '.'], 'h': {'name': 'natural language processing (NLP) technologies', 'pos': [19, 26]}, 't': {'name': 'AAC', 'pos': [27, 28]}, 'relation': 'usage'}
{'token': ['One', 'major', 'projects', 'ASEL', '(', 'COMPAN', '-', 'SION', 'project', ')', 'concerned', 'application', 'primarily', 'lexical', 'semantics', 'sentence', 'generation', 'technology', 'expand', 'telegraphic', 'input', 'full', 'sentences', '.'], 'h': {'name': 'sentence generation technology', 'pos': [15, 18]}, 't': {'name': 'telegraphic input', 'pos': [19, 21]}, 'relation': 'usage'}
{'token': ['view', 'entire', 'problem', 'series', 'classification', 'problems', 'employ', 'memory', '-', 'based', 'learning', '(', 'MBL', ')', 'resolve', '.'], 'h': {'name': 'memory-based learning (MBL)', 'pos': [7, 14]}, 't': {'name': 'classification problems', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['problem', 'word', 'segmentation', 'affects', 'aspects', 'Chinese', 'language', 'processing', ',', 'including', 'development', 'text', '-', '-speech', 'synthesis', 'systems', '.'], 'h': {'name': 'word segmentation', 'pos': [1, 3]}, 't': {'name': 'Chinese language processing', 'pos': [5, 8]}, 'relation': 'part_whole'}
{'token': ['paper', 'treats', 'classification', 'semantic', 'functions', 'performed', 'adnominal', 'constituents', 'Japanese', ',', 'many', 'parts', 'speech', 'act', 'adnominal', 'constituents', '.'], 'h': {'name': 'adnominal constituents', 'pos': [6, 8]}, 't': {'name': 'Japanese', 'pos': [8, 9]}, 'relation': 'part_whole'}
{'token': ['adjectives', '"', 'noun', '+', '"', '(', 'English', '"', '+', 'noun', '"', ')', 'structures', ',', 'broad', 'range', 'semantic', 'functions', ',', 'discussed', '.'], 'h': {'name': 'semantic functions', 'pos': [16, 18]}, 't': {'name': '"noun + NO" (in English "of + noun") structures', 'pos': [1, 13]}, 'relation': 'model-feature'}
{'token': ['feasibility', 'verified', 'self', '-', 'organizing', 'semantic', 'map', 'based', 'neural', 'network', 'model', '.'], 'h': {'name': 'neural network model', 'pos': [8, 11]}, 't': {'name': 'self-organizing semantic map', 'pos': [2, 7]}, 'relation': 'usage'}
{'token': ['Recent', 'corpus', '-', 'based', 'work', 'word', 'sense', 'disambiguation', 'explores', 'application', 'statistical', 'pattern', 'recognition', 'procedures', 'lexical', 'co-occurrence', 'data', 'large', 'text', 'databases', '.'], 'h': {'name': 'statistical pattern recognition procedures', 'pos': [10, 14]}, 't': {'name': 'lexical co-occurrence data', 'pos': [14, 17]}, 'relation': 'usage'}
{'token': ['Statistical', 'methods', 'play', 'definite', 'role', 'work', ',', 'helping', 'organize', 'analyze', 'data', ',', 'disambiguation', 'method', 'employ', 'statistical', 'data', 'decision', 'criteria', '.'], 'h': {'name': 'statistical data', 'pos': [15, 17]}, 't': {'name': 'disambiguation method', 'pos': [12, 14]}, 'relation': 'usage'}
{'token': ['approach', 'illustrated', 'experiment', 'discriminating', 'among', 'senses', 'adjectives', ',', 'relatively', 'neglected', 'work', 'sense', 'disambiguation', '.'], 'h': {'name': 'senses', 'pos': [5, 6]}, 't': {'name': 'adjectives', 'pos': [6, 7]}, 'relation': 'model-feature'}
{'token': ['particular', ',', 'paper', 'assesses', 'potential', 'nouns', 'discriminating', 'among', 'senses', 'adjectives', 'modify', '.'], 'h': {'name': 'senses', 'pos': [8, 9]}, 't': {'name': 'adjectives', 'pos': [9, 10]}, 'relation': 'model-feature'}
{'token': ['assessment', 'based', 'empirical', 'study', 'five', 'frequent', 'ambiguous', 'adjectives', 'English', ':', 'three', '-', 'quarters', 'instances', 'adjectives', 'disambiguated', 'almost', 'errorlessly', 'nouns', 'modify', 'syntactic', 'constructions', 'occur', '.'], 'h': {'name': 'ambiguous adjectives', 'pos': [6, 8]}, 't': {'name': 'English', 'pos': [8, 9]}, 'relation': 'part_whole'}
{'token': ['assessment', 'based', 'empirical', 'study', 'five', 'frequent', 'ambiguous', 'adjectives', 'English', ':', 'three', '-', 'quarters', 'instances', 'adjectives', 'disambiguated', 'almost', 'errorlessly', 'nouns', 'modify', 'syntactic', 'constructions', 'occur', '.'], 'h': {'name': 'nouns', 'pos': [18, 19]}, 't': {'name': 'syntactic constructions', 'pos': [20, 22]}, 'relation': 'model-feature'}
{'token': ['Furthermore', ',', 'small', 'number', 'semantic', 'attributes', 'supply', 'compact', 'means', 'representing', 'noun', 'clues', 'rules', '.'], 'h': {'name': 'semantic attributes', 'pos': [4, 6]}, 't': {'name': 'noun', 'pos': [10, 11]}, 'relation': 'model-feature'}
{'token': ['sense', 'ambiguous', 'modified', 'noun', 'may', 'needed', 'determine', 'relevant', 'semantic', 'attribute', 'disambiguation', 'target', 'adjective', ';', 'adjectives', ',', 'verbs', ',', 'grammatical', 'constructions', 'show', 'evidence', 'high', 'reliability', ',', 'sometimes', 'high', 'applicability', ',', 'stand', 'specific', ',', 'well', '-', 'defined', 'syntactic', 'relations', 'ambiguous', 'adjective', '.'], 'h': {'name': 'sense', 'pos': [0, 1]}, 't': {'name': 'ambiguous modified noun', 'pos': [1, 4]}, 'relation': 'model-feature'}
{'token': ['sense', 'ambiguous', 'modified', 'noun', 'may', 'needed', 'determine', 'relevant', 'semantic', 'attribute', 'disambiguation', 'target', 'adjective', ';', 'adjectives', ',', 'verbs', ',', 'grammatical', 'constructions', 'show', 'evidence', 'high', 'reliability', ',', 'sometimes', 'high', 'applicability', ',', 'stand', 'specific', ',', 'well', '-', 'defined', 'syntactic', 'relations', 'ambiguous', 'adjective', '.'], 'h': {'name': 'semantic attribute', 'pos': [8, 10]}, 't': {'name': 'target adjective', 'pos': [11, 13]}, 'relation': 'model-feature'}
{'token': ['paper', 'presents', 'method', 'incorporating', 'character', 'clustering', 'based', 'mutual', 'information', 'Decision', '-', 'Tree', 'Dictionary', '-', 'less', 'morphological', 'analysis', '.'], 'h': {'name': 'mutual information', 'pos': [7, 9]}, 't': {'name': 'character clustering', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['using', 'natural', 'classes', ',', 'confirmed', 'morphological', 'analyzer', 'significantly', 'improved', 'tokenizing', 'tagging', 'Japanese', 'text', '.'], 'h': {'name': 'tagging', 'pos': [10, 11]}, 't': {'name': 'text', 'pos': [12, 13]}, 'relation': 'usage'}
{'token': ['case', 'study', 'one', 'direction', ',', 'discuss', 'recent', 'development', 'automatic', 'method', 'evaluating', 'definition', 'questions', 'based', 'n-gram', 'overlap', ',', 'commonly', '-', 'used', 'technique', 'summarization', 'evaluation', '.'], 'h': {'name': 'n-gram overlap', 'pos': [14, 16]}, 't': {'name': 'automatic method for evaluating definition questions', 'pos': [8, 13]}, 'relation': 'usage'}
{'token': ["SYSTRAN'S", 'Chinese', 'word', 'segmentation', 'one', 'important', 'component', 'Chinese', '-', 'English', 'machine', 'translation', 'system', '.'], 'h': {'name': 'Chinese word segmentation', 'pos': [1, 4]}, 't': {'name': 'Chinese-English machine translation system', 'pos': [7, 13]}, 'relation': 'part_whole'}
{'token': ['Chinese', 'word', 'segmentation', 'module', 'uses', 'rule', '-', 'based', 'approach', ',', 'based', 'large', 'dictionary', 'fine', '-', 'grained', 'linguistic', 'rules', '.'], 'h': {'name': 'rule-based approach', 'pos': [5, 9]}, 't': {'name': 'Chinese word segmentation', 'pos': [0, 3]}, 'relation': 'usage'}
{'token': ['works', 'general', '-', 'purpose', 'texts', 'different', 'Chinese', '-speaking', 'regions', ',', 'with', 'performance', '.'], 'h': {'name': 'Chinese-speaking regions', 'pos': [6, 9]}, 't': {'name': 'general-purpose texts', 'pos': [1, 5]}, 'relation': 'model-feature'}
{'token': ['ParaMor', ',', 'minimally', 'supervised', 'morphology', 'induction', 'algorithm', ',', 'retrusses', 'word', 'forms', 'raw', 'text', 'corpora', 'back', 'onto', 'paradigmatic', 'skeletons', ';', 'performing', 'par', 'state', '-', '-', '-', 'art', 'minimally', 'supervised', 'morphology', 'induction', 'algorithms', 'morphological', 'analysis', 'English', 'German', '.'], 'h': {'name': 'morphological analysis', 'pos': [31, 33]}, 't': {'name': 'English', 'pos': [33, 34]}, 'relation': 'usage'}
{'token': ['structures', 'hand', ',', 'Para', 'Mor', 'annotates', 'word', 'forms', 'morpheme', 'boundaries', '.'], 'h': {'name': 'morpheme boundaries', 'pos': [8, 10]}, 't': {'name': 'word forms', 'pos': [6, 8]}, 'relation': 'model-feature'}
{'token': ['set', 'ParaMor', "'s", 'free', 'parameters', 'analyze', 'training', 'corpus', 'Spanish', '.'], 'h': {'name': 'Spanish', 'pos': [8, 9]}, 't': {'name': 'training corpus', 'pos': [6, 8]}, 'relation': 'part_whole'}
{'token': ['Without', 'adjusting', 'parameters', ',', 'induce', 'morphological', 'structure', 'English', 'German', '.'], 'h': {'name': 'morphological structure', 'pos': [5, 7]}, 't': {'name': 'English', 'pos': [7, 8]}, 'relation': 'model-feature'}
{'token': ['contribution', 'work', 'incorporated', 'novel', 'long', 'distance', 'features', 'address', 'challenges', 'computing', 'multi-level', 'confidence', 'scores', '.'], 'h': {'name': 'distance features', 'pos': [5, 7]}, 't': {'name': 'multi-level confidence scores', 'pos': [10, 13]}, 'relation': 'usage'}
{'token': ['Using', 'Conditional', 'Maximum', 'Entropy', '(', 'CME', ')', 'classifier', 'selected', 'features', ',', 'reached', 'annotation', 'error', 'rate', '26.0', '%', 'SWBD', 'corpus', ',', 'compared', 'subtree', 'error', 'rate', '41.91', '%', ',', 'closely', 'related', 'benchmark', 'Charniak', 'parser', '(', 'Kahn', 'et', 'al.', ',', '2005', ')', '.'], 'h': {'name': 'Conditional Maximum Entropy (CME) classifier', 'pos': [1, 8]}, 't': {'name': 'annotation error rate', 'pos': [12, 15]}, 'relation': 'result'}
{'token': ['Coreference', 'resolution', 'systems', 'usually', 'attempt', 'find', 'suitable', 'antecedent', '(', 'almost', ')', 'every', 'noun', 'phrase'], 'h': {'name': 'Coreference resolution systems', 'pos': [0, 3]}, 't': {'name': 'noun phrase', 'pos': [12, 14]}, 'relation': 'usage'}
{'token': ['use', 'small', 'training', 'corpus', '(', 'MUC', '-', '7', ')', ',', 'also', 'acquire', 'data', 'Internet', '.'], 'h': {'name': 'data', 'pos': [12, 13]}, 't': {'name': 'Internet', 'pos': [13, 14]}, 'relation': 'part_whole'}
{'token': ['Combining', 'classifiers', 'sequentially', ',', 'achieve', '88.9', '%', 'precision', '84.6', '%', 'recall', 'discourse', 'new', 'entities', '.'], 'h': {'name': 'classifiers', 'pos': [1, 2]}, 't': {'name': 'precision', 'pos': [7, 8]}, 'relation': 'result'}
{'token': ['expect', 'classifiers', 'provide', 'good', 'prefiltering', 'coreference', 'resolution', 'systems', ',', 'improving', 'speed', 'performance', '.'], 'h': {'name': 'classifiers', 'pos': [1, 2]}, 't': {'name': 'coreference resolution systems', 'pos': [5, 8]}, 'relation': 'usage'}
{'token': ['MBDP', '-1', 'knowledge', '-', 'free', 'segmentation', 'algorithm', 'bootstraps', 'lexicon', ',', 'starts', 'empty', '.'], 'h': {'name': 'knowledge-free segmentation algorithm', 'pos': [2, 7]}, 't': {'name': 'lexicon', 'pos': [8, 9]}, 'relation': 'usage'}
{'token': ['paper', ',', 'present', 'methods', 'allow', 'users', 'natural', 'language', 'processor', '(', 'NLP', ')', 'define', ',', 'inspect', ',', 'modify', 'case', 'frame', 'information', 'associated', 'words', 'phrases', 'known', 'system', '.'], 'h': {'name': 'case frame information', 'pos': [17, 20]}, 't': {'name': 'words', 'pos': [21, 22]}, 'relation': 'model-feature'}
{'token': ['number', 'sizes', 'parallel', 'corpora', 'keep', 'growing', ',', 'makes', 'necessary', 'automatic', 'methods', 'processing', ':', 'combining', ',', 'checking', 'improving', 'corpora', 'quality', ',', 'etc.'], 'h': {'name': 'corpora quality', 'pos': [17, 19]}, 't': {'name': 'parallel corpora', 'pos': [2, 4]}, 'relation': 'model-feature'}
{'token': ['method', 'takes', 'consideration', 'slight', 'differences', 'source', 'documents', ',', 'different', 'levels', 'segmentation', 'input', 'corpora', ',', 'encoding', 'differences', 'aspects', 'task', '.'], 'h': {'name': 'segmentation', 'pos': [10, 11]}, 't': {'name': 'input corpora', 'pos': [11, 13]}, 'relation': 'usage'}
{'token': ['first', 'experiment', ',', 'Estonian', '-', 'English', 'part', 'JRC', '-', 'Acquis', 'corpus', 'combined', 'another', 'corpus', 'legislation', 'texts', '.'], 'h': {'name': 'Estonian-English', 'pos': [3, 6]}, 't': {'name': 'JRC-Acquis corpus', 'pos': [7, 11]}, 'relation': 'part_whole'}
{'token': ['first', 'experiment', ',', 'Estonian', '-', 'English', 'part', 'JRC', '-', 'Acquis', 'corpus', 'combined', 'another', 'corpus', 'legislation', 'texts', '.'], 'h': {'name': 'legislation texts', 'pos': [14, 16]}, 't': {'name': 'corpus', 'pos': [13, 14]}, 'relation': 'part_whole'}
{'token': ['generation', 'module', 'supports', 'seamless', 'integration', 'full', 'grammar', 'rules', ',', 'templates', 'canned', 'text', '.'], 'h': {'name': 'grammar rules', 'pos': [6, 8]}, 't': {'name': 'generation module', 'pos': [0, 2]}, 'relation': 'usage'}
{'token': ['Ambiguity', 'fundamental', 'property', 'natural', 'language'], 'h': {'name': 'Ambiguity', 'pos': [0, 1]}, 't': {'name': 'natural language', 'pos': [3, 5]}, 'relation': 'model-feature'}
{'token': ['Perhaps', ',', 'burdensome', 'case', 'ambiguity', 'manifests', 'syntactic', 'level', 'analysis', '.'], 'h': {'name': 'ambiguity', 'pos': [4, 5]}, 't': {'name': 'syntactic level of analysis', 'pos': [6, 9]}, 'relation': 'model-feature'}
{'token': ['presented', 'methods', 'based', 'language', 'specific', 'features', 'synthetical', 'languages', 'improve', 'results', 'simple', 'stochastic', 'approaches', '.'], 'h': {'name': 'language specific features', 'pos': [3, 6]}, 't': {'name': 'synthetical languages', 'pos': [6, 8]}, 'relation': 'model-feature'}
{'token': ['texts', 'English', 'Czech', '.'], 'h': {'name': 'texts', 'pos': [0, 1]}, 't': {'name': 'English', 'pos': [1, 2]}, 'relation': 'model-feature'}
{'token': ['paper', 'presents', 'techniques', 'multimedia', 'annotation', 'application', 'video', 'summarization', 'translation', '.'], 'h': {'name': 'multimedia annotation', 'pos': [3, 5]}, 't': {'name': 'video summarization and translation', 'pos': [6, 9]}, 'relation': 'usage'}
{'token': ['video', 'scene', 'description', 'consists', 'semi-automatically', 'detected', 'keyframes', 'scene', 'video', 'clip', 'time', 'codes', 'scenes', '.'], 'h': {'name': 'semi-automatically detected keyframes', 'pos': [4, 7]}, 't': {'name': 'video scene description', 'pos': [0, 3]}, 'relation': 'part_whole'}
{'token': ['text', 'data', 'multimedia', 'annotation', 'syntactically', 'semantically', 'structured', 'using', 'linguistic', 'annotation', '.'], 'h': {'name': 'text data', 'pos': [0, 2]}, 't': {'name': 'syntactically and semantically structured', 'pos': [4, 7]}, 'relation': 'model-feature'}
{'token': ['proposed', 'multimedia', 'summarization', 'works', 'upon', 'multimodal', 'document', 'consists', 'video', ',', 'keyframes', 'scenes', ',', 'transcripts', 'scenes', '.'], 'h': {'name': ' multimedia summarization', 'pos': [1, 3]}, 't': {'name': 'multimodal document', 'pos': [5, 7]}, 'relation': 'usage'}
{'token': ['multimedia', 'translation', 'automatically', 'generates', 'several', 'versions', 'multimedia', 'content', 'different', 'languages', '.'], 'h': {'name': 'languages', 'pos': [9, 10]}, 't': {'name': 'multimedia content', 'pos': [6, 8]}, 'relation': 'model-feature'}
{'token': ['machine', 'translation', '(', 'MT', ')', 'knowledge', 'automatically', 'constructed', 'bilingual', 'corpora', ',', 'redundant', 'rules', 'acquired', 'due', 'translation', 'variety', '.'], 'h': {'name': 'bilingual corpora', 'pos': [8, 10]}, 't': {'name': 'machine translation (MT) knowledge', 'pos': [0, 6]}, 'relation': 'usage'}
{'token': ['rules', 'increase', 'ambiguity', 'cause', 'incorrect', 'MT', 'results', '.'], 'h': {'name': 'rules', 'pos': [0, 1]}, 't': {'name': 'ambiguity', 'pos': [2, 3]}, 'relation': 'result'}
{'token': ['overcome', 'problem', ',', 'constrain', 'sentences', 'used', 'knowledge', 'extraction', '"', 'appropriate', 'bilingual', 'sentences', 'MT', '"', '.'], 'h': {'name': 'sentences', 'pos': [4, 5]}, 't': {'name': 'knowledge extraction', 'pos': [6, 8]}, 'relation': 'usage'}
{'token': ['overcome', 'problem', ',', 'constrain', 'sentences', 'used', 'knowledge', 'extraction', '"', 'appropriate', 'bilingual', 'sentences', 'MT', '"', '.'], 'h': {'name': 'bilingual sentences', 'pos': [10, 12]}, 't': {'name': 'MT', 'pos': [12, 13]}, 'relation': 'usage'}
{'token': ['creation', 'scholarly', 'digital', 'editions', 'AAC', 'edition', 'philosophy', 'edition', 'principles', 'applied', 'whereby', 'new', 'corpus', 'research', 'methods', 'made', 'use', 'questions', 'computational', 'philology', 'textual', 'studies', 'digital', 'environment', '.'], 'h': {'name': 'AAC edition philosophy and edition principles', 'pos': [4, 9]}, 't': {'name': 'scholarly digital editions', 'pos': [1, 4]}, 'relation': 'usage'}
{'token': ['evaluation', 'results', 'show', 'system', 'achieve', 'F', 'measure', '0.9400.967', 'different', 'testing', 'corpora', '.'], 'h': {'name': 'system', 'pos': [3, 4]}, 't': {'name': 'F measure', 'pos': [5, 7]}, 'relation': 'result'}
{'token': ['paper', ',', 'propose', 'machine', 'learning', 'algorithm', 'shallow', 'semantic', 'parsing', ',', 'extending', 'work', 'Gildea', 'Jurafsky', '(', '2002', ')', ',', 'Surdeanu', 'et', 'al.', '(', '2003', ')', 'others', '.'], 'h': {'name': 'machine learning algorithm', 'pos': [3, 6]}, 't': {'name': 'shallow semantic parsing', 'pos': [6, 9]}, 'relation': 'usage'}
{'token': ['algorithm', 'based', 'Support', 'Vector', 'Machines', 'show', 'give', 'improvement', 'performance', 'earlier', 'classifiers', '.'], 'h': {'name': 'Support Vector Machines', 'pos': [2, 5]}, 't': {'name': 'algorithm', 'pos': [0, 1]}, 'relation': 'usage'}
{'token': ['show', 'performance', 'improvements', 'number', 'new', 'features', 'measure', 'ability', 'generalize', 'new', 'test', 'set', 'drawn', 'AQUAINT', 'corpus', '.'], 'h': {'name': 'test set', 'pos': [10, 12]}, 't': {'name': 'AQUAINT corpus', 'pos': [13, 15]}, 'relation': 'part_whole'}
{'token': ['Many', 'kinds', 'language', 'model', 'used', 'speech', 'understanding', 'suffer', 'imperfect', 'modeling', 'intra-sentential', 'contextual', 'influences', '.'], 'h': {'name': 'language model', 'pos': [2, 4]}, 't': {'name': 'speech understanding', 'pos': [5, 7]}, 'relation': 'usage'}
{'token': ['argue', 'problem', 'addressed', 'clustering', 'sentences', 'training', 'corpus', 'automatically', 'sub', 'corpora', 'criterion', 'entropy', 'reduction', ',', 'calculating', 'separate', 'language', 'model', 'parameters', 'cluster', '.'], 'h': {'name': 'sentences', 'pos': [4, 5]}, 't': {'name': 'training corpus', 'pos': [5, 7]}, 'relation': 'part_whole'}
{'token': ['kind', 'clustering', 'offers', 'way', 'represent', 'important', 'contextual', 'effects', 'therefore', 'significantly', 'improve', 'performance', 'model', '.'], 'h': {'name': 'clustering', 'pos': [1, 2]}, 't': {'name': 'contextual effects', 'pos': [6, 8]}, 'relation': 'model-feature'}
{'token': ['also', 'offers', 'reasonably', 'automatic', 'means', 'gather', 'evidence', 'whether', 'complex', ',', 'context', '-', 'sensitive', 'model', 'using', 'general', 'kind', 'linguistic', 'information', 'likely', 'reward', 'effort', 'would', 'required', 'develop', ':', 'clustering', 'improves', 'performance', 'model', ',', 'proves', 'existence', 'context', 'dependencies', ',', 'exploited', 'unclustered', 'model', '.'], 'h': {'name': 'clustering', 'pos': [26, 27]}, 't': {'name': 'model', 'pos': [29, 30]}, 'relation': 'result'}
{'token': ['evidence', 'claims', ',', 'present', 'results', 'showing', 'clustering', 'improves', 'models', 'others', 'ATIS', 'domain', '.'], 'h': {'name': 'clustering', 'pos': [6, 7]}, 't': {'name': 'models', 'pos': [8, 9]}, 'relation': 'result'}
{'token': ['paper', 'presents', 'parsing', 'system', 'detection', 'syntactic', 'errors', '.'], 'h': {'name': 'parsing system', 'pos': [2, 4]}, 't': {'name': 'detection of syntactic errors', 'pos': [4, 7]}, 'relation': 'usage'}
{'token': ['combines', 'robust', 'partial', 'parser', 'obtains', 'main', 'sentence', 'components', 'finite', '-', 'state', 'parser', 'used', 'description', 'syntactic', 'error', 'patterns', '.'], 'h': {'name': 'finite-state parser', 'pos': [8, 12]}, 't': {'name': 'syntactic error patterns', 'pos': [14, 17]}, 'relation': 'usage'}
{'token': ['system', 'tested', 'corpus', 'real', 'texts', ',', 'containing', 'correct', 'incorrect', 'sentences', ',', 'promising', 'results', '.'], 'h': {'name': 'texts', 'pos': [4, 5]}, 't': {'name': 'corpus', 'pos': [2, 3]}, 'relation': 'part_whole'}
{'token': ['objectives', 'project', 'advance', 'understanding', 'merits', 'current', 'text', 'analysis', 'techniques', ',', 'applied', 'performance', 'realistic', 'text', 'analysis', 'tasks', ',', 'achieve', 'understanding', 'means', 'sound', 'performance', 'evaluation', 'methodology', '.'], 'h': {'name': 'text analysis techniques', 'pos': [6, 9]}, 't': {'name': 'realistic text analysis tasks', 'pos': [12, 16]}, 'relation': 'usage'}
{'token': ['Talk', "'n", "'", 'Travel', 'fully', 'conversational', ',', 'mixed', '-', 'initiative', 'system', 'allows', 'user', 'specify', 'constraints', 'travel', 'plan', 'arbitrary', 'order', ',', 'ask', 'questions', ',', 'etc.', ',', 'general', 'spoken', 'English', '.'], 'h': {'name': 'general spoken English', 'pos': [25, 28]}, 't': {'name': 'questions', 'pos': [21, 22]}, 'relation': 'model-feature'}
{'token': ['system', 'operates', 'according', 'plan', '-', 'based', 'agenda', 'mechanism', ',', 'rather', 'finite', 'state', 'network', ',', 'attempts', 'negotiate', 'user', 'constraints', 'met', '.'], 'h': {'name': 'plan-based agenda mechanism', 'pos': [3, 8]}, 't': {'name': 'system', 'pos': [0, 1]}, 'relation': 'usage'}
{'token': ['mentioned', 'Mitkov', '(', '1996', ')', ',', 'solving', 'anaphora', 'extracting', 'antecedent', 'key', 'issues', 'correct', 'translation', '.'], 'h': {'name': 'anaphora', 'pos': [7, 8]}, 't': {'name': 'translation', 'pos': [13, 14]}, 'relation': 'part_whole'}
{'token': ['SS', 'stores', 'lexical', ',', 'syntactic', ',', 'morphologic', 'semantic', 'information', 'every', 'constituent', 'grammar', '.'], 'h': {'name': 'lexical, syntactic, morphologic and semantic information', 'pos': [2, 9]}, 't': {'name': 'constituent', 'pos': [10, 11]}, 'relation': 'model-feature'}
{'token': ['mechanism', 'could', 'added', 'MT', 'system', 'additional', 'module', 'solve', 'anaphora', 'generation', 'problem', '.'], 'h': {'name': 'mechanism', 'pos': [0, 1]}, 't': {'name': 'MT system', 'pos': [3, 5]}, 'relation': 'usage'}
{'token': ['paper', 'addresses', 'language', 'engineering', 'infrastructure', 'issues', 'considering', 'whether', 'standard', 'V&amp', ';', 'V', 'methods', 'fundamentally', 'different', 'evaluation', 'practices', 'commonly', 'used', 'NLP', 'systems', ',', 'proposes', 'practical', 'approaches', 'applying', 'V&amp', ';', 'V', 'context', 'language', 'processing', 'systems', '.'], 'h': {'name': 'standard V&amp;V methods', 'pos': [8, 13]}, 't': {'name': 'evaluation practices', 'pos': [15, 17]}, 'relation': 'compare'}
{'token': ['paper', 'addresses', 'language', 'engineering', 'infrastructure', 'issues', 'considering', 'whether', 'standard', 'V&amp', ';', 'V', 'methods', 'fundamentally', 'different', 'evaluation', 'practices', 'commonly', 'used', 'NLP', 'systems', ',', 'proposes', 'practical', 'approaches', 'applying', 'V&amp', ';', 'V', 'context', 'language', 'processing', 'systems', '.'], 'h': {'name': 'V&amp;V', 'pos': [26, 29]}, 't': {'name': 'language processing systems', 'pos': [30, 33]}, 'relation': 'usage'}
{'token': ['paper', ',', 'propose', 'practical', 'approach', 'extracting', 'relevant', 'paragraphs', 'original', 'document', 'form', 'summary', 'Thai', 'text', '.'], 'h': {'name': 'paragraphs', 'pos': [7, 8]}, 't': {'name': 'document', 'pos': [9, 10]}, 'relation': 'part_whole'}
{'token': ['paper', ',', 'propose', 'practical', 'approach', 'extracting', 'relevant', 'paragraphs', 'original', 'document', 'form', 'summary', 'Thai', 'text', '.'], 'h': {'name': 'summary', 'pos': [11, 12]}, 't': {'name': 'Thai text', 'pos': [12, 14]}, 'relation': 'model-feature'}
{'token': ['idea', 'approach', 'exploit', 'local', 'global', 'properties', 'paragraphs', '.'], 'h': {'name': 'local and global properties', 'pos': [3, 6]}, 't': {'name': 'paragraphs', 'pos': [6, 7]}, 'relation': 'model-feature'}
{'token': ['local', 'property', 'considered', 'clusters', 'significant', 'words', 'within', 'paragraph', ',', 'global', 'property', 'thought', 'relations', 'paragraphs', 'document', '.'], 'h': {'name': 'clusters', 'pos': [3, 4]}, 't': {'name': 'significant words', 'pos': [4, 6]}, 'relation': 'model-feature'}
{'token': ['Syntax', '-', 'based', 'Machine', 'Translation', 'systems', 'recently', 'become', 'focus', 'research', 'much', 'hope', 'outperform', 'traditional', 'Phrase', '-', 'Based', 'Statistical', 'Machine', 'Translation', '(', 'PBSMT', ')'], 'h': {'name': 'Syntax-based Machine Translation systems', 'pos': [0, 6]}, 't': {'name': 'traditional Phrase- Based Statistical Machine Translation (PBSMT)', 'pos': [13, 23]}, 'relation': 'compare'}
{'token': ['Toward', 'goal', ',', 'present', 'method', 'analyzing', 'morphosyntactic', 'content', 'language', 'Elicitation', 'Corpus', 'one', 'included', 'LDC', "'s", 'upcoming', 'LCTL', 'language', 'packs', '.'], 'h': {'name': 'morphosyntactic content', 'pos': [6, 8]}, 't': {'name': 'Elicitation Corpus', 'pos': [9, 11]}, 'relation': 'part_whole'}
{'token': ['providing', 'tool', 'augment', 'structure', '-', 'based', 'MT', 'models', 'rich', 'features', ',', 'believe', 'discriminative', 'power', 'current', 'models', 'improved', '.'], 'h': {'name': 'rich features', 'pos': [8, 10]}, 't': {'name': 'structure-based MT models', 'pos': [3, 8]}, 'relation': 'usage'}
{'token': ['article', 'outlines', 'quantitative', 'method', 'segmenting', 'texts', 'thematically', 'coherent', 'units', '.'], 'h': {'name': 'quantitative method', 'pos': [2, 4]}, 't': {'name': 'texts', 'pos': [5, 6]}, 'relation': 'usage'}
{'token': ['method', 'relies', 'network', 'lexical', 'collocations', 'compute', 'thematic', 'coherence', 'different', 'parts', 'text', 'lexical', 'cohesiveness', 'words', '.'], 'h': {'name': 'network of lexical collocations', 'pos': [2, 5]}, 't': {'name': 'method', 'pos': [0, 1]}, 'relation': 'usage'}
{'token': ['method', 'relies', 'network', 'lexical', 'collocations', 'compute', 'thematic', 'coherence', 'different', 'parts', 'text', 'lexical', 'cohesiveness', 'words', '.'], 'h': {'name': 'lexical cohesiveness', 'pos': [11, 13]}, 't': {'name': 'words', 'pos': [13, 14]}, 'relation': 'model-feature'}
{'token': ['also', 'present', 'results', 'experiment', 'locating', 'boundaries', 'series', 'concatened', 'texts', '.'], 'h': {'name': 'boundaries', 'pos': [5, 6]}, 't': {'name': 'texts', 'pos': [8, 9]}, 'relation': 'part_whole'}
{'token': ['work', ',', 'introduce', 'model', 'sense', 'assignment', 'relies', 'assigning', 'senses', 'contexts', 'within', 'words', 'appear', ',', 'rather', 'words', '.'], 'h': {'name': 'model', 'pos': [3, 4]}, 't': {'name': 'sense assignment', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['work', ',', 'introduce', 'model', 'sense', 'assignment', 'relies', 'assigning', 'senses', 'contexts', 'within', 'words', 'appear', ',', 'rather', 'words', '.'], 'h': {'name': 'words', 'pos': [11, 12]}, 't': {'name': 'contexts', 'pos': [9, 10]}, 'relation': 'model-feature'}
{'token': ['paper', 'describe', 'morphological', 'analysis', 'method', 'based', 'maximum', 'entropy', 'model', '.'], 'h': {'name': 'maximum entropy model', 'pos': [6, 9]}, 't': {'name': 'morphological analysis method', 'pos': [2, 5]}, 'relation': 'usage'}
{'token': ['method', 'uses', 'model', 'consult', 'dictionary', 'large', 'amount', 'lexical', 'information', 'also', 'identify', 'unknown', 'words', 'learning', 'certain', 'characteristics', '.'], 'h': {'name': 'model', 'pos': [2, 3]}, 't': {'name': 'method', 'pos': [0, 1]}, 'relation': 'usage'}
{'token': ['method', 'uses', 'model', 'consult', 'dictionary', 'large', 'amount', 'lexical', 'information', 'also', 'identify', 'unknown', 'words', 'learning', 'certain', 'characteristics', '.'], 'h': {'name': 'lexical information', 'pos': [7, 9]}, 't': {'name': 'dictionary', 'pos': [4, 5]}, 'relation': 'part_whole'}
{'token': ['method', 'uses', 'model', 'consult', 'dictionary', 'large', 'amount', 'lexical', 'information', 'also', 'identify', 'unknown', 'words', 'learning', 'certain', 'characteristics', '.'], 'h': {'name': 'characteristics', 'pos': [15, 16]}, 't': {'name': 'unknown words', 'pos': [11, 13]}, 'relation': 'model-feature'}
{'token': ['Finally', ',', 'present', 'Corporator', ',', 'Open', 'Source', 'software', 'designed', 'collecting', 'corpus', 'RSS', 'feeds', '.'], 'h': {'name': 'corpus', 'pos': [10, 11]}, 't': {'name': 'RSS feeds', 'pos': [11, 13]}, 'relation': 'part_whole'}
{'token': ['Several', 'SVMs', 'trained', 'using', 'information', 'pyramids', 'summary', 'content', 'units', '.'], 'h': {'name': 'summary content units', 'pos': [6, 9]}, 't': {'name': 'SVMs', 'pos': [1, 2]}, 'relation': 'usage'}
{'token': ['performance', 'compared', 'best', 'performing', 'systems', 'DUC-2005', ',', 'using', 'both', 'and', 'Pan', ',', 'an', 'scoring', 'method', 'for', 'evaluation', '.'], 'h': {'name': 'performance', 'pos': [0, 1]}, 't': {'name': 'DUC-2005', 'pos': [5, 6]}, 'relation': 'compare'}
{'token': ['performance', 'compared', 'best', 'performing', 'systems', 'DUC-2005', ',', 'using', 'both', 'ROUGE', 'auto', ',', 'an', 'scoring', 'method', 'for', 'evaluation', '.'], 'h': {'name': 'automatic scoring method', 'pos': [13, 15]}, 't': {'name': 'pyramid evaluation', 'pos': [16, 17]}, 'relation': 'usage'}
{'token': ['present', 'novel', 'unsupervised', 'method', 'sentence', 'compression', 'relies', 'dependency', 'tree', 'representation', 'shortens', 'sentences', 'removing', 'subtrees', '.'], 'h': {'name': 'unsupervised method', 'pos': [2, 4]}, 't': {'name': 'sentence compression', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['demonstrate', 'choice', 'parser', 'affects', 'performance', 'system', '.'], 'h': {'name': 'parser', 'pos': [2, 3]}, 't': {'name': 'performance', 'pos': [4, 5]}, 'relation': 'result'}
{'token': ['also', 'apply', 'method', 'German', 'report', 'results', 'evaluation', 'humans', '.'], 'h': {'name': 'method', 'pos': [2, 3]}, 't': {'name': 'German', 'pos': [3, 4]}, 'relation': 'usage'}
{'token': ['approach', 'even', 'outperformed', 'hand', 'coded', 'system', 'NER', 'Spanish', ',', 'achieved', 'high', 'accuracies', 'Portuguese', '.'], 'h': {'name': 'NER', 'pos': [6, 7]}, 't': {'name': 'Spanish', 'pos': [7, 8]}, 'relation': 'usage'}
{'token': ['karaka', 'based', 'approach', 'parsing', 'Indian', 'languages', 'described', '.'], 'h': {'name': 'parsing', 'pos': [3, 4]}, 't': {'name': 'Indian languages', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['used', 'building', 'parser', 'Hindi', 'prototype', 'Machine', 'Translation', 'system', '.'], 'h': {'name': 'parser', 'pos': [2, 3]}, 't': {'name': 'Hindi', 'pos': [3, 4]}, 'relation': 'usage'}
{'token': ['paper', 'presents', 'work', 'detection', 'temporal', 'information', 'web', 'pages', '.'], 'h': {'name': 'detection', 'pos': [3, 4]}, 't': {'name': 'web pages', 'pos': [6, 8]}, 'relation': 'usage'}
{'token': ['pages', 'examined', 'within', 'scope', 'study', 'taken', 'tourism', 'sector', 'temporal', 'information', 'question', 'thus', 'particular', 'area', '.'], 'h': {'name': 'temporal information', 'pos': [8, 10]}, 't': {'name': 'pages', 'pos': [0, 1]}, 'relation': 'part_whole'}
{'token': ['differences', 'exist', 'extraction', 'plain', 'textual', 'data', 'extraction', 'web', 'brought', 'light', '.'], 'h': {'name': 'extraction', 'pos': [2, 3]}, 't': {'name': 'plain textual data', 'pos': [3, 6]}, 'relation': 'usage'}
{'token': ['adopt', 'symbolic', 'approach', 'relying', 'patterns', 'rules', 'detection', ',', 'extraction', 'annotation', 'temporal', 'expressions', ';', 'method', 'based', 'use', 'transducers', '.'], 'h': {'name': 'patterns', 'pos': [4, 5]}, 't': {'name': 'symbolic approach', 'pos': [1, 3]}, 'relation': 'usage'}
{'token': ['adopt', 'symbolic', 'approach', 'relying', 'patterns', 'rules', 'detection', ',', 'extraction', 'annotation', 'temporal', 'expressions', ';', 'method', 'based', 'use', 'transducers', '.'], 'h': {'name': 'rules', 'pos': [5, 6]}, 't': {'name': 'detection', 'pos': [6, 7]}, 'relation': 'usage'}
{'token': ['adopt', 'symbolic', 'approach', 'relying', 'patterns', 'rules', 'detection', ',', 'extraction', 'annotation', 'temporal', 'expressions', ';', 'method', 'based', 'use', 'transducers', '.'], 'h': {'name': 'annotation', 'pos': [9, 10]}, 't': {'name': 'temporal expressions', 'pos': [10, 12]}, 'relation': 'usage'}
{'token': ['first', 'release', 'German', 'Ph@ttSessionz', 'speech', 'database', 'contains', 'read', 'spontaneous', 'speech', '864', 'adolescent', 'speakers', 'largest', 'database', 'kind', 'German', '.'], 'h': {'name': 'read and spontaneous speech', 'pos': [7, 10]}, 't': {'name': 'German Ph@ttSessionz speech database', 'pos': [2, 6]}, 'relation': 'part_whole'}
{'token': ['paper', ',', 'present', 'cross', '-sectional', 'study', 'of', 'f0', 'measurements', 'on', '.'], 'h': {'name': 'cross-sectional study', 'pos': [3, 6]}, 't': {'name': 'f0 measurements', 'pos': [7, 9]}, 'relation': 'topic'}
{'token': ['Furthermore', ',', 'shows', 'perceptive', 'mel-scale', ',', 'little', 'difference', 'relative', 'f0', 'variability', 'male', 'female', 'speakers', '.'], 'h': {'name': 'relative f0 variability', 'pos': [8, 11]}, 't': {'name': 'male and female speakers', 'pos': [11, 14]}, 'relation': 'model-feature'}
{'token': ['study', 'provides', 'statistically', 'reliable', 'voice', 'parameters', 'adolescent', 'speakers', 'German', '.'], 'h': {'name': 'voice parameters', 'pos': [4, 6]}, 't': {'name': 'adolescent speakers', 'pos': [6, 8]}, 'relation': 'model-feature'}
{'token': ['results', 'may', 'contribute', 'making', 'spoken', 'dialog', 'systems', 'robust', 'restricting', 'user', 'input', 'utterances', 'low', 'f0', 'variability', '.'], 'h': {'name': 'utterances', 'pos': [11, 12]}, 't': {'name': 'user input', 'pos': [9, 11]}, 'relation': 'part_whole'}
{'token': ['platform', 'support', 'researchers', 'engineers', 'well', '-', 'developed', 'standardized', 'resources', 'application', 'tools', 'thereby', 'avoiding', 'duplicate', 'activities', 'scratch', 'amplifying', 'overall', 'effort', 'domain', '.'], 'h': {'name': 'standardized resources', 'pos': [7, 9]}, 't': {'name': 'platform', 'pos': [0, 1]}, 'relation': 'usage'}
{'token': ['present', 'article', ',', 'part', 'aspectual', 'operation', 'system', ',', 'generation', 'system', 'iterative', 'expressions', 'using', 'set', 'operators', 'called', 'iterative', 'operators', '.'], 'h': {'name': 'generation system', 'pos': [8, 10]}, 't': {'name': 'aspectual operation system', 'pos': [4, 7]}, 'relation': 'part_whole'}
{'token': ['classification', 'carried', 'especially', 'consideration', 'durative', '/', 'non-durative', 'character', 'denoted', 'events', 'also', 'consideration', 'existence', '/', 'non-existence', 'culmination', 'point', '(', 'boundary', ')', 'events', '.'], 'h': {'name': 'durative / non-durative character', 'pos': [4, 8]}, 't': {'name': 'events', 'pos': [9, 10]}, 'relation': 'model-feature'}
{'token': ['paper', ',', 'show', 'time', '-', 'synchronous', 'one', '-', 'pass', 'decoding', 'using', 'cross', '-', 'word', 'triphones', 'trigram', 'language', 'model', 'implemented', 'using', 'dynamically', 'built', 'tree', '-', 'structured', 'network', '.'], 'h': {'name': 'cross-word triphones', 'pos': [11, 15]}, 't': {'name': 'time-synchronous one-pass decoding', 'pos': [3, 10]}, 'relation': 'usage'}
{'token': ['paper', ',', 'show', 'time', '-', 'synchronous', 'one', '-', 'pass', 'decoding', 'using', 'cross', '-', 'word', 'triphones', 'trigram', 'language', 'model', 'implemented', 'using', 'dynamically', 'built', 'tree', '-', 'structured', 'network', '.'], 'h': {'name': 'tree-structured network', 'pos': [22, 26]}, 't': {'name': 'trigram language model', 'pos': [15, 18]}, 'relation': 'usage'}
{'token': ['included', 'HTK', 'large', 'vocabulary', 'speech', 'recognition', 'system', 'used', '1993', 'ARPA', 'WSJ', 'evaluation', 'experimental', 'results', 'presented', 'task', '.'], 'h': {'name': 'HTK large vocabulary speech recognition system', 'pos': [1, 7]}, 't': {'name': '1993 ARPA WSJ evaluation', 'pos': [8, 12]}, 'relation': 'usage'}
{'token': ['Traditionally', ',', 'statistical', 'machine', 'translation', 'systems', 'relied', 'parallel', 'bi-lingual', 'data', 'train', 'translation', 'model', '.'], 'h': {'name': 'parallel bi-lingual data', 'pos': [7, 10]}, 't': {'name': 'statistical machine translation systems', 'pos': [2, 6]}, 'relation': 'usage'}
{'token': ['bi-lingual', 'parallel', 'data', 'expensive', 'generate', ',', 'monolingual', 'data', 'relatively', 'common', '.'], 'h': {'name': 'bi-lingual parallel data', 'pos': [0, 3]}, 't': {'name': 'monolingual data', 'pos': [6, 8]}, 'relation': 'compare'}
{'token': ['Yet', 'monolingual', 'data', 'under-utilized', ',', 'used', 'primarily', 'training', 'language', 'model', 'target', 'language', '.'], 'h': {'name': 'monolingual data', 'pos': [1, 3]}, 't': {'name': 'language model', 'pos': [8, 10]}, 'relation': 'usage'}
{'token': ['paper', 'describes', 'novel', 'method', 'utilizing', 'monolingual', 'target', 'data', 'improve', 'performance', 'statistical', 'machine', 'translation', 'system', 'news', 'stories', '.'], 'h': {'name': 'monolingual target data', 'pos': [5, 8]}, 't': {'name': 'statistical machine translation system', 'pos': [10, 14]}, 'relation': 'usage'}
{'token': ['every', 'source', 'document', 'translated', ',', 'large', 'monolingual', 'data', 'set', 'target', 'language', 'searched', 'documents', 'might', 'comparable', 'source', 'documents', '.'], 'h': {'name': 'documents', 'pos': [12, 13]}, 't': {'name': 'source documents', 'pos': [15, 17]}, 'relation': 'compare'}
{'token': ['documents', 'used', 'adapt', 'MT', 'system', 'increase', 'probability', 'generating', 'texts', 'resemble', 'comparable', 'document', '.'], 'h': {'name': 'documents', 'pos': [0, 1]}, 't': {'name': 'MT system', 'pos': [3, 5]}, 'relation': 'usage'}
{'token': ['Experimental', 'results', 'obtained', 'adapting', 'language', 'translation', 'models', 'show', 'substantial', 'gains', 'baseline', 'system', '.'], 'h': {'name': 'language and translation models', 'pos': [4, 7]}, 't': {'name': 'baseline system', 'pos': [10, 12]}, 'relation': 'compare'}
{'token': ['paper', 'describes', 'unsupervised', 'knowledge', '-', 'lean', 'methodology', 'automatically', 'determining', 'number', 'senses', 'ambiguous', 'word', 'used', 'large', 'corpus', '.'], 'h': {'name': 'ambiguous word', 'pos': [11, 13]}, 't': {'name': 'corpus', 'pos': [15, 16]}, 'relation': 'part_whole'}
{'token': ['paper', 'describes', 'Unisys', 'MUC', '-', '3', 'text', 'understanding', 'system', ',', 'system', 'based', 'upon', 'three', '-', 'tiered', 'approach', 'text', 'processing', 'powerful', 'knowledge', '-', 'based', 'form', 'information', 'retrieval', 'plays', 'central', 'role', '.'], 'h': {'name': 'three-tiered approach', 'pos': [13, 17]}, 't': {'name': 'system', 'pos': [10, 11]}, 'relation': 'usage'}
{'token': ['decision', 'made', 'focus', 'development', 'knowledge', '-', 'based', 'information', 'retrieval', 'component', ',', 'precluded', 'integration', 'Pundit', 'prototype', '.'], 'h': {'name': 'Pundit', 'pos': [13, 14]}, 't': {'name': 'prototype', 'pos': [14, 15]}, 'relation': 'part_whole'}
{'token': ['ARBITER', 'Prolog', 'program', 'extracts', 'assertions', 'macromolecular', 'binding', 'relationships', 'biomedical', 'text', '.'], 'h': {'name': 'macromolecular binding relationships', 'pos': [5, 8]}, 't': {'name': 'biomedical text', 'pos': [8, 10]}, 'relation': 'part_whole'}
{'token': ['discussing', 'formal', 'evaluation', 'ARBITER', ',', 'report', 'application', '491,000', 'MEDLINE', 'abstracts', ',', 'almost', '25,000', 'binding', 'relationships', 'suitable', 'entry', 'database', 'macro-molecular', 'function', 'extracted', '.'], 'h': {'name': 'ARBITER', 'pos': [3, 4]}, 't': {'name': 'MEDLINE abstracts', 'pos': [8, 10]}, 'relation': 'usage'}
{'token': ['discussing', 'formal', 'evaluation', 'ARBITER', ',', 'report', 'application', '491,000', 'MEDLINE', 'abstracts', ',', 'almost', '25,000', 'binding', 'relationships', 'suitable', 'entry', 'database', 'macro-molecular', 'function', 'extracted', '.'], 'h': {'name': 'macro-molecular function', 'pos': [18, 20]}, 't': {'name': 'database', 'pos': [17, 18]}, 'relation': 'part_whole'}
{'token': ['resolution', 'lexical', 'ambiguity', 'important', 'natural', 'language', 'processing', 'tasks', ',', 'range', 'computational', 'techniques', 'proposed', 'solution', '.'], 'h': {'name': 'lexical ambiguity', 'pos': [1, 3]}, 't': {'name': 'natural language processing tasks', 'pos': [4, 8]}, 'relation': 'part_whole'}
{'token': ['paper', ',', 'describe', 'method', 'lexical', 'disambiguation', 'text', 'using', 'definitions', 'machine', '-', 'readable', 'dictionary', 'together', 'technique', 'simulated', 'annealing', '.'], 'h': {'name': 'definitions', 'pos': [8, 9]}, 't': {'name': 'lexical disambiguation', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['initial', 'results', 'sample', 'set', '50', 'sentences', 'comparable', 'researchers', ',', 'fully', 'automatic', 'method', 'requires', 'hand', 'coding', 'lexical', 'entries', ',', 'hand', 'tagging', 'text', '.'], 'h': {'name': 'hand coding', 'pos': [13, 15]}, 't': {'name': 'lexical entries', 'pos': [15, 17]}, 'relation': 'usage'}
{'token': ['initial', 'results', 'sample', 'set', '50', 'sentences', 'comparable', 'researchers', ',', 'fully', 'automatic', 'method', 'requires', 'hand', 'coding', 'lexical', 'entries', ',', 'hand', 'tagging', 'text', '.'], 'h': {'name': 'hand tagging', 'pos': [18, 20]}, 't': {'name': 'text', 'pos': [20, 21]}, 'relation': 'usage'}
{'token': ['date', ',', 'array', 'formal', 'natural', 'language', 'processing', 'technologies', 'used', 'perform', 'mass', 'changes', 'legacy', 'textual', 'databases', 'facilitate', 'user', 'interfacing', 'relational', 'databases', 'software', 'applications', '.'], 'h': {'name': 'formal and natural language processing technologies', 'pos': [3, 8]}, 't': {'name': 'legacy textual databases', 'pos': [12, 15]}, 'relation': 'usage'}
{'token': ['present', 'discourse', 'annotation', 'work', 'aimed', 'constructing', 'parallel', 'corpus', 'Rhetorical', 'Structure', 'trees', 'collection', 'Japanese', 'texts', 'corresponding', 'English', 'translations', '.'], 'h': {'name': 'Rhetorical Structure trees', 'pos': [8, 11]}, 't': {'name': 'parallel corpus', 'pos': [6, 8]}, 'relation': 'part_whole'}
{'token': ['approach', 'knowledge', 'representation', 'taken', 'multi-modal', 'multi-domain', 'dialogue', 'system', '-', 'SmartKom', '-', 'presented', '.'], 'h': {'name': 'knowledge representation', 'pos': [1, 3]}, 't': {'name': 'multi-modal multi-domain dialogue system - SmartKom -', 'pos': [4, 11]}, 'relation': 'usage'}
{'token': ['paper', 'presents', 'intial', 'work', 'system', 'bridges', 'robust', ',', 'broad', '-', 'coverage', 'natural', 'language', 'processing', 'precise', 'semantics', 'automated', 'reasoning', ',', 'focusing', 'solving', 'logic', 'puzzles', 'drawn', 'sources', 'Law', 'School', 'Admission', 'Test', '(', 'LSAT', ')', 'analytic', 'section', 'Graduate', 'Record', 'Exam', '(', 'GRE', ')', '.'], 'h': {'name': 'logic puzzles', 'pos': [21, 23]}, 't': {'name': 'Law School Admission Test (LSAT)', 'pos': [25, 32]}, 'relation': 'part_whole'}
{'token': ['highlight', 'key', 'challenges', ',', 'discuss', 'representations', 'performance', 'prototype', 'system', '.'], 'h': {'name': 'performance', 'pos': [6, 7]}, 't': {'name': 'prototype system', 'pos': [7, 9]}, 'relation': 'model-feature'}
{'token': ['paper', ',', 'new', 'parsing', 'model', 'proposed', 'formulate', 'complete', 'chunking', 'problem', 'series', 'boundary', 'detection', 'subtasks', '.'], 'h': {'name': 'chunking problem', 'pos': [8, 10]}, 't': {'name': 'parsing model', 'pos': [3, 5]}, 'relation': 'model-feature'}
{'token': ['applying', 'SVM', 'algorithm', 'subtasks', ',', 'achieved', 'best', 'F-', 'Score', 'of', '%', 'and', '%', 'respectively', '.'], 'h': {'name': 'SVM algorithm', 'pos': [1, 3]}, 't': {'name': 'F-Score', 'pos': [7, 9]}, 'relation': 'result'}
{'token': ['paper', ',', 'introduce', 'WordNet', '-', 'based', 'measure', 'semantic', 'relatedness', 'combining', 'structure', 'content', 'WordNet', 'co-occurrence', 'information', 'derived', 'raw', 'text', '.'], 'h': {'name': 'co-occurrence information', 'pos': [13, 15]}, 't': {'name': 'raw text', 'pos': [16, 18]}, 'relation': 'part_whole'}
{'token': ['use', 'co-occurrence', 'information', 'along', 'Word', 'Net', 'definitions', 'build', 'gloss', 'vectors', 'corresponding', 'concept', 'Word', 'Net', '.'], 'h': {'name': 'gloss vectors', 'pos': [8, 10]}, 't': {'name': 'concept', 'pos': [11, 12]}, 'relation': 'model-feature'}
{'token': ['Numeric', 'scores', 'relatedness', 'assigned', 'pair', 'concepts', 'measuring', 'cosine', 'angle', 'respective', 'gloss', 'vectors', '.'], 'h': {'name': 'Numeric scores of relatedness', 'pos': [0, 3]}, 't': {'name': 'concepts', 'pos': [5, 6]}, 'relation': 'model-feature'}
{'token': ['show', 'measure', 'compares', 'favorably', 'measures', 'respect', 'human', 'judgments', 'semantic', 'relatedness', ',', 'performs', 'well', 'used', 'word', 'sense', 'disambiguation', 'algorithm', 'relies', 'semantic', 'relatedness', '.'], 'h': {'name': 'semantic relatedness', 'pos': [19, 21]}, 't': {'name': 'word sense disambiguation algorithm', 'pos': [14, 18]}, 'relation': 'usage'}
{'token': ['addition', ',', 'adapted', 'different', 'domains', ',', 'since', 'plain', 'text', 'corpus', 'used', 'derive', 'co–occurrence', 'information', '.'], 'h': {'name': 'co–occurrence information', 'pos': [12, 14]}, 't': {'name': 'plain text corpus', 'pos': [7, 10]}, 'relation': 'part_whole'}
{'token': ['paper', 'describes', 'system', 'used', 'RTE3', 'task', '.'], 'h': {'name': 'system', 'pos': [2, 3]}, 't': {'name': 'RTE3 task', 'pos': [4, 6]}, 'relation': 'usage'}
{'token': ['system', 'maps', 'premise', 'hypothesis', 'pairs', 'abstract', 'knowledge', 'representation', '(', 'AKR', ')', 'performs', 'entailment', 'contradiction', 'detection', '(', 'ecd', ')', 'resulting', 'AKRs', '.'], 'h': {'name': 'abstract knowledge representation (AKR)', 'pos': [5, 11]}, 't': {'name': 'premise and hypothesis pairs', 'pos': [2, 5]}, 'relation': 'model-feature'}
{'token': ['Two', 'versions', 'ECD', 'used', 'RTE3', ',', 'one', 'strict', 'ECD', 'one', 'looser', 'ECD', '.'], 'h': {'name': 'ECD', 'pos': [2, 3]}, 't': {'name': 'RTE3', 'pos': [4, 5]}, 'relation': 'usage'}
{'token': ['propose', 'new', 'language', 'learning', 'model', 'learns', 'syntactic-semantic', 'grammar', 'small', 'number', 'natural', 'language', 'strings', 'annotated', 'semantics', ',', 'along', 'basic', 'assumptions', 'natural', 'language', 'syntax', '.'], 'h': {'name': 'natural language strings', 'pos': [10, 13]}, 't': {'name': 'semantics', 'pos': [14, 15]}, 'relation': 'model-feature'}
{'token': ['paper', ',', 'propose', 'novel', 'graph', 'based', 'sentence', 'ranking', 'algorithm', ',', 'namely', 'PNR2', ',', 'update', 'summarization', '.'], 'h': {'name': 'graph based sentence ranking algorithm', 'pos': [4, 9]}, 't': {'name': 'update summarization', 'pos': [13, 15]}, 'relation': 'usage'}
{'token': ['paper', 'discusses', 'application', 'Expectation', '-', 'Maximization', '(', 'EM', ')', 'clustering', 'algorithm', 'task', 'Chinese', 'verb', 'sense', 'discrimination', '.'], 'h': {'name': 'Expectation-Maximization (EM) clustering algorithm', 'pos': [3, 11]}, 't': {'name': 'Chinese verb sense discrimination', 'pos': [12, 16]}, 'relation': 'usage'}
{'token': ['model', 'utilized', 'rich', 'linguistic', 'features', 'capture', 'predicate', '-', 'argument', 'structure', 'information', 'target', 'verbs', '.'], 'h': {'name': 'rich linguistic features', 'pos': [2, 5]}, 't': {'name': 'model', 'pos': [0, 1]}, 'relation': 'usage'}
{'token': ['model', 'utilized', 'rich', 'linguistic', 'features', 'capture', 'predicate', '-', 'argument', 'structure', 'information', 'target', 'verbs', '.'], 'h': {'name': 'predicate-argument structure information', 'pos': [6, 11]}, 't': {'name': 'target verbs', 'pos': [11, 13]}, 'relation': 'model-feature'}
{'token': ['semantic', 'taxonomy', 'Chinese', 'nouns', ',', 'built', 'semi-automatically', 'based', 'two', 'electronic', 'Chinese', 'semantic', 'dictionaries', ',', 'used', 'provide', 'semantic', 'features', 'model', '.'], 'h': {'name': 'semantic taxonomy', 'pos': [0, 2]}, 't': {'name': 'Chinese nouns', 'pos': [2, 4]}, 'relation': 'model-feature'}
{'token': ['semantic', 'taxonomy', 'Chinese', 'nouns', ',', 'built', 'semi-automatically', 'based', 'two', 'electronic', 'Chinese', 'semantic', 'dictionaries', ',', 'used', 'provide', 'semantic', 'features', 'model', '.'], 'h': {'name': 'semantic features', 'pos': [16, 18]}, 't': {'name': 'model', 'pos': [18, 19]}, 'relation': 'usage'}
{'token': ['enhanced', 'model', 'certain', 'fine', '-', 'grained', 'semantic', 'categories', 'called', 'lexical', 'sets', '.'], 'h': {'name': 'fine-grained semantic categories', 'pos': [3, 8]}, 't': {'name': 'model', 'pos': [1, 2]}, 'relation': 'usage'}
{'token': ['results', 'indicate', 'lexical', 'sets', 'improve', 'model', "'s", 'performance', 'three', 'challenging', 'verbs', 'chosen', 'first', 'set', 'experiments', '.'], 'h': {'name': 'lexical sets', 'pos': [2, 4]}, 't': {'name': 'model', 'pos': [5, 6]}, 'relation': 'result'}
{'token': ['paper', 'proposes', 'efficient', 'linguistic', 'processing', 'strategy', 'speech', 'recognition', 'understanding', 'using', 'dependency', 'structure', 'grammar', '.'], 'h': {'name': 'dependency structure grammar', 'pos': [10, 13]}, 't': {'name': 'speech recognition and understanding', 'pos': [6, 9]}, 'relation': 'usage'}
{'token': ['speech', 'processing', 'phrase', 'recognition', 'based', 'phoneme', 'recognition', ',', 'parser', 'extracts', 'sentence', 'best', 'likelihood', 'taking', 'account', 'phonetic', 'likelihood', 'phrase', 'candidates', 'linguistic', 'likelihood', 'semantic', 'inter-phrase', 'dependency', 'relationships', '.'], 'h': {'name': 'phoneme recognition', 'pos': [5, 7]}, 't': {'name': 'phrase recognition', 'pos': [2, 4]}, 'relation': 'usage'}
{'token': ['fast', 'parsing', 'algorithm', 'using', 'breadth-', 'first', 'search', 'is', 'proposed', '.'], 'h': {'name': 'breadth-first search', 'pos': [4, 7]}, 't': {'name': 'parsing algorithm', 'pos': [1, 3]}, 'relation': 'usage'}
{'token': ['predictor', 'pre-selects', 'phrase', 'candidates', 'using', 'transition', 'rules', 'combined', 'dependency', 'structure', 'reduce', 'amount', 'phonetic', 'processing', '.'], 'h': {'name': 'transition rules', 'pos': [5, 7]}, 't': {'name': 'predictor', 'pos': [0, 1]}, 'relation': 'usage'}
{'token': ['experimental', 'results', 'show', 'greatly', 'increases', 'accuracy', 'speech', 'recognitions', ',', 'breadth-', 'first', 'parsing', 'algorithm', 'and', 'predictor', 'increase', 'processing', 'speed', '.'], 'h': {'name': 'predictor', 'pos': [14, 15]}, 't': {'name': 'processing speed', 'pos': [16, 18]}, 'relation': 'result'}
{'token': ['EU', '-', 'funded', 'project', ',', 'QALL', '-', ',', 'domain-specific', 'ontology', 'was', 'developed', 'applied', 'answering', 'in', 'the', 'tourism', 'along', 'with', 'the', 'two', 'ontologies', 'for', 'concept', 'and', 'reasoning'], 'h': {'name': 'domain-specific ontology', 'pos': [8, 10]}, 't': {'name': 'question answering', 'pos': [13, 14]}, 'relation': 'usage'}
{'token': ['design', 'ontology', 'presented', 'paper', ',', 'semi-automatic', 'alignment', 'procedure', 'described', 'alignment', 'results', 'given', 'well', '.'], 'h': {'name': 'semi-automatic alignment procedure', 'pos': [5, 8]}, 't': {'name': 'alignment results', 'pos': [9, 11]}, 'relation': 'result'}
{'token': ['Furthermore', ',', 'aligned', 'ontology', 'used', 'semantically', 'annotate', 'original', 'data', 'obtained', 'tourism', 'web', 'sites', 'natural', 'language', 'questions', '.'], 'h': {'name': 'natural language questions', 'pos': [13, 16]}, 't': {'name': 'data', 'pos': [8, 9]}, 'relation': 'part_whole'}
{'token': ['storage', 'schema', 'annotated', 'data', 'data', 'access', 'method', 'retrieving', 'answers', 'annotated', 'data', 'also', 'reported', 'paper', '.'], 'h': {'name': 'data access method', 'pos': [4, 7]}, 't': {'name': 'annotated data', 'pos': [9, 11]}, 'relation': 'usage'}
{'token': ['particular', 'discuss', 'natural', 'language', 'generation', 'system', 'composed', 'SPoT', ',', 'trainable', 'sentence', 'planner', ',', 'FERGUS', ',', 'stochastic', 'surface', 'realizer', '.'], 'h': {'name': 'SPoT', 'pos': [7, 8]}, 't': {'name': 'natural language generation system', 'pos': [2, 6]}, 'relation': 'part_whole'}
{'token': ['show', 'stochastic', 'NLG', 'components', 'made', 'work', 'together', ',', 'ported', 'new', 'domains', 'apparent', 'ease', ',', 'NLG', 'components', 'integrated', 'real', '-', 'time', 'dialog', 'system', '.'], 'h': {'name': 'NLG components', 'pos': [14, 16]}, 't': {'name': 'real-time dialog system', 'pos': [17, 22]}, 'relation': 'part_whole'}
{'token': ['current', 'work', ',', 'produce', 'manual', 'segmentation', 'laughter', 'large', 'corpus', 'interactive', 'multi-party', 'seminars', ',', 'promises', 'valuable', 'resource', 'acoustic', 'modeling', 'purposes', '.'], 'h': {'name': 'interactive multi-party seminars', 'pos': [9, 12]}, 't': {'name': 'corpus', 'pos': [8, 9]}, 'relation': 'part_whole'}
{'token': ['paper', 'presents', 'extended', 'GLR', 'parsing', 'algorithm', 'grammar', 'PCFG', '*', 'based', 'Tomita', "'s", 'GLR', 'parsing', 'algorithm', 'extends', '.'], 'h': {'name': 'grammar PCFG*', 'pos': [6, 9]}, 't': {'name': 'extended GLR parsing algorithm', 'pos': [2, 6]}, 'relation': 'usage'}
{'token': ['also', 'define', 'new', 'grammar', 'PCFG', '*', 'based', 'PCFG', 'assigns', 'probability', 'also', 'frequency', 'associated', 'rule', '.'], 'h': {'name': 'PCFG', 'pos': [7, 8]}, 't': {'name': 'grammar PCFG*', 'pos': [3, 6]}, 'relation': 'usage'}
{'token': ['also', 'define', 'new', 'grammar', 'PCFG', '*', 'based', 'PCFG', 'assigns', 'probability', 'also', 'frequency', 'associated', 'rule', '.'], 'h': {'name': 'frequency', 'pos': [11, 12]}, 't': {'name': 'rule', 'pos': [13, 14]}, 'relation': 'model-feature'}
{'token': ['syntactic', 'parsing', 'system', 'implemented', 'based', 'rule', '-', 'based', 'approach', 'statistics', 'approach', '.'], 'h': {'name': 'rule-based approach', 'pos': [5, 9]}, 't': {'name': 'syntactic parsing system', 'pos': [0, 3]}, 'relation': 'usage'}
{'token': ['paper', ',', 'discuss', 'lemma', 'identification', 'Japanese', 'morphological', 'analysis', ',', 'crucial', 'proper', 'formulation', 'morphological', 'analysis', 'benefits', 'NLP', 'researchers', 'also', 'corpus', 'linguists', '.'], 'h': {'name': 'lemma identification', 'pos': [3, 5]}, 't': {'name': 'Japanese morphological analysis', 'pos': [5, 8]}, 'relation': 'usage'}
{'token': ['Since', 'Japanese', 'words', 'often', 'variation', 'orthography', 'vocabulary', 'Japanese', 'consists', 'words', 'several', 'different', 'origins', ',', 'sometimes', 'happens', 'one', 'writing', 'form', 'corresponds', 'lemma', 'single', 'writing', 'form', 'corresponds', 'two', 'lemmas', 'different', 'readings', '/', 'meanings', '.'], 'h': {'name': 'words', 'pos': [9, 10]}, 't': {'name': 'vocabulary', 'pos': [6, 7]}, 'relation': 'part_whole'}
{'token': ['Since', 'Japanese', 'words', 'often', 'variation', 'orthography', 'vocabulary', 'Japanese', 'consists', 'words', 'several', 'different', 'origins', ',', 'sometimes', 'happens', 'one', 'writing', 'form', 'corresponds', 'lemma', 'single', 'writing', 'form', 'corresponds', 'two', 'lemmas', 'different', 'readings', '/', 'meanings', '.'], 'h': {'name': 'writing form', 'pos': [17, 19]}, 't': {'name': 'lemma', 'pos': [20, 21]}, 'relation': 'model-feature'}
{'token': ['Since', 'Japanese', 'words', 'often', 'variation', 'orthography', 'vocabulary', 'Japanese', 'consists', 'words', 'several', 'different', 'origins', ',', 'sometimes', 'happens', 'one', 'writing', 'form', 'corresponds', 'lemma', 'single', 'writing', 'form', 'corresponds', 'two', 'lemmas', 'different', 'readings', '/', 'meanings', '.'], 'h': {'name': 'writing form', 'pos': [22, 24]}, 't': {'name': 'lemmas', 'pos': [26, 27]}, 'relation': 'model-feature'}
{'token': ['mapping', 'writing', 'form', 'onto', 'lemma', 'important', 'linguistic', 'analysis', 'corpora', '.'], 'h': {'name': 'linguistic analysis', 'pos': [6, 8]}, 't': {'name': 'corpora', 'pos': [8, 9]}, 'relation': 'topic'}
{'token': ['current', 'study', 'focuses', 'disambiguation', 'heteronyms', ',', 'words', 'writing', 'form', 'different', 'word', 'forms', '.'], 'h': {'name': 'disambiguation', 'pos': [3, 4]}, 't': {'name': 'heteronyms', 'pos': [4, 5]}, 'relation': 'usage'}
{'token': ['resolve', 'heteronym', 'ambiguity', ',', 'make', 'use', 'goshu', 'information', ',', 'classification', 'words', 'based', 'origin', '.'], 'h': {'name': 'origin', 'pos': [12, 13]}, 't': {'name': 'words', 'pos': [10, 11]}, 'relation': 'model-feature'}
{'token': ['Founded', 'fact', 'words', 'goshu', 'classes', 'likely', 'combine', 'compound', 'words', 'words', 'classes', ',', 'employ', 'statistical', 'model', 'based', 'CRFs', 'using', 'goshu', 'information', '.'], 'h': {'name': 'words', 'pos': [2, 3]}, 't': {'name': 'goshu classes', 'pos': [3, 5]}, 'relation': 'part_whole'}
{'token': ['Founded', 'fact', 'words', 'goshu', 'classes', 'likely', 'combine', 'compound', 'words', 'words', 'classes', ',', 'employ', 'statistical', 'model', 'based', 'CRFs', 'using', 'goshu', 'information', '.'], 'h': {'name': 'words', 'pos': [9, 10]}, 't': {'name': 'classes', 'pos': [10, 11]}, 'relation': 'part_whole'}
{'token': ['Founded', 'fact', 'words', 'goshu', 'classes', 'likely', 'combine', 'compound', 'words', 'words', 'classes', ',', 'employ', 'statistical', 'model', 'based', 'CRFs', 'using', 'goshu', 'information', '.'], 'h': {'name': 'CRFs', 'pos': [16, 17]}, 't': {'name': 'statistical model', 'pos': [13, 15]}, 'relation': 'usage'}
{'token': ['Experimental', 'results', 'show', 'use', 'goshu', 'information', 'considerably', 'improves', 'performance', 'heteronym', 'disambiguation', 'lemma', 'identification', ',', 'suggesting', 'goshu', 'information', 'solves', 'lemma', 'identification', 'task', 'effectively', '.'], 'h': {'name': 'goshu information', 'pos': [4, 6]}, 't': {'name': 'performance', 'pos': [8, 9]}, 'relation': 'result'}
{'token': ['Experimental', 'results', 'show', 'use', 'goshu', 'information', 'considerably', 'improves', 'performance', 'heteronym', 'disambiguation', 'lemma', 'identification', ',', 'suggesting', 'goshu', 'information', 'solves', 'lemma', 'identification', 'task', 'effectively', '.'], 'h': {'name': 'information', 'pos': [16, 17]}, 't': {'name': 'lemma identification task', 'pos': [18, 21]}, 'relation': 'usage'}
{'token': ['event', 'detection', 'algorithm', 'identifies', 'collocations', 'may', 'cause', 'event', 'specific', 'timestamp', '.'], 'h': {'name': 'event detection algorithm', 'pos': [0, 3]}, 't': {'name': 'collocations', 'pos': [4, 5]}, 'relation': 'usage'}
{'token': ['event', 'summarization', 'algorithm', 'retrieves', 'set', 'collocations', 'describe', 'event', '.'], 'h': {'name': 'event summarization algorithm', 'pos': [0, 3]}, 't': {'name': 'collocations', 'pos': [5, 6]}, 'relation': 'usage'}
{'token': ['describe', 'two', 'approaches', 'analyzing', 'tagging', 'team', 'discourse', 'using', 'Latent', 'Semantic', 'Analysis', '(', 'LSA', ')', 'predict', 'team', 'performance', '.'], 'h': {'name': 'Latent Semantic Analysis (LSA)', 'pos': [8, 14]}, 't': {'name': 'tagging', 'pos': [4, 5]}, 'relation': 'usage'}
{'token': ['huge', 'amount', 'translation', 'work', 'needs', 'done', 'creating', 'updating', 'technical', 'documentation', '.'], 'h': {'name': 'translation work', 'pos': [2, 4]}, 't': {'name': 'technical documentation', 'pos': [8, 10]}, 'relation': 'usage'}
{'token': ['objective', 'project', 'pilot', 'study', 'several', 'new', 'ideas', 'automatic', 'adaptation', 'improvement', 'natural', 'language', 'processing', '(', 'NLP', ')', 'systems', '.'], 'h': {'name': 'pilot study', 'pos': [2, 4]}, 't': {'name': 'automatic adaptation', 'pos': [7, 9]}, 'relation': 'topic'}
{'token': ['effort', 'focuses', 'particularly', 'automatically', 'inferring', 'meaning', 'new', 'words', 'context', 'developing', 'partial', 'interpretations', 'language', 'either', 'fragmentary', 'beyond', 'capability', 'NLP', 'system', 'understand', '.'], 'h': {'name': 'meaning', 'pos': [5, 6]}, 't': {'name': 'words', 'pos': [7, 8]}, 'relation': 'model-feature'}
{'token': ['NLP', 'system', 'uses', 'large', 'annotated', 'corpora', ',', 'developed', 'DARPA', '-', 'funded', 'TREE-BANK', 'project', 'at', 'the', 'Pennsylvania', 'to', 'adapt', 'acquiring', 'and', 'semantic', 'from', 'the', '.'], 'h': {'name': 'large annotated corpora', 'pos': [3, 6]}, 't': {'name': 'NLP system', 'pos': [0, 2]}, 'relation': 'usage'}
{'token': ['NLP', 'system', 'uses', 'large', 'annotated', 'corpora', ',', 'developed', 'DARPA', '-', 'funded', 'TREE-BANK', 'project', 'at', 'the', 'Pennsylvania', 'to', 'adapt', 'acquiring', 'syntactic', 'and', 'semantic', 'from', 'the', 'examples', '.'], 'h': {'name': 'syntactic and semantic information', 'pos': [19, 22]}, 't': {'name': 'annotated examples', 'pos': [24, 25]}, 'relation': 'part_whole'}
{'token': ['Statistical', 'language', 'modeling', ',', 'based', 'probability', 'estimates', 'derived', 'large', 'corpora', ',', 'provide', 'means', 'ranking', 'alternative', 'interpretations', 'fragments', '.'], 'h': {'name': 'probability estimates', 'pos': [5, 7]}, 't': {'name': 'Statistical language modeling', 'pos': [0, 3]}, 'relation': 'usage'}
{'token': ['Lexicalized', 'concepts', 'organized', 'semantic', 'relations', '(', 'synonymy', ',', 'antonymy', ',', 'hyponymy', ',', 'meronymy', ',', 'etc.', ')'], 'h': {'name': 'semantic relations', 'pos': [3, 5]}, 't': {'name': 'Lexicalized concepts', 'pos': [0, 2]}, 'relation': 'model-feature'}
{'token': ['Work', 'grant', 'intended', 'extend', 'upgrade', 'WordNet', ',', 'make', 'generally', 'available', ',', 'develop', 'tool', 'use', 'practical', 'applications', '.'], 'h': {'name': 'WordNet', 'pos': [5, 6]}, 't': {'name': 'applications', 'pos': [15, 16]}, 'relation': 'usage'}
{'token': ['order', 'make', 'available', 'information', 'retrieval', 'machine', 'translation', ',', 'system', 'developed', 'English', 'text', 'input', 'automatically', 'gives', 'output', 'text', 'augmented', 'syntactic', 'semantic', 'anotations', 'disambiguate', 'substantive', 'words', '.'], 'h': {'name': 'syntactic and semantic anotations', 'pos': [18, 21]}, 't': {'name': 'substantive words', 'pos': [22, 24]}, 'relation': 'model-feature'}
{'token': ['Initially', ',', 'semantic', 'tagging', 'done', 'manually', '(', '1', ')', 'obtain', 'extensive', 'experience', 'tagging', 'process', '(', '2', ')', 'create', 'database', 'correctly', 'tagged', 'text', 'use', 'testing', 'proposals', 'automatic', 'sense', 'disambiguation', '.'], 'h': {'name': 'text', 'pos': [21, 22]}, 't': {'name': 'database', 'pos': [18, 19]}, 'relation': 'part_whole'}
{'token': ['Review', 'previous', 'designs', 'involving', 'TIPSTER', 'technology', ',', 'support', 'design', 'process', '.', 'Determine', 'application', 'benefit', 'upgrading', 'advanced', 'TIPSTER', 'technology', 'developed', 'since', 'application', 'implemented', '.'], 'h': {'name': 'TIPSTER technology', 'pos': [16, 18]}, 't': {'name': 'application', 'pos': [12, 13]}, 'relation': 'usage'}
{'token': ['Accurate', 'lemmatization', 'German', 'nouns', 'mandates', 'use', 'lexicon', '.'], 'h': {'name': 'lemmatization', 'pos': [1, 2]}, 't': {'name': 'German nouns', 'pos': [2, 4]}, 'relation': 'usage'}
{'token': ['present', 'self', '-', 'learning', 'lemmatizer', 'capable', 'automatically', 'creating', 'full', '-', 'form', 'lexicon', 'processing', 'German', 'documents', '.'], 'h': {'name': 'self-learning lemmatizer', 'pos': [1, 5]}, 't': {'name': 'German documents', 'pos': [13, 15]}, 'relation': 'usage'}
{'token': ['paper', 'describe', '-', 'Atlas', 'creates', 'utilizes', 'proof', '-', 'based', 'representation', 'student', 'essays', '.'], 'h': {'name': 'proof-based representation', 'pos': [6, 10]}, 't': {'name': 'Why-Atlas', 'pos': [2, 4]}, 'relation': 'usage'}
{'token': ['describe', 'creates', 'proof', 'given', 'output', 'sentence', '-', 'level', 'understanding', ',', 'uses', 'proofs', 'give', 'students', 'feedback', ',', 'preliminary', 'runtime', 'measures', ',', 'work', 'currently', 'derive', 'additional', 'benefits', 'proof', '-', 'based', 'approach', 'tutoring', 'applications', '.'], 'h': {'name': 'proof-based approach', 'pos': [25, 29]}, 't': {'name': 'tutoring applications', 'pos': [29, 31]}, 'relation': 'usage'}
{'token': ['Compared', 'syntactic', 'knowledge', ',', 'semantic', 'knowledge', 'difficult', 'annotate', ',', 'ambiguity', 'problem', 'serious', '.'], 'h': {'name': 'syntactic knowledge', 'pos': [1, 3]}, 't': {'name': 'semantic knowledge', 'pos': [4, 6]}, 'relation': 'compare'}
{'token': ['Finally', ',', 'compare', 'corpus', 'well', '-', 'known', 'corpora', '.'], 'h': {'name': 'corpus', 'pos': [3, 4]}, 't': {'name': 'corpora', 'pos': [7, 8]}, 'relation': 'compare'}
{'token': ['techniques', ',', 'developed', 'within', 'Augmented', 'Transition', 'Network', '(', 'ATN', ')', 'model', ',', 'shown', 'adequate', 'handle', 'many', 'cases', '.'], 'h': {'name': 'techniques', 'pos': [0, 1]}, 't': {'name': 'Augmented Transition Network (ATN) model', 'pos': [4, 11]}, 'relation': 'usage'}
{'token': ['identified', ',', 'reference', 'chains', 'extended', 'across', 'segment', 'boundaries', ',', 'thus', 'enabling', 'application', 'CT', 'entire', 'discourse', '.'], 'h': {'name': 'CT', 'pos': [12, 13]}, 't': {'name': 'discourse', 'pos': [14, 15]}, 'relation': 'usage'}
{'token': ['describe', 'processes', 'veins', 'defined', 'discourse', 'structure', 'trees', 'CT', 'applied', 'global', 'discourse', 'using', 'chains', '.'], 'h': {'name': 'CT', 'pos': [7, 8]}, 't': {'name': 'global discourse', 'pos': [9, 11]}, 'relation': 'usage'}
{'token': ['also', 'define', 'discourse', 'smoothness', 'index', 'used', 'compare', 'different', 'discourse', 'structures', 'interpretations', ',', 'show', 'VT', 'used', 'abstract', 'span', 'text', 'context', 'whole', 'discourse', '.'], 'h': {'name': 'discourse smoothness index', 'pos': [2, 5]}, 't': {'name': 'discourse structures and interpretations', 'pos': [8, 11]}, 'relation': 'usage'}
{'token': ['HITIQA', 'interactive', 'open-domain', 'question', 'answering', 'technology', 'designed', 'allow', 'analysts', 'pose', 'complex', 'exploratory', 'questions', 'natural', 'language', 'obtain', 'relevant', 'information', 'units', 'prepare', 'briefing', 'reports', 'order', 'satisfy', 'given', 'scenario', '.'], 'h': {'name': 'natural language', 'pos': [13, 15]}, 't': {'name': 'exploratory questions', 'pos': [11, 13]}, 'relation': 'model-feature'}
{'token': ['system', 'uses', 'novel', 'data-driven', 'semantics', 'conduct', 'clarification', 'dialogue', 'user', 'explores', 'scope', 'context', 'desired', 'answer', 'space', '.'], 'h': {'name': 'data-driven semantics', 'pos': [3, 5]}, 't': {'name': 'system', 'pos': [0, 1]}, 'relation': 'usage'}
{'token': ['One', 'resulted', 'first', 'freely', 'distributable', 'corpus', 'fully', 'anonymized', 'clinical', 'text', '.'], 'h': {'name': 'fully anonymized clinical text', 'pos': [6, 10]}, 't': {'name': 'corpus', 'pos': [5, 6]}, 'relation': 'part_whole'}
{'token': ['key', 'feature', 'task', 'required', 'categorization', 'respect', 'large', 'commercially', 'significant', 'set', 'labels', '.'], 'h': {'name': 'set of labels', 'pos': [9, 11]}, 't': {'name': 'categorization', 'pos': [4, 5]}, 'relation': 'usage'}
{'token': ['Many', 'systems', 'performed', 'levels', 'approaching', 'inter', '-', 'coder', 'agreement', ',', 'suggesting', 'human', '-', 'like', 'performance', 'task', 'within', 'reach', 'currently', 'available', 'technologies', '.'], 'h': {'name': 'human-like performance', 'pos': [11, 15]}, 't': {'name': 'currently available technologies', 'pos': [18, 21]}, 'relation': 'compare'}
{'token': ['paper', 'describe', 'automatic', 'information', 'nuggetization', 'application', 'text', 'comparison', '.'], 'h': {'name': 'automatic information nuggetization', 'pos': [2, 5]}, 't': {'name': 'text comparison', 'pos': [6, 8]}, 'relation': 'usage'}
{'token': ['specifically', ',', 'take', 'close', 'look', 'machine', '-', 'generated', 'nuggets', 'used', 'create', 'evaluation', 'material', '.'], 'h': {'name': 'machine-generated nuggets', 'pos': [5, 9]}, 't': {'name': 'evaluation material', 'pos': [11, 13]}, 'relation': 'usage'}
{'token': ['semiautomatic', 'annotation', 'scheme', 'designed', 'produce', 'gold', '-', 'standard', 'data', 'exceptionally', 'high', 'inter-human', 'agreement', '.'], 'h': {'name': 'semiautomatic annotation scheme', 'pos': [0, 3]}, 't': {'name': 'gold-standard data', 'pos': [5, 9]}, 'relation': 'usage'}
{'token': ['paper', 'presents', 'results', 'experiments', 'tested', 'different', 'kinds', 'features', 'retrieval', 'Chinese', 'opinionated', 'texts', '.'], 'h': {'name': 'features', 'pos': [7, 8]}, 't': {'name': 'retrieval', 'pos': [8, 9]}, 'relation': 'usage'}
{'token': ['assume', 'task', 'retrieval', 'opinionated', 'texts', '(', 'OIR', ')', 'regarded', 'subtask', 'general', 'IR', ',', 'distinct', 'features', '.'], 'h': {'name': 'retrieval', 'pos': [2, 3]}, 't': {'name': 'IR', 'pos': [11, 12]}, 'relation': 'part_whole'}
{'token': ['paper', 'discusses', 'supervised', 'learning', 'morphology', 'using', 'stochastic', 'transducers', ',', 'trained', 'using', 'Expectation', '-', 'Maximization', '(', 'EM', ')', 'algorithm', '.'], 'h': {'name': 'stochastic transducers', 'pos': [6, 8]}, 't': {'name': 'supervised learning', 'pos': [2, 4]}, 'relation': 'usage'}
{'token': ['evaluated', 'compared', 'data', 'sets', 'English', ',', 'German', ',', 'Slovene', 'Arabic', '.'], 'h': {'name': 'data sets', 'pos': [2, 4]}, 't': {'name': 'English', 'pos': [4, 5]}, 'relation': 'part_whole'}
{'token': ['Speech', 'recognition', 'problems', 'reality', 'current', 'spoken', 'dialogue', 'systems'], 'h': {'name': 'Speech recognition problems', 'pos': [0, 3]}, 't': {'name': 'spoken dialogue systems', 'pos': [5, 8]}, 'relation': 'part_whole'}
{'token': ['apply', 'Chi', 'Square', '(', '%', '2', ')', 'analysis', 'corpus', 'speech', '-', 'based', 'computer', 'tutoring', 'dialogues', 'discover', 'dependencies', 'within', 'across', 'turns', '.'], 'h': {'name': 'Chi Square (%2) analysis', 'pos': [1, 8]}, 't': {'name': 'corpus of speech-based computer tutoring dialogues', 'pos': [8, 15]}, 'relation': 'usage'}
{'token': ['interlingual', 'knowledge', '-', 'based', 'machine', 'translation', 'system', ',', 'ambiguity', 'arises', 'source', 'language', 'analyzer', 'produces', 'one', 'interlingua', 'expression', 'source', 'sentence', '.'], 'h': {'name': 'interlingua expression', 'pos': [15, 17]}, 't': {'name': 'source sentence', 'pos': [17, 19]}, 'relation': 'model-feature'}
{'token': ['also', 'test', 'methods', 'large', 'corpus', 'test', 'sentences', ',', 'order', 'illustrate', 'different', 'disambiguation', 'methods', 'reduce', 'average', 'number', 'parses', 'per', 'sentence', '.'], 'h': {'name': 'test sentences', 'pos': [5, 7]}, 't': {'name': 'corpus', 'pos': [4, 5]}, 'relation': 'part_whole'}
{'token': ['also', 'test', 'methods', 'large', 'corpus', 'test', 'sentences', ',', 'order', 'illustrate', 'different', 'disambiguation', 'methods', 'reduce', 'average', 'number', 'parses', 'per', 'sentence', '.'], 'h': {'name': 'disambiguation methods', 'pos': [11, 13]}, 't': {'name': 'parses', 'pos': [16, 17]}, 'relation': 'result'}
{'token': ['intersection', 'tree', 'transducer', '-', 'based', 'translation', 'models', 'n-gram', 'language', 'models', 'results', 'huge', 'dynamic', 'programs', 'machine', 'translation', 'decoding', '.'], 'h': {'name': 'dynamic programs', 'pos': [12, 14]}, 't': {'name': 'machine translation decoding', 'pos': [14, 17]}, 'relation': 'usage'}
{'token': ['contrast', 'previous', 'order', '-', 'based', 'bigram-', 'to', 'trigram', 'approaches', ',', 'we', 'on', 'encoding', '-', 'based', 'methods', ',', 'which', 'a', 'clustered', 'encoding', 'of', 'language', '.'], 'h': {'name': 'clustered encoding', 'pos': [19, 21]}, 't': {'name': 'encoding-based methods', 'pos': [12, 16]}, 'relation': 'usage'}
{'token': ['Moreover', ',', 'entire', 'decoding', 'cascade', 'trigram', 'language', 'models', 'faster', 'corresponding', 'bigram', 'pass', 'alone', 'bigram-', 'to', 'decoder', '.'], 'h': {'name': 'decoding cascade for trigram language models', 'pos': [3, 8]}, 't': {'name': 'bigram-to-trigram decoder', 'pos': [13, 16]}, 'relation': 'compare'}
{'token': ['paper', 'presents', 'findings', 'feasibility', 'pronoun', 'resolution', 'biomedical', 'texts', ',', 'comparison', 'conducting', 'pronoun', 'resolution', 'newswire', 'domain', '.'], 'h': {'name': 'pronoun resolution', 'pos': [4, 6]}, 't': {'name': 'biomedical texts', 'pos': [6, 8]}, 'relation': 'usage'}
{'token': ['paper', 'presents', 'findings', 'feasibility', 'pronoun', 'resolution', 'biomedical', 'texts', ',', 'comparison', 'conducting', 'pronoun', 'resolution', 'newswire', 'domain', '.'], 'h': {'name': 'pronoun resolution', 'pos': [11, 13]}, 't': {'name': 'newswire domain', 'pos': [13, 15]}, 'relation': 'usage'}
{'token': ['Sharing', 'portions', 'grammars', 'across', 'languages', 'greatly', 'reduces', 'costs', 'multilingual', 'grammar', 'engineering', '.'], 'h': {'name': 'grammars', 'pos': [2, 3]}, 't': {'name': 'multilingual grammar engineering', 'pos': [8, 11]}, 'relation': 'result'}
{'token': ['Taking', 'grammatical', 'relatedness', 'seriously', ',', 'particularly', 'interested', 'designing', 'linguistically', 'motivated', 'grammatical', 'resources', 'Slavic', 'languages', 'used', 'applied', 'theoretical', 'computational', 'linguistics', '.'], 'h': {'name': 'linguistically motivated grammatical resources', 'pos': [8, 12]}, 't': {'name': 'applied and theoretical computational linguistics', 'pos': [15, 19]}, 'relation': 'usage'}
{'token': ['basis', 'Slavic', 'data', ',', 'show', 'domain', 'ontology', 'conceptualising', 'morpho-syntactic', '"', 'building', 'blocks', '"', 'serve', 'basis', 'shared', 'grammar', 'Slavic', '.'], 'h': {'name': 'domain ontology', 'pos': [5, 7]}, 't': {'name': 'shared grammar of Slavic', 'pos': [15, 18]}, 'relation': 'usage'}
{'token': ['currently', 'developing', 'MiniSTEx', ',', 'spatiotemporal', 'annotation', 'system', 'handle', 'temporal', '/', 'geospatial', 'information', 'directly', 'indirectly', 'expressed', 'texts', '.'], 'h': {'name': 'temporal and/or geospatial information', 'pos': [8, 12]}, 't': {'name': 'texts', 'pos': [15, 16]}, 'relation': 'part_whole'}
{'token': ['first', 'version', 'MiniSTEx', 'originally', 'developed', 'Dutch', ',', 'keeping', 'mind', 'also', 'useful', 'European', 'languages', ',', 'multilingual', 'applications', '.'], 'h': {'name': 'MiniSTEx', 'pos': [2, 3]}, 't': {'name': 'Dutch', 'pos': [5, 6]}, 'relation': 'usage'}
{'token': ['paper', 'describe', 'technique', 'improving', 'performance', 'information', 'extraction', 'system', 'speech', 'data', 'explicitly', 'modeling', 'errors', 'recognizer', 'output', '.'], 'h': {'name': 'information extraction system', 'pos': [5, 8]}, 't': {'name': 'speech data', 'pos': [8, 10]}, 'relation': 'usage'}
{'token': ['paper', ',', 'report', 'QA', 'system', 'answer', 'type', 'questions', 'based', 'confirmed', 'knowledge', 'base', 'developed', 'using', 'mails', 'posted', 'mailing', 'list', '.'], 'h': {'name': 'QA system', 'pos': [3, 5]}, 't': {'name': 'type questions', 'pos': [6, 8]}, 'relation': 'usage'}
{'token': ['paper', ',', 'report', 'QA', 'system', 'answer', 'type', 'questions', 'based', 'confirmed', 'knowledge', 'base', 'developed', 'using', 'mails', 'posted', 'mailing', 'list', '.'], 'h': {'name': 'confirmed knowledge base', 'pos': [9, 12]}, 't': {'name': 'mails', 'pos': [14, 15]}, 'relation': 'part_whole'}
{'token': ['first', 'discuss', 'problem', 'developing', 'knowledge', 'base', 'using', 'natural', 'language', 'documents', ':', 'wrong', 'information', 'natural', 'language', 'documents', '.'], 'h': {'name': 'knowledge base', 'pos': [4, 6]}, 't': {'name': 'natural language documents', 'pos': [7, 10]}, 'relation': 'part_whole'}
{'token': ['first', 'discuss', 'problem', 'developing', 'knowledge', 'base', 'using', 'natural', 'language', 'documents', ':', 'wrong', 'information', 'natural', 'language', 'documents', '.'], 'h': {'name': 'wrong information', 'pos': [11, 13]}, 't': {'name': 'natural language documents', 'pos': [13, 16]}, 'relation': 'part_whole'}
{'token': [',', 'describe', 'method', 'detecting', 'wrong', 'information', 'mails', 'posted', 'mailing', 'list', 'developing', 'knowledge', 'base', 'using', 'mails', '.'], 'h': {'name': 'wrong information', 'pos': [4, 6]}, 't': {'name': 'mails', 'pos': [6, 7]}, 'relation': 'part_whole'}
{'token': [',', 'describe', 'method', 'detecting', 'wrong', 'information', 'mails', 'posted', 'mailing', 'list', 'developing', 'knowledge', 'base', 'using', 'mails', '.'], 'h': {'name': 'knowledge base', 'pos': [11, 13]}, 't': {'name': 'mails', 'pos': [14, 15]}, 'relation': 'part_whole'}
{'token': ['Finally', ',', 'show', 'question', 'answer', 'mails', 'posted', 'mailing', 'list', 'used', 'knowledge', 'base', 'QA', 'system', '.'], 'h': {'name': 'knowledge base', 'pos': [10, 12]}, 't': {'name': 'QA system', 'pos': [12, 14]}, 'relation': 'usage'}
{'token': ['demonstrate', 'new', 'research', 'approach', 'problem', 'predicting', 'reading', 'difficulty', 'text', 'passage', ',', 'recasting', 'readability', 'terms', 'statistical', 'language', 'modeling', '.'], 'h': {'name': 'reading difficulty', 'pos': [6, 8]}, 't': {'name': 'text passage', 'pos': [8, 10]}, 'relation': 'model-feature'}
{'token': ['demonstrate', 'new', 'research', 'approach', 'problem', 'predicting', 'reading', 'difficulty', 'text', 'passage', ',', 'recasting', 'readability', 'terms', 'statistical', 'language', 'modeling', '.'], 'h': {'name': 'statistical language modeling', 'pos': [14, 17]}, 't': {'name': 'readability', 'pos': [12, 13]}, 'relation': 'model-feature'}
{'token': ['derive', 'measure', 'based', 'extension', 'multinomial', 'naive', 'Bayes', 'classification', 'combines', 'multiple', 'language', 'models', 'estimate', 'likely', 'grade', 'level', 'given', 'passage', '.'], 'h': {'name': 'language models', 'pos': [10, 12]}, 't': {'name': 'multinomial naive Bayes classification', 'pos': [4, 8]}, 'relation': 'usage'}
{'token': ['perform', 'predictions', 'individual', 'Web', 'pages', 'English', 'compare', 'performance', 'widely', '-', 'used', 'semantic', 'variables', 'traditional', 'readability', 'measures', '.'], 'h': {'name': 'semantic variables', 'pos': [11, 13]}, 't': {'name': 'readability measures', 'pos': [14, 16]}, 'relation': 'part_whole'}
{'token': ['traditional', 'semantic', 'variables', 'type-', 'token', 'ratio', 'gave', 'the', 'performance', 'on', 'calibrated', 'test', 'passages', ',', 'while', 'language', 'modeling', 'approach', 'gave', 'better', 'accuracy', 'for', 'Web', 'documents', 'and', 'passages', '(', 'less', 'than', 'words', ')', '.'], 'h': {'name': 'language modeling approach', 'pos': [15, 18]}, 't': {'name': 'Web documents', 'pos': [22, 24]}, 'relation': 'usage'}
{'token': ['Syntactic', 'semantic', 'information', 'represented', 'grammar', 'uniform', 'manner', ',', 'similar', 'HPSG', '(', 'Pollard', 'Sag', ',', '1987', ')', '.'], 'h': {'name': 'grammar', 'pos': [4, 5]}, 't': {'name': 'Syntactic and semantic information', 'pos': [0, 3]}, 'relation': 'model-feature'}
{'token': ['LINK', 'used', 'several', 'information', 'extraction', 'applications', '.'], 'h': {'name': 'LINK', 'pos': [0, 1]}, 't': {'name': 'information extraction applications', 'pos': [3, 6]}, 'relation': 'usage'}
{'token': ['project', 'General', 'Motors', ',', 'LINK', 'used', 'process', 'terse', 'free', '-', 'form', 'descriptions', 'symptoms', 'displayed', 'malfunctioning', 'automobiles', ',', 'repairs', 'fixed', '.'], 'h': {'name': 'LINK', 'pos': [4, 5]}, 't': {'name': 'free-form descriptions', 'pos': [8, 12]}, 'relation': 'usage'}
{'token': ['Reduplication', ',', 'central', 'instance', 'prosodic', 'morphology', ',', 'particularly', 'challenging', 'state', '-', '-', '-', 'art', 'computational', 'morphology', ',', 'since', 'involves', 'copying', 'part', 'phonological', 'string'], 'h': {'name': 'Reduplication', 'pos': [0, 1]}, 't': {'name': 'prosodic morphology', 'pos': [4, 6]}, 'relation': 'part_whole'}
{'token': ['paper', 'advocate', 'finite', '-', 'state', 'method', 'combines', 'enriched', 'lexical', 'representations', 'via', 'intersection', 'implement', 'copying', '.'], 'h': {'name': 'enriched lexical representations', 'pos': [7, 10]}, 't': {'name': 'finite-state method', 'pos': [2, 6]}, 'relation': 'usage'}
{'token': ['proposal', 'includes', 'resource', '-', 'conscious', 'variant', 'automata', 'benefit', 'existence', 'lazy', 'algorithms', '.'], 'h': {'name': 'lazy algorithms', 'pos': [9, 11]}, 't': {'name': 'resource-conscious variant of automata', 'pos': [2, 7]}, 'relation': 'usage'}
{'token': ['quick', 'relevancy', 'judgements', 'require', 'two', 'steps', ':', '(', '1', ')', 'recognizing', 'expression', 'highly', 'relevant', 'given', 'domain', ',', 'e.g.', '"', 'killed', '"', 'domain', 'terrorism', ',', '(', '2', ')', 'verifying', 'context', 'surrounding', 'expression', 'consistent', 'relevancy', 'guidelines', 'domain', ',', 'e.g.', '"', '5', 'soldiers', 'killed', 'guerrillas', '"', 'consistent', 'terrorism', 'domain', 'since', 'victims', 'terrorist', 'acts', 'must', 'civilians', '.'], 'h': {'name': 'expression', 'pos': [11, 12]}, 't': {'name': 'given domain', 'pos': [14, 16]}, 'relation': 'model-feature'}
{'token': ['Relevancy', 'Signatures', 'Algorithm', 'attempts', 'simulate', 'first', 'step', 'process', 'deriving', 'reliable', 'relevancy', 'cues', 'corpus', 'training', 'texts', 'using', 'cues', 'quickly', 'identify', 'new', 'texts', 'highly', 'likely', 'relevant', '.'], 'h': {'name': 'reliable relevancy cues', 'pos': [9, 12]}, 't': {'name': 'corpus of training texts', 'pos': [12, 15]}, 'relation': 'part_whole'}
{'token': ['system', 'accepts', 'entire', 'English', 'news', 'story', '(', 'text', ')', 'query', ',', 'retrieves', 'relevant', 'Chinese', 'broadcast', 'news', 'stories', '(', 'audio', ')', 'document', 'collection', '.'], 'h': {'name': 'relevant Chinese broadcast news stories (audio)', 'pos': [12, 20]}, 't': {'name': 'document collection', 'pos': [20, 22]}, 'relation': 'part_whole'}
{'token': ['English', 'queries', 'translated', 'Chinese', 'means', 'dictionary', '-', 'based', 'approach', ',', 'integrated', 'phrase', '-', 'based', 'translation', 'word', '-', '-', 'word', 'translation', '.'], 'h': {'name': 'phrase-based translation', 'pos': [11, 15]}, 't': {'name': 'dictionary-based approach', 'pos': [5, 9]}, 'relation': 'usage'}
{'token': ['Untranslatable', 'named', 'entities', 'transliterated', 'novel', 'subword', 'translation', 'technique', '.'], 'h': {'name': 'novel subword translation technique', 'pos': [4, 8]}, 't': {'name': 'Untranslatable named entities', 'pos': [0, 3]}, 'relation': 'usage'}
{'token': ['Experimental', 'results', 'demonstrate', 'use', 'phrase', '-', 'based', 'translation', 'subword', 'translation', 'gave', 'performance', 'gains', ',', 'multi-scale', 'retrieval', 'outperforms', 'word', '-', 'based', 'retrieval', '.'], 'h': {'name': 'multi-scale retrieval', 'pos': [14, 16]}, 't': {'name': 'word-based retrieval', 'pos': [17, 21]}, 'relation': 'compare'}
{'token': ['English', 'past', 'tense', 'interesting', 'features', 'combination', 'regular', 'rules', 'semi-productive', 'strong', 'verb', 'patterns', ',', 'many', 'respects', 'trivial', 'morphological', 'system', '-', 'reflecting', 'generally', 'vestigal', 'nature', 'inflectional', 'morphology', 'within', 'modern', 'English', '.'], 'h': {'name': 'features', 'pos': [4, 5]}, 't': {'name': 'English past tense', 'pos': [0, 3]}, 'relation': 'model-feature'}
{'token': ['English', 'past', 'tense', 'interesting', 'features', 'combination', 'regular', 'rules', 'semi-productive', 'strong', 'verb', 'patterns', ',', 'many', 'respects', 'trivial', 'morphological', 'system', '-', 'reflecting', 'generally', 'vestigal', 'nature', 'inflectional', 'morphology', 'within', 'modern', 'English', '.'], 'h': {'name': 'vestigal nature', 'pos': [21, 23]}, 't': {'name': 'inflectional morphology', 'pos': [23, 25]}, 'relation': 'model-feature'}
{'token': ['define', ',', 'implement', 'evaluate', 'novel', 'model', 'statistical', 'machine', 'translation', ',', 'based', 'shallow', 'syntactic', 'analysis', '(', 'part', '-of', 'speech', 'tagging', 'and', 'chunking', ')', 'in', 'and', 'languages', '.'], 'h': {'name': 'shallow syntactic analysis', 'pos': [11, 14]}, 't': {'name': 'statistical machine translation', 'pos': [6, 9]}, 'relation': 'usage'}
{'token': ['paper', 'analyzes', 'translation', 'quality', 'machine', 'translation', 'systems', '10', 'language', 'pairs', 'translating', 'Czech', ',', 'English', ',', 'French', ',', 'German', ',', 'Hungarian', ',', 'Spanish', '.'], 'h': {'name': 'machine translation systems', 'pos': [4, 7]}, 't': {'name': 'language pairs', 'pos': [8, 10]}, 'relation': 'usage'}
{'token': ['validate', 'manual', 'evaluation', 'methodology', 'measuring', 'intra', '-', 'inter-annotator', 'agreement', ',', 'collecting', 'timing', 'information', '.'], 'h': {'name': 'intra- and inter-annotator agreement', 'pos': [5, 9]}, 't': {'name': 'manual evaluation methodology', 'pos': [1, 4]}, 'relation': 'usage'}
{'token': ['paper', ',', 'describe', 'issues', 'translation', 'proper', 'names', 'English', 'Chinese', 'faced', 'constructing', 'system', 'multilingual', 'text', 'generation', 'supporting', 'languages', '.'], 'h': {'name': 'translation', 'pos': [4, 5]}, 't': {'name': 'proper names', 'pos': [5, 7]}, 'relation': 'usage'}
{'token': ['CWS', 'based', 'backward', 'maximum', 'matching', 'word', 'support', 'model', '(', 'WSM', ')', 'contextual', '-', 'based', 'Chinese', 'unknown', 'word', 'identification', '.'], 'h': {'name': 'backward maximum matching', 'pos': [2, 5]}, 't': {'name': 'CWS', 'pos': [0, 1]}, 'relation': 'usage'}
{'token': ['Arabic', 'language', 'far', 'richer', 'systems', 'inflection', 'derivation', 'English', 'little', 'morphology', '.'], 'h': {'name': 'systems of inflection and derivation', 'pos': [4, 7]}, 't': {'name': 'Arabic language', 'pos': [0, 2]}, 'relation': 'model-feature'}
{'token': ['Segmentation', 'inflected', 'Arabic', 'words', 'way', 'smooth', 'highly', 'morphological', 'nature', '.'], 'h': {'name': 'Segmentation', 'pos': [0, 1]}, 't': {'name': 'inflected Arabic words', 'pos': [1, 4]}, 'relation': 'usage'}
{'token': ['paper', ',', 'describe', 'statistically', 'linguistically', 'motivated', 'methods', 'Arabic', 'word', 'segmentation', '.'], 'h': {'name': 'statistically and linguistically motivated methods', 'pos': [3, 7]}, 't': {'name': 'Arabic word segmentation', 'pos': [7, 10]}, 'relation': 'usage'}
{'token': [',', 'show', 'efficiency', 'proposed', 'methods', 'Arabic-English', 'BTEC', 'and', 'NIST', '.'], 'h': {'name': 'proposed methods', 'pos': [3, 5]}, 't': {'name': 'Arabic-English BTEC and NIST tasks', 'pos': [5, 9]}, 'relation': 'usage'}
{'token': ['Developing', 'high', '-', 'quality', 'lexicon', 'often', 'first', 'step', 'towards', 'building', 'POS', 'tagger', ',', 'turn', 'front', '-', 'end', 'many', 'NLP', 'systems', '.'], 'h': {'name': 'high-quality lexicon', 'pos': [1, 5]}, 't': {'name': 'POS tagger', 'pos': [10, 12]}, 'relation': 'usage'}
{'token': ['frame', 'lexicon', 'acquisition', 'problem', 'transductive', 'learning', 'problem', ',', 'perform', 'comparisons', 'three', 'transductive', 'algorithms', ':', 'Transductive', 'SVMs', ',', 'Spectral', 'Graph', 'Transducers', ',', 'novel', 'Transductive', 'Clustering', 'method', '.'], 'h': {'name': 'Transductive SVMs', 'pos': [14, 16]}, 't': {'name': 'Spectral Graph Transducers', 'pos': [17, 20]}, 'relation': 'compare'}
{'token': ['present', 'API', 'computing', 'semantic', 'relatedness', 'words', 'Wikipedia', '.'], 'h': {'name': 'API', 'pos': [1, 2]}, 't': {'name': 'semantic relatedness', 'pos': [3, 5]}, 'relation': 'usage'}
{'token': ['paper', 'presents', 'general', 'platform', ',', 'namely', 'synchronous', 'tree', 'sequence', 'substitution', 'grammar', '(', 'STSSG', ')', ',', 'grammar', 'comparison', 'study', 'Translational', 'Equivalence', 'Modeling', '(', 'TEM', ')', 'Statistical', 'Machine', 'Translation', '(', 'SMT', ')', '.'], 'h': {'name': 'synchronous tree sequence substitution grammar (STSSG)', 'pos': [6, 14]}, 't': {'name': 'grammar comparison study', 'pos': [15, 18]}, 'relation': 'usage'}
{'token': ['Experimental', 'results', 'show', 'STSSG', 'able', 'better', 'explain', 'data', 'parallel', 'corpora', 'grammars', '.'], 'h': {'name': 'STSSG', 'pos': [3, 4]}, 't': {'name': 'other grammars', 'pos': [10, 11]}, 'relation': 'compare'}
{'token': ['study', 'finds', 'complexity', 'structure', 'divergence', 'much', 'higher', 'suggested', 'literature', ',', 'imposes', 'big', 'challenge', 'syntactic', 'transformation', '-', 'based', 'SMT', '.'], 'h': {'name': 'structure divergence', 'pos': [3, 5]}, 't': {'name': 'syntactic transformation-based SMT', 'pos': [13, 18]}, 'relation': 'result'}
{'token': ['paper', 'presents', 'innovative', 'unsupervised', 'method', 'automatic', 'sentence', 'extraction', 'using', 'graph', '-', 'based', 'ranking', 'algorithms', '.'], 'h': {'name': 'unsupervised method', 'pos': [3, 5]}, 't': {'name': 'automatic sentence extraction', 'pos': [5, 8]}, 'relation': 'usage'}
{'token': ['evaluate', 'method', 'context', 'text', 'summarization', 'task', ',', 'show', 'results', 'obtained', 'compare', 'favorably', 'previously', 'published', 'results', 'established', 'benchmarks', '.'], 'h': {'name': 'method', 'pos': [1, 2]}, 't': {'name': 'text summarization task', 'pos': [3, 6]}, 'relation': 'usage'}
{'token': ['Preferred', 'antecedents', 'subset', 'possible', 'antecedents', ',', 'selected', 'application', 'extralinguistic', 'knowledge', '.'], 'h': {'name': 'Preferred antecedents', 'pos': [0, 2]}, 't': {'name': 'possible antecedents', 'pos': [3, 5]}, 'relation': 'part_whole'}
{'token': ['paper', 'presents', 'syntactic', 'description', 'fragment', 'German', 'worked', 'within', 'machine', 'translation', 'project', 'Eurotra', '.'], 'h': {'name': 'syntactic description', 'pos': [2, 4]}, 't': {'name': 'German', 'pos': [5, 6]}, 'relation': 'model-feature'}
{'token': ['represents', 'syntactic', 'part', 'German', 'module', 'multilingual', 'translation', 'system', '.'], 'h': {'name': 'syntactic part', 'pos': [1, 3]}, 't': {'name': 'German module', 'pos': [3, 5]}, 'relation': 'part_whole'}
{'token': ['present', 'approach', 'querying', 'collections', 'heterogeneous', 'linguistic', 'corpora', 'annotated', 'multiple', 'layers', 'using', 'arbitrary', 'XML', '-', 'based', 'markup', 'languages', '.'], 'h': {'name': 'multiple layers', 'pos': [8, 10]}, 't': {'name': 'heterogeneous linguistic corpora', 'pos': [4, 7]}, 'relation': 'model-feature'}
{'token': ['OWL', 'ontology', 'provides', 'homogenising', 'view', 'conceptually', 'different', 'markup', 'languages', 'common', 'querying', 'framework', 'established', 'using', 'method', 'ontology', '-', 'based', 'query', 'expansion', '.'], 'h': {'name': 'OWL ontology', 'pos': [0, 2]}, 't': {'name': 'markup languages', 'pos': [7, 9]}, 'relation': 'usage'}
{'token': ['OWL', 'ontology', 'provides', 'homogenising', 'view', 'conceptually', 'different', 'markup', 'languages', 'common', 'querying', 'framework', 'established', 'using', 'method', 'ontology', '-', 'based', 'query', 'expansion', '.'], 'h': {'name': 'ontology-based query expansion', 'pos': [15, 20]}, 't': {'name': 'querying framework', 'pos': [10, 12]}, 'relation': 'usage'}
{'token': ['interface', 'also', 'used', 'ontology', '-', 'based', 'querying', 'multiple', 'corpora', 'simultaneously', '.'], 'h': {'name': 'ontology-based querying', 'pos': [3, 7]}, 't': {'name': 'corpora', 'pos': [8, 9]}, 'relation': 'usage'}
{'token': ['also', 'evaluate', 'model', 'related', 'role', '-', 'labelling', 'task', ',', 'compare', 'standard', 'role', 'labeller', '.'], 'h': {'name': 'model', 'pos': [2, 3]}, 't': {'name': 'standard role labeller', 'pos': [10, 13]}, 'relation': 'compare'}
{'token': ['tasks', ',', 'model', 'benefits', 'class', '-', 'based', 'smoothing', ',', 'allows', 'make', 'correct', 'argument', '-specific', 'predictions', 'despite', 'a', 'sparse', 'data', 'problem', '.'], 'h': {'name': 'class-based smoothing', 'pos': [4, 8]}, 't': {'name': 'model', 'pos': [2, 3]}, 'relation': 'result'}
{'token': ['standard', 'labeller', 'suffers', 'sparse', 'data', 'strong', 'reliance', 'syntactic', 'cues', ',', 'especially', 'prediction', 'task', '.'], 'h': {'name': 'sparse data', 'pos': [3, 5]}, 't': {'name': 'standard labeller', 'pos': [0, 2]}, 'relation': 'result'}
{'token': ['standard', 'labeller', 'suffers', 'sparse', 'data', 'strong', 'reliance', 'syntactic', 'cues', ',', 'especially', 'prediction', 'task', '.'], 'h': {'name': 'syntactic cues', 'pos': [7, 9]}, 't': {'name': 'prediction task', 'pos': [11, 13]}, 'relation': 'usage'}
{'token': ['bootstrapping', 'fashion', ',', '-', 'called', "'", 'Pendulum', 'Algorithm', "'", 'operates', 'word', 'sets', 'obtained', 'co-occurrence', 'statistics', 'large', 'un-', 'annotated', 'corpus', 'and', 'error', 'propagation', 'low', 'by', 'step', '.'], 'h': {'name': "'Pendulum Algorithm'", 'pos': [5, 9]}, 't': {'name': 'word sets', 'pos': [10, 12]}, 'relation': 'usage'}
{'token': ['bootstrapping', 'fashion', ',', '-', 'called', "'", 'Pendulum', 'Algorithm', "'", 'operates', 'word', 'sets', 'obtained', 'co-occurrence', 'statistics', 'large', 'un-', 'annotated', 'corpus', 'and', 'error', 'propagation', 'low', 'by', 'step', '.'], 'h': {'name': 'co-occurrence statistics', 'pos': [13, 15]}, 't': {'name': 'large un-annotated corpus', 'pos': [15, 19]}, 'relation': 'part_whole'}
{'token': ['first', 'algorithm', ',', 'phone', '-', 'dependent', 'cepstral', 'compensation', ',', 'similar', 'concept', 'previously', '-', 'described', 'MFCDCN', 'method', ',', 'except', 'cepstral', 'compensation', 'vectors', 'selected', 'according', 'current', 'phonetic', 'hypothesis', ',', 'rather', 'basis', 'SNR', 'VQ', 'codeword', 'identity', '.'], 'h': {'name': 'phone-dependent cepstral compensation', 'pos': [3, 8]}, 't': {'name': 'MFCDCN method', 'pos': [14, 16]}, 'relation': 'compare'}
{'token': ['Use', 'various', 'compensation', 'algorithms', 'consort', 'produces', 'reduction', 'error', 'rates', 'SPHINX', '-', 'II', 'much', '40', 'percent', 'relative', 'rate', 'achieved', 'cepstral', 'mean', 'normalization', 'alone', ',', 'development', 'test', 'sets', 'context', '1993', 'ARPA', 'CSR', 'evaluations', '.'], 'h': {'name': 'compensation algorithms', 'pos': [2, 4]}, 't': {'name': 'reduction of error rates', 'pos': [6, 9]}, 'relation': 'result'}
{'token': ['One', 'critical', 'components', 'CLT', 'speech', 'recognition', 'system', 'used', 'track', 'child', "'s", 'progress', 'oral', 'reading', 'provide', 'sufficient', 'information', 'detect', 'reading', 'miscues', '.'], 'h': {'name': 'reading miscues', 'pos': [18, 20]}, 't': {'name': 'oral reading', 'pos': [12, 14]}, 'relation': 'part_whole'}
{'token': ['paper', ',', 'extend', 'prior', 'work', 'examining', 'novel', 'labeling', 'children', "'s", 'oral', 'reading', 'audio', 'data', 'order', 'better', 'understand', 'factors', 'contribute', 'significantly', 'speech', 'recognition', 'errors', '.'], 'h': {'name': 'labeling', 'pos': [7, 8]}, 't': {'name': 'oral reading audio data', 'pos': [10, 14]}, 'relation': 'model-feature'}
{'token': ['Next', ',', 'consider', 'problem', 'detecting', 'miscues', 'oral', 'reading', '.'], 'h': {'name': 'miscues', 'pos': [5, 6]}, 't': {'name': 'oral reading', 'pos': [6, 8]}, 'relation': 'part_whole'}
