{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('open-nre': conda)"
  },
  "interpreter": {
   "hash": "66f85137aa5e2a5257f5c4f2ba28a89ccc01c866862ea6aef1209745d61fbdc8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/igor/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "import os, pandas as pd\n",
    "import stanza\n",
    "import nltk\n",
    "\n",
    "RESOURCE_PATH = \"/mnt/projects/OpenNRE/benchmark/raw_ddi/DDICorpus\"\n",
    "OUTPUT_PATH = \"/mnt/projects/OpenNRE/benchmark/ddi\"\n",
    "outdir = 'original/'\n",
    "indir = 'original/'\n",
    "outdir1 = 'entity_blinding/'\n",
    "outdir2 = 'punct_stop_digit/'\n",
    "outdir3 = 'punct_digit/'\n",
    "outdir4 = 'ner_blinding/'\n",
    "def res(path): return os.path.join(RESOURCE_PATH, path)\n",
    "def out(path): return os.path.join(OUTPUT_PATH, path)\n",
    "from opennre.dataset.converters.converter_ddi import get_dataset_dataframe, write_dataframe, \\\n",
    "read_dataframe, check_equality_of_written_and_read_df, write_into_txt, combine, write_relations_json\n",
    "from opennre.dataset.preprocess import preprocess, replace_ner, get_entity_positions_and_replacement_sentence\n",
    "\n",
    "def makedir(outdir, res):\n",
    "    if not os.path.exists(res(outdir)):\n",
    "        os.makedirs(res(outdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.1.json: 139kB [00:00, 12.5MB/s]                    \n",
      "2021-06-19 01:05:07 INFO: Downloading these customized packages for language: en (English)...\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | craft   |\n",
      "| pos       | craft   |\n",
      "| lemma     | craft   |\n",
      "| depparse  | craft   |\n",
      "| pretrain  | craft   |\n",
      "=======================\n",
      "\n",
      "2021-06-19 01:05:07,358 - stanza - INFO - Downloading these customized packages for language: en (English)...\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | craft   |\n",
      "| pos       | craft   |\n",
      "| lemma     | craft   |\n",
      "| depparse  | craft   |\n",
      "| pretrain  | craft   |\n",
      "=======================\n",
      "\n",
      "2021-06-19 01:05:07 INFO: File exists: /home/igor/stanza_resources/en/tokenize/craft.pt.\n",
      "2021-06-19 01:05:07,364 - stanza - INFO - File exists: /home/igor/stanza_resources/en/tokenize/craft.pt.\n",
      "2021-06-19 01:05:07 INFO: File exists: /home/igor/stanza_resources/en/pos/craft.pt.\n",
      "2021-06-19 01:05:07,420 - stanza - INFO - File exists: /home/igor/stanza_resources/en/pos/craft.pt.\n",
      "2021-06-19 01:05:07 INFO: File exists: /home/igor/stanza_resources/en/lemma/craft.pt.\n",
      "2021-06-19 01:05:07,434 - stanza - INFO - File exists: /home/igor/stanza_resources/en/lemma/craft.pt.\n",
      "2021-06-19 01:05:07 INFO: File exists: /home/igor/stanza_resources/en/depparse/craft.pt.\n",
      "2021-06-19 01:05:07,687 - stanza - INFO - File exists: /home/igor/stanza_resources/en/depparse/craft.pt.\n",
      "2021-06-19 01:05:07 INFO: File exists: /home/igor/stanza_resources/en/pretrain/craft.pt.\n",
      "2021-06-19 01:05:07,884 - stanza - INFO - File exists: /home/igor/stanza_resources/en/pretrain/craft.pt.\n",
      "2021-06-19 01:05:07 INFO: Finished downloading models and saved to /home/igor/stanza_resources.\n",
      "2021-06-19 01:05:07,885 - stanza - INFO - Finished downloading models and saved to /home/igor/stanza_resources.\n",
      "2021-06-19 01:05:07 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | craft   |\n",
      "| pos       | craft   |\n",
      "| lemma     | craft   |\n",
      "| depparse  | craft   |\n",
      "=======================\n",
      "\n",
      "2021-06-19 01:05:07,888 - stanza - INFO - Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | craft   |\n",
      "| pos       | craft   |\n",
      "| lemma     | craft   |\n",
      "| depparse  | craft   |\n",
      "=======================\n",
      "\n",
      "2021-06-19 01:05:07 INFO: Use device: gpu\n",
      "2021-06-19 01:05:07,925 - stanza - INFO - Use device: gpu\n",
      "2021-06-19 01:05:07 INFO: Loading: tokenize\n",
      "2021-06-19 01:05:07,926 - stanza - INFO - Loading: tokenize\n",
      "2021-06-19 01:05:10 INFO: Loading: pos\n",
      "2021-06-19 01:05:10,686 - stanza - INFO - Loading: pos\n",
      "2021-06-19 01:05:10 INFO: Loading: lemma\n",
      "2021-06-19 01:05:10,843 - stanza - INFO - Loading: lemma\n",
      "2021-06-19 01:05:10 INFO: Loading: depparse\n",
      "2021-06-19 01:05:10,876 - stanza - INFO - Loading: depparse\n",
      "2021-06-19 01:05:11 INFO: Done loading processors!\n",
      "2021-06-19 01:05:11,186 - stanza - INFO - Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "stanza.download('en', package='craft')\n",
    "nlp = stanza.Pipeline('en', package='craft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/572 [00:00<?, ?it/s]total_files_to_read: 572  from dir:  /mnt/projects/OpenNRE/benchmark/raw_ddi/DDICorpus/Train/DrugBank/\n",
      "100%|██████████| 572/572 [43:50<00:00,  4.60s/it]\n"
     ]
    }
   ],
   "source": [
    "df_train_drugbank = get_dataset_dataframe(nlp, res('Train/DrugBank/'), relation_extraction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/142 [00:00<?, ?it/s]total_files_to_read: 142  from dir:  /mnt/projects/OpenNRE/benchmark/raw_ddi/DDICorpus/Train/MedLine/\n",
      "100%|██████████| 142/142 [01:38<00:00,  1.44it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train_medline = get_dataset_dataframe(nlp, res('Train/MedLine/'), relation_extraction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/158 [00:00<?, ?it/s]total_files_to_read: 158  from dir:  /mnt/projects/OpenNRE/benchmark/raw_ddi/DDICorpus/Test/Test for DDI Extraction task/DrugBank/\n",
      "100%|██████████| 158/158 [06:51<00:00,  2.60s/it]\n"
     ]
    }
   ],
   "source": [
    "df_test_drugbank = get_dataset_dataframe(nlp, res('Test/Test for DDI Extraction task/DrugBank/'), relation_extraction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/33 [00:00<?, ?it/s]total_files_to_read: 33  from dir:  /mnt/projects/OpenNRE/benchmark/raw_ddi/DDICorpus/Test/Test for DDI Extraction task/MedLine/\n",
      "100%|██████████| 33/33 [00:22<00:00,  1.43it/s]\n"
     ]
    }
   ],
   "source": [
    "df_test_medline = get_dataset_dataframe(nlp, res('Test/Test for DDI Extraction task/MedLine/'), relation_extraction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "26004"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "len(df_train_drugbank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1787"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "len(df_train_medline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5265"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "len(df_test_drugbank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "451"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "len(df_test_medline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_empty_entity_rows(df):\n",
    "    empty_entity_rows = []\n",
    "    def find_empty_entity_number(row):\n",
    "        metadata = row.metadata\n",
    "        e1 = metadata['e1']['word_index']\n",
    "        e2 = metadata['e2']['word_index']\n",
    "        if not e1 or not e2:\n",
    "            empty_entity_rows.append(row.row_num)\n",
    "    temp_df = df.copy()\n",
    "    temp_df.insert(0, 'row_num', range(0, len(temp_df)))\n",
    "    temp_df.apply(find_empty_entity_number, axis=1)\n",
    "    return empty_entity_rows\n",
    "\n",
    "def get_empty_rows_array(empty_entity_rows, df):\n",
    "    empty_rows_array = []\n",
    "    for index in empty_entity_rows:\n",
    "        e1 = df.iloc[index].e1\n",
    "        e2 = df.iloc[index].e2\n",
    "        original_sentence = df.iloc[index].original_sentence\n",
    "        tokenized_sentence = df.iloc[index].tokenized_sentence\n",
    "        metadata = df.iloc[index].metadata\n",
    "        empty_rows_array.append([index, original_sentence, e1, e2, metadata, tokenized_sentence])\n",
    "    new_df = pd.DataFrame(data=empty_rows_array,    # values\n",
    "             columns=['index_original', 'original_sentence' , 'e1', 'e2', 'metadata', 'tokenized_sentence'])\n",
    "    return empty_rows_array, new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_empty_vals(df):\n",
    "    empty_entity_rows = get_empty_entity_rows(df)\n",
    "    empty_rows_array, new_df = get_empty_rows_array(empty_entity_rows, df)\n",
    "    return empty_rows_array, new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([],\n",
       " Empty DataFrame\n",
       " Columns: [index_original, original_sentence, e1, e2, metadata, tokenized_sentence]\n",
       " Index: [])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "get_empty_vals(df_train_drugbank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([],\n",
       " Empty DataFrame\n",
       " Columns: [index_original, original_sentence, e1, e2, metadata, tokenized_sentence]\n",
       " Index: [])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "get_empty_vals(df_train_medline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([],\n",
       " Empty DataFrame\n",
       " Columns: [index_original, original_sentence, e1, e2, metadata, tokenized_sentence]\n",
       " Index: [])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "get_empty_vals(df_test_drugbank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([],\n",
       " Empty DataFrame\n",
       " Columns: [index_original, original_sentence, e1, e2, metadata, tokenized_sentence]\n",
       " Index: [])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "get_empty_vals(df_test_medline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(out(outdir)):\n",
    "    os.makedirs(out(outdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframe(df_train_drugbank, out(outdir + 'train_drugbank_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_drugbank_copy = read_dataframe(out(outdir + 'train_drugbank_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# The first checks with the pd.equals method, and the other does a manual checking per column\n",
    "check_equality_of_written_and_read_df(df_train_drugbank, df_train_drugbank_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframe(df_train_medline, out(outdir + 'train_medline_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_medline_copy = read_dataframe(out(outdir + 'train_medline_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "check_equality_of_written_and_read_df(df_train_medline, df_train_medline_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframe(df_test_drugbank, out(outdir + 'test_drugbank_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_drugbank_copy = read_dataframe(out(outdir + 'test_drugbank_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "check_equality_of_written_and_read_df(df_test_drugbank, df_test_drugbank_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframe(df_test_medline, out(outdir + 'test_medline_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_medline_copy = read_dataframe(out(outdir + 'test_medline_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "check_equality_of_written_and_read_df(df_test_medline, df_test_medline_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  3%|▎         | 843/26004 [00:00<00:02, 8425.61it/s]Unique relations: \t ['none' 'mechanism' 'effect' 'advise' 'int']\n",
      "100%|██████████| 26004/26004 [00:03<00:00, 8497.92it/s]\n"
     ]
    }
   ],
   "source": [
    "write_into_txt(df_train_drugbank, out(outdir + 'train_drugbank_original.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 93%|█████████▎| 1664/1787 [00:00<00:00, 8417.83it/s]Unique relations: \t ['none' 'mechanism' 'effect' 'advise' 'int']\n",
      "100%|██████████| 1787/1787 [00:00<00:00, 8262.36it/s]\n"
     ]
    }
   ],
   "source": [
    "write_into_txt(df_train_medline, out(outdir + 'train_medline_original.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 16%|█▌        | 832/5265 [00:00<00:00, 8310.68it/s]Unique relations: \t ['none' 'effect' 'int' 'advise' 'mechanism']\n",
      "100%|██████████| 5265/5265 [00:00<00:00, 7885.13it/s]\n"
     ]
    }
   ],
   "source": [
    "write_into_txt(df_test_drugbank, out(outdir + 'test_drugbank_original.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 451/451 [00:00<00:00, 8103.49it/s]Unique relations: \t ['none' 'mechanism' 'advise' 'effect' 'int']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "write_into_txt(df_test_medline, out(outdir + 'test_medline_original.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine(out, outdir,  'train_drugbank_original', 'train_medline_original', 'ddi_train_original.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine(out, outdir, 'test_drugbank_original', 'test_medline_original', 'ddi_val_original.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataframe_names = ['train_drugbank', 'train_medline', 'test_drugbank', 'test_medline']\n",
    "makedir(outdir1, out)\n",
    "makedir(outdir2, out)\n",
    "makedir(outdir3, out)\n",
    "makedir(outdir4, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.1.json: 139kB [00:00, 11.6MB/s]                    \n",
      "2021-06-19 01:58:10 INFO: Downloading these customized packages for language: en (English)...\n",
      "================================\n",
      "| Processor       | Package    |\n",
      "--------------------------------\n",
      "| tokenize        | craft      |\n",
      "| pos             | craft      |\n",
      "| lemma           | craft      |\n",
      "| depparse        | craft      |\n",
      "| ner             | bionlp13cg |\n",
      "| pretrain        | craft      |\n",
      "| backward_charlm | pubmed     |\n",
      "| forward_charlm  | pubmed     |\n",
      "================================\n",
      "\n",
      "2021-06-19 01:58:10,202 - stanza - INFO - Downloading these customized packages for language: en (English)...\n",
      "================================\n",
      "| Processor       | Package    |\n",
      "--------------------------------\n",
      "| tokenize        | craft      |\n",
      "| pos             | craft      |\n",
      "| lemma           | craft      |\n",
      "| depparse        | craft      |\n",
      "| ner             | bionlp13cg |\n",
      "| pretrain        | craft      |\n",
      "| backward_charlm | pubmed     |\n",
      "| forward_charlm  | pubmed     |\n",
      "================================\n",
      "\n",
      "2021-06-19 01:58:10 INFO: File exists: /home/igor/stanza_resources/en/tokenize/craft.pt.\n",
      "2021-06-19 01:58:10,206 - stanza - INFO - File exists: /home/igor/stanza_resources/en/tokenize/craft.pt.\n",
      "2021-06-19 01:58:10 INFO: File exists: /home/igor/stanza_resources/en/pos/craft.pt.\n",
      "2021-06-19 01:58:10,245 - stanza - INFO - File exists: /home/igor/stanza_resources/en/pos/craft.pt.\n",
      "2021-06-19 01:58:10 INFO: File exists: /home/igor/stanza_resources/en/lemma/craft.pt.\n",
      "2021-06-19 01:58:10,253 - stanza - INFO - File exists: /home/igor/stanza_resources/en/lemma/craft.pt.\n",
      "2021-06-19 01:58:10 INFO: File exists: /home/igor/stanza_resources/en/depparse/craft.pt.\n",
      "2021-06-19 01:58:10,426 - stanza - INFO - File exists: /home/igor/stanza_resources/en/depparse/craft.pt.\n",
      "2021-06-19 01:58:10 INFO: File exists: /home/igor/stanza_resources/en/ner/bionlp13cg.pt.\n",
      "2021-06-19 01:58:10,719 - stanza - INFO - File exists: /home/igor/stanza_resources/en/ner/bionlp13cg.pt.\n",
      "2021-06-19 01:58:10 INFO: File exists: /home/igor/stanza_resources/en/pretrain/craft.pt.\n",
      "2021-06-19 01:58:10,851 - stanza - INFO - File exists: /home/igor/stanza_resources/en/pretrain/craft.pt.\n",
      "2021-06-19 01:58:10 INFO: File exists: /home/igor/stanza_resources/en/backward_charlm/pubmed.pt.\n",
      "2021-06-19 01:58:10,895 - stanza - INFO - File exists: /home/igor/stanza_resources/en/backward_charlm/pubmed.pt.\n",
      "2021-06-19 01:58:10 INFO: File exists: /home/igor/stanza_resources/en/forward_charlm/pubmed.pt.\n",
      "2021-06-19 01:58:10,938 - stanza - INFO - File exists: /home/igor/stanza_resources/en/forward_charlm/pubmed.pt.\n",
      "2021-06-19 01:58:10 INFO: Finished downloading models and saved to /home/igor/stanza_resources.\n",
      "2021-06-19 01:58:10,939 - stanza - INFO - Finished downloading models and saved to /home/igor/stanza_resources.\n",
      "2021-06-19 01:58:10 INFO: Loading these models for language: en (English):\n",
      "==========================\n",
      "| Processor | Package    |\n",
      "--------------------------\n",
      "| tokenize  | craft      |\n",
      "| pos       | craft      |\n",
      "| lemma     | craft      |\n",
      "| depparse  | craft      |\n",
      "| ner       | bionlp13cg |\n",
      "==========================\n",
      "\n",
      "2021-06-19 01:58:10,942 - stanza - INFO - Loading these models for language: en (English):\n",
      "==========================\n",
      "| Processor | Package    |\n",
      "--------------------------\n",
      "| tokenize  | craft      |\n",
      "| pos       | craft      |\n",
      "| lemma     | craft      |\n",
      "| depparse  | craft      |\n",
      "| ner       | bionlp13cg |\n",
      "==========================\n",
      "\n",
      "2021-06-19 01:58:10 INFO: Use device: gpu\n",
      "2021-06-19 01:58:10,943 - stanza - INFO - Use device: gpu\n",
      "2021-06-19 01:58:10 INFO: Loading: tokenize\n",
      "2021-06-19 01:58:10,943 - stanza - INFO - Loading: tokenize\n",
      "2021-06-19 01:58:10 INFO: Loading: pos\n",
      "2021-06-19 01:58:10,956 - stanza - INFO - Loading: pos\n",
      "2021-06-19 01:58:11 INFO: Loading: lemma\n",
      "2021-06-19 01:58:11,096 - stanza - INFO - Loading: lemma\n",
      "2021-06-19 01:58:11 INFO: Loading: depparse\n",
      "2021-06-19 01:58:11,132 - stanza - INFO - Loading: depparse\n",
      "2021-06-19 01:58:11 INFO: Loading: ner\n",
      "2021-06-19 01:58:11,451 - stanza - INFO - Loading: ner\n",
      "2021-06-19 01:58:11 INFO: Done loading processors!\n",
      "2021-06-19 01:58:11,817 - stanza - INFO - Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "stanza.download('en', package='craft', processors={'ner': 'bionlp13cg'})\n",
    "nlp = stanza.Pipeline('en', package=\"craft\", processors={\"ner\": \"bionlp13cg\"}, tokenize_no_ssplit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for original_df_name in original_dataframe_names:\n",
    "    type1 = preprocess(read_dataframe, out(indir + original_df_name + '_original.csv'), nlp)\n",
    "    type2 = preprocess(read_dataframe, out(indir + original_df_name + '_original.csv'), nlp, 2)\n",
    "    type3 = preprocess(read_dataframe, out(indir + original_df_name + '_original.csv'), nlp, 3)\n",
    "    type4 = preprocess(read_dataframe, out(indir + original_df_name + '_original.csv'), nlp, 4)\n",
    "    write_dataframe(type1, out(outdir1 + original_df_name + '_entity_blinding.csv'))\n",
    "    write_dataframe(type2, out(outdir2 + original_df_name + '_punct_stop_digit.csv'))\n",
    "    write_dataframe(type3, out(outdir3 + original_df_name + '_punct_digit.csv'))\n",
    "    write_dataframe(type4, out(outdir4 + original_df_name + '_ner_blinding.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  3%|▎         | 864/26004 [00:00<00:02, 8638.67it/s]Unique relations: \t ['none' 'mechanism' 'effect' 'advise' 'int']\n",
      "100%|██████████| 26004/26004 [00:03<00:00, 8332.36it/s]\n",
      "  3%|▎         | 877/26004 [00:00<00:02, 8762.65it/s]Unique relations: \t ['none' 'mechanism' 'effect' 'advise' 'int']\n",
      "100%|██████████| 26004/26004 [00:03<00:00, 8130.54it/s]\n",
      "  3%|▎         | 836/26004 [00:00<00:03, 8351.25it/s]Unique relations: \t ['none' 'mechanism' 'effect' 'advise' 'int']\n",
      "100%|██████████| 26004/26004 [00:03<00:00, 8237.43it/s]\n",
      "  3%|▎         | 810/26004 [00:00<00:03, 8095.61it/s]Unique relations: \t ['none' 'mechanism' 'effect' 'advise' 'int']\n",
      "100%|██████████| 26004/26004 [00:03<00:00, 7998.01it/s]\n",
      " 46%|████▌     | 816/1787 [00:00<00:00, 8152.85it/s]Unique relations: \t ['none' 'mechanism' 'effect' 'advise' 'int']\n",
      "100%|██████████| 1787/1787 [00:00<00:00, 7960.78it/s]\n",
      " 44%|████▍     | 784/1787 [00:00<00:00, 7837.35it/s]Unique relations: \t ['none' 'mechanism' 'effect' 'advise' 'int']\n",
      "100%|██████████| 1787/1787 [00:00<00:00, 8264.27it/s]\n",
      " 47%|████▋     | 846/1787 [00:00<00:00, 8454.16it/s]Unique relations: \t ['none' 'mechanism' 'effect' 'advise' 'int']\n",
      "100%|██████████| 1787/1787 [00:00<00:00, 8199.99it/s]\n",
      " 84%|████████▍ | 1503/1787 [00:00<00:00, 7518.83it/s]Unique relations: \t ['none' 'mechanism' 'effect' 'advise' 'int']\n",
      "100%|██████████| 1787/1787 [00:00<00:00, 7595.41it/s]\n",
      " 16%|█▌        | 819/5265 [00:00<00:00, 8187.04it/s]Unique relations: \t ['none' 'effect' 'int' 'advise' 'mechanism']\n",
      "100%|██████████| 5265/5265 [00:00<00:00, 7578.29it/s]\n",
      " 16%|█▋        | 862/5265 [00:00<00:00, 8612.53it/s]Unique relations: \t ['none' 'effect' 'int' 'advise' 'mechanism']\n",
      "100%|██████████| 5265/5265 [00:00<00:00, 8279.66it/s]\n",
      " 15%|█▌        | 794/5265 [00:00<00:00, 7935.96it/s]Unique relations: \t ['none' 'effect' 'int' 'advise' 'mechanism']\n",
      "100%|██████████| 5265/5265 [00:00<00:00, 7864.64it/s]\n",
      " 32%|███▏      | 1699/5265 [00:00<00:00, 8503.13it/s]Unique relations: \t ['none' 'effect' 'int' 'advise' 'mechanism']\n",
      "100%|██████████| 5265/5265 [00:00<00:00, 8345.93it/s]\n",
      "100%|██████████| 451/451 [00:00<00:00, 8638.29it/s]\n",
      "100%|██████████| 451/451 [00:00<00:00, 7855.09it/s]\n",
      "100%|██████████| 451/451 [00:00<00:00, 8463.71it/s]\n",
      "  0%|          | 0/451 [00:00<?, ?it/s]Unique relations: \t ['none' 'mechanism' 'advise' 'effect' 'int']\n",
      "Unique relations: \t ['none' 'mechanism' 'advise' 'effect' 'int']\n",
      "Unique relations: \t ['none' 'mechanism' 'advise' 'effect' 'int']\n",
      "Unique relations: \t ['none' 'mechanism' 'advise' 'effect' 'int']\n",
      "100%|██████████| 451/451 [00:00<00:00, 8152.70it/s]\n"
     ]
    }
   ],
   "source": [
    "for original_df_name in original_dataframe_names:\n",
    "    type1 = read_dataframe(out(outdir1 + original_df_name + '_entity_blinding.csv'))\n",
    "    type2 = read_dataframe(out(outdir2 + original_df_name + '_punct_stop_digit.csv'))\n",
    "    type3 = read_dataframe(out(outdir3 + original_df_name + '_punct_digit.csv'))\n",
    "    type4 = read_dataframe(out(outdir4 + original_df_name + '_ner_blinding.csv'))\n",
    "    write_into_txt(type1, out(outdir1 + original_df_name + '_entity_blinding.txt'))\n",
    "    write_into_txt(type2, out(outdir2 + original_df_name + '_punct_stop_digit.txt'))\n",
    "    write_into_txt(type3, out(outdir3 + original_df_name + '_punct_digit.txt'))\n",
    "    write_into_txt(type4, out(outdir4 + original_df_name + '_ner_blinding.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['train', 'test']:\n",
    "    if i == 'train':\n",
    "        combine(out, outdir1, i + '_drugbank_entity_blinding', i + '_medline_entity_blinding', 'ddi_train_entity_blinding.txt')\n",
    "        combine(out, outdir2, i + '_drugbank_punct_stop_digit', i + '_medline_punct_stop_digit', 'ddi_train_punct_stop_digit.txt')\n",
    "        combine(out, outdir3, i + '_drugbank_punct_digit', i + '_medline_punct_digit', 'ddi_train_punct_digit.txt')\n",
    "        combine(out, outdir4, i + '_drugbank_ner_blinding', i + '_medline_ner_blinding', 'ddi_train_ner_blinding.txt')\n",
    "    else:\n",
    "        combine(out, outdir1, i + '_drugbank_entity_blinding', i + '_medline_entity_blinding', 'ddi_val_entity_blinding.txt')\n",
    "        combine(out, outdir2, i + '_drugbank_punct_stop_digit', i + '_medline_punct_stop_digit', 'ddi_val_punct_stop_digit.txt')\n",
    "        combine(out, outdir3, i + '_drugbank_punct_digit', i + '_medline_punct_digit', 'ddi_val_punct_digit.txt')\n",
    "        combine(out, outdir4, i + '_drugbank_ner_blinding', i + '_medline_ner_blinding', 'ddi_val_ner_blinding.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_relations_json(out(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_file_length(res, filename):\n",
    "    return len(open(res(filename)).readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "27791\n27791\n27791\n27791\n27791\n"
     ]
    }
   ],
   "source": [
    "print(output_file_length(out, indir + 'ddi_train_original.txt'))\n",
    "print(output_file_length(out, outdir1 + 'train_entity_blinding.txt'))\n",
    "print(output_file_length(out, outdir2 + 'train_punct_stop_digit.txt'))\n",
    "print(output_file_length(out, outdir3 + 'train_punct_digit.txt'))\n",
    "print(output_file_length(out, outdir4 + 'train_ner_blinding.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5716\n5716\n5716\n5716\n5716\n"
     ]
    }
   ],
   "source": [
    "print(output_file_length(out, indir + 'ddi_val_original.txt'))\n",
    "print(output_file_length(out, outdir1 + 'ddi_val_entity_blinding.txt'))\n",
    "print(output_file_length(out, outdir2 + 'ddi_val_punct_stop_digit.txt'))\n",
    "print(output_file_length(out, outdir3 + 'ddi_val_punct_digit.txt'))\n",
    "print(output_file_length(out, outdir4 + 'ddi_val_ner_blinding.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}